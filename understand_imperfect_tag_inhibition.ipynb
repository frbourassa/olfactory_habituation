{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893db8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from modelfcts.backgrounds import (\n",
    "    update_powerlaw_times_concs, \n",
    "    logof10, \n",
    "    sample_background_powerlaw,\n",
    "    sample_ss_conc_powerlaw, \n",
    "    decompose_nonorthogonal_basis, \n",
    "    update_alternating_inputs, \n",
    "    generate_odorant\n",
    ")\n",
    "from modelfcts.tagging import (\n",
    "    project_neural_tag, \n",
    "    create_sparse_proj_mat, \n",
    "    tags_list_to_csr_matrix, \n",
    "    SparseNDArray\n",
    ")\n",
    "from utils.statistics import seed_from_gen\n",
    "from modelfcts.distribs import (\n",
    "    truncexp1_inverse_transform, \n",
    "    truncexp1_density, \n",
    "    powerlaw_cutoff_inverse_transform\n",
    ")\n",
    "from modelfcts.checktools import check_conc_samples_powerlaw_exp1\n",
    "from modelfcts.smoothing_function import moving_average\n",
    "from simulfcts.plotting import (\n",
    "    plot_cbars_gammas_sums, \n",
    "    plot_cbars_gamma_series, \n",
    "    plot_3d_series, \n",
    "    plot_w_matrix, \n",
    "    plot_background_norm_inhibition, \n",
    "    plot_background_neurons_inhibition\n",
    ")\n",
    "from utils.metrics import jaccard, l2_norm\n",
    "from modelfcts.ibcm import relu_inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41cc4c3",
   "metadata": {},
   "source": [
    "# Static $\\vec{m}$ equal to background odors (impossible)\n",
    "To understand if the problem comes from $W$ or $M$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_inhib_static_m(m_vecs, update_bk, bk_init, inhib_params, bk_params, tmax, dt,\n",
    "                         seed=None, noisetype=\"normal\", skp=1, activ_fct=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        m_vecs(np.ndarray): 2d array, shape (number neurons, number dimensions)\n",
    "            The M matrix where each row is an m vector, ie\n",
    "            synaptic weights connecting one inhibitory neuron to input neurons.\n",
    "        update_bk (callable): function that updates the background variables and\n",
    "            the background vector\n",
    "        bk_init (list of two 1d np.ndarrays): [bk_vari_init, bk_vec_init]\n",
    "            bk_vari_init (np.ndarray): array of background random variables,\n",
    "                shaped [odor, n_var_per_odor], or 1d if one var. per odor.\n",
    "            bk_vec_init (np.ndarray): initial background vector, must have size n_orn\n",
    "        inhib_params (list): alpha, beta: list of parameters for the inhibitory\n",
    "            neurons update. Should have alpha > beta here.\n",
    "            For the early times averaging of synaptic weights, will use beta\n",
    "            and alpha as alpha and beta (to keep m vector close to origin).\n",
    "        bk_params (list): list of parameters passed to update_bk (3rd argument)\n",
    "        tmax (float): max time\n",
    "        dt (float): time step\n",
    "        seed (int): seed for the random number generator\n",
    "        noisetype (str): either \"normal\" or \"uniform\"\n",
    "        skp (int): save only every skp time step\n",
    "\n",
    "    Returns:\n",
    "        tseries, bk_series, bkvec_series, m_series, cbar_series, w_series, s_series\n",
    "    \"\"\"\n",
    "    n_neu = m_vecs.shape[0]  # Number of neurons\n",
    "    n_orn = m_vecs.shape[1]\n",
    "    bk_vari_init, bk_vec_init = bk_init\n",
    "    assert n_orn == bk_vec_init.shape[0], \"Mismatch between dimension of m and background\"\n",
    "    alpha, beta = inhib_params\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    tseries = np.arange(0, tmax, dt*skp)\n",
    "\n",
    "    # Containers for the solution over time\n",
    "    bk_series = np.zeros([tseries.shape[0]] + list(bk_vari_init.shape))\n",
    "    cbar_series = np.zeros([tseries.shape[0], n_neu])\n",
    "    w_series = np.zeros([tseries.shape[0], n_orn, n_neu])  # Inhibitory weights\n",
    "    bkvec_series = np.zeros([tseries.shape[0], n_orn])  # Input vecs, convenient to compute inhibited output\n",
    "    s_series = np.zeros([tseries.shape[0], n_orn])\n",
    "\n",
    "    ## Initialize running variables, separate from the containers above to avoid side effects.\n",
    "    cbar = np.zeros(n_neu)  # neuron activities\n",
    "    wmat = w_series[0].copy()  # Initialize with null inhibition\n",
    "    bk_vari = bk_vari_init.copy()\n",
    "    bkvec = bk_vec_init.copy()\n",
    "    m = m_vecs.copy()\n",
    "    if activ_fct is None:\n",
    "        svec = bk_vec_init.copy()\n",
    "    elif activ_fct == \"ReLU\":\n",
    "        svec = relu_inplace(bk_vec_init.copy())\n",
    "    else: raise ValueError(\"Unknown activation function: {}\".format(activ_fct))\n",
    "\n",
    "    # Initialize neuron activity with m and background at time zero\n",
    "    cbar = m.dot(bkvec)\n",
    "\n",
    "    # Store back some initial values in containers\n",
    "    cbar_series[0] = cbar\n",
    "    bk_series[0] = bk_vari\n",
    "    bkvec_series[0] = bkvec\n",
    "    s_series[0] = svec\n",
    "\n",
    "    # Generate N(0, 1) noise samples in advance\n",
    "    if (tseries.shape[0]*skp-1)*bk_vari.size > 1e7:\n",
    "        raise ValueError(\"Too much memory needed; consider calling multiple times for shorter times\")\n",
    "    if noisetype == \"normal\":\n",
    "        noises = rng.normal(0, 1, size=(tseries.shape[0]*skp-1,*bk_vari.shape))\n",
    "    elif noisetype == \"uniform\":\n",
    "        noises = rng.random(size=(tseries.shape[0]*skp-1, *bk_vari.shape))\n",
    "    else:\n",
    "        raise NotImplementedError(\"Noise option {} not implemented\".format(noisetype))\n",
    "\n",
    "    t = 0\n",
    "    for k in range(0, len(tseries)*skp-1):\n",
    "        t += dt\n",
    "        ### Inhibitory  weights\n",
    "        # They depend on cbar and svec at time step k, which are still in cbar, svec\n",
    "        # cbar, shape [n_neu], should broadcast against columns of wmat,\n",
    "        # while svec, shape [n_orn], should broadcast across rows (copied on each column)\n",
    "        wmat = wmat + dt * (alpha*cbar[np.newaxis, :]*svec[:, np.newaxis] - beta*wmat)\n",
    "\n",
    "        # Update background to time k+1, to be used in next time step\n",
    "        bkvec, bk_vari = update_bk(bk_vari, bk_params, noises[k], dt)\n",
    "\n",
    "        # Then, compute activity of IBCM neurons at next time step, k+1,\n",
    "        # with the updated background and synaptic weight vector m\n",
    "        # Compute un-inhibited activity of each neuron with current input (at time k)\n",
    "        cbar = m.dot(bkvec)\n",
    "        # Lastly, projection neurons at time step k+1\n",
    "        if activ_fct is None:\n",
    "            svec = bkvec - wmat.dot(cbar)\n",
    "        else:\n",
    "            svec = relu_inplace(bkvec - wmat.dot(cbar))\n",
    "\n",
    "        # Save current state only if at a multiple of skp\n",
    "        if (k % skp) == (skp - 1):\n",
    "            knext = (k+1) // skp\n",
    "            w_series[knext] = wmat\n",
    "            bk_series[knext] = bk_vari\n",
    "            bkvec_series[knext] = bkvec\n",
    "            cbar_series[knext] = cbar  # Save activity of neurons at time k+1\n",
    "            s_series[knext] = svec\n",
    "\n",
    "    return tseries, bk_series, bkvec_series, cbar_series, w_series, s_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa14fffb",
   "metadata": {},
   "source": [
    "## Attempt with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "### General simulation parameters\n",
    "n_dimensions = 25  # Half the real number for faster simulations\n",
    "n_components = 6\n",
    "n_neurons = n_components\n",
    "n_kenyon = int(2000 / 50 * n_dimensions)\n",
    "\n",
    "# Simulation rates and coupling stay the same (try at least)\n",
    "duration = 320000.0\n",
    "deltat = 1.0\n",
    "inhib_rates = [2.5e-4, 5e-5]  # alpha, beta\n",
    "# Background components need to be redefined. Extra dimensions are somewhat superfluous\n",
    "\n",
    "# Choose randomly generated background vectors\n",
    "rgen_meta = np.random.default_rng(seed=0x21e0b502e992cf60b2b7ea5c9a3ebc46)\n",
    "back_components = np.zeros([n_components, n_dimensions])\n",
    "for i in range(n_components):\n",
    "    back_components[i] = generate_odorant(n_dimensions, rgen_meta, lambda_in=0.1)\n",
    "back_components = back_components / l2_norm(back_components).reshape(-1, 1)\n",
    "    \n",
    "# Turbulent background parameters: same rates and constants for all odors\n",
    "back_params = [\n",
    "    np.asarray([1.0] * n_components),        # whiff_tmins\n",
    "    np.asarray([100.] * n_components),       # whiff_tmaxs\n",
    "    np.asarray([2.0] * n_components),        # blank_tmins\n",
    "    np.asarray([200.0] * n_components),      # blank_tmaxs\n",
    "    np.asarray([0.6] * n_components),        # c0s\n",
    "    np.asarray([0.5] * n_components),        # alphas\n",
    "]\n",
    "back_params.append(back_components)\n",
    "\n",
    "# Initial values of background process variables (t, c for each variable)\n",
    "init_concs = sample_ss_conc_powerlaw(*back_params[:-1], size=1, rgen=rgen_meta)\n",
    "init_times = powerlaw_cutoff_inverse_transform(\n",
    "                rgen_meta.random(size=n_components), *back_params[2:4])\n",
    "tc_init = np.stack([init_times, init_concs.squeeze()], axis=1)\n",
    "\n",
    "# Initial background vector \n",
    "init_bkvec = tc_init[:, 1].dot(back_components)\n",
    "# nus are first in the list of initial background params\n",
    "init_back_list = [tc_init, init_bkvec]\n",
    "\n",
    "# Set m vectors equal to background vectors\n",
    "constant_m_basis = back_components\n",
    "\n",
    "# For odor tagging\n",
    "proj_mat = create_sparse_proj_mat(n_kenyon, n_dimensions, rgen_meta, fraction_filled=6/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_init, update_bk, bk_init, ibcm_params, inhib_params, bk_params, tmax, dt, seed=None, noisetype=\"normal\"\n",
    "skp = 10\n",
    "sim_results = integrate_inhib_static_m(constant_m_basis, update_powerlaw_times_concs, \n",
    "                init_back_list, inhib_rates, back_params, duration, deltat, \n",
    "                seed=seed_from_gen(rgen_meta), noisetype=\"uniform\", skp=skp, activ_fct=\"ReLU\")\n",
    "tser, nuser, bkvecser, cbarser, wser, sser = sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a527c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the time course of the dot products -- not interesting with gaussian degeneracy\n",
    "# Unclear what it shows. \n",
    "fig, axes = plot_w_matrix(tser, wser, skp=20, lw=1.5)\n",
    "pseudo_inv = np.linalg.pinv(constant_m_basis)\n",
    "for j in range(n_components):\n",
    "    axes.flat[j].set_ylim(axes.flat[j].get_ylim())\n",
    "    for i in range(n_dimensions):\n",
    "        axes.flat[j].axhline(pseudo_inv[i, j], color=\"grey\", ls=\"--\")\n",
    "        \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, bknorm_ser, snorm_ser = plot_background_norm_inhibition(tser, bkvecser, sser, skp=10)\n",
    "\n",
    "# Compute noise reduction factor, annotate\n",
    "transient = 150000 // skp\n",
    "avg_bknorm = np.mean(bknorm_ser[transient:])\n",
    "avg_snorm = np.mean(snorm_ser[transient:])\n",
    "avg_reduction_factor = avg_snorm / avg_bknorm\n",
    "std_bknorm = np.std(bknorm_ser[transient:])\n",
    "std_snorm = np.std(snorm_ser[transient:])\n",
    "std_reduction_factor = std_snorm / std_bknorm\n",
    "\n",
    "print(\"Mean activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(avg_reduction_factor * 100))\n",
    "print(\"Standard deviation of activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(std_reduction_factor * 100))\n",
    "ax.annotate(\"St. dev. reduced to {:.1f} %\".format(std_reduction_factor * 100), \n",
    "           xy=(0.98, 0.98), xycoords=\"axes fraction\", ha=\"right\", va=\"top\")\n",
    "\n",
    "ax.legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.8))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bf5bb0",
   "metadata": {},
   "source": [
    "### Background tag silencing and new odor detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707523c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_x(xvec, mmat, wmat, activ_fct=None):\n",
    "    # xvec has shape [..., n_orn]\n",
    "    cvec = xvec.dot(mmat.T)  # cvec has shape [..., n_i]\n",
    "    svec = xvec - cvec.dot(wmat.T)  # svec has shape [..., n_orn]\n",
    "    if activ_fct == \"ReLU\":\n",
    "        svec = relu_inplace(svec)\n",
    "    return svec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattened_dict_vals(d, dim1, dim2):\n",
    "    vals = []\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            vals.append(d[(i, j)])\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bee28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_list_to_csr_matrix(tag_list, n_neu):\n",
    "    \"\"\" Given a list of sets of active neurons (i.e. a list of tags), \n",
    "    and the size of the layer, save to a scipy.sparse.csr_matrix\n",
    "    where each row is one tag. This minimizes memory use compared\n",
    "    to saving to a dense padded 2d array, yet is easier to save\n",
    "    to disk (without pickling) than a list of Python sets. \n",
    "    \n",
    "    Args:\n",
    "        tag_list (list of sets of ints): a list of sets of\n",
    "            indices of active neurons\n",
    "        n_neu (int): number of neurons in the layer, e.g.\n",
    "            largest possible neuron index + 1. \n",
    "    Returns:\n",
    "        tags_matrix (sp.sparse.csr_matrix): each row is one tag\n",
    "    \"\"\"\n",
    "    tag_lengths = list(map(len, tag_list))\n",
    "    tags_indptr = np.concatenate([[0], np.cumsum(tag_lengths)])\n",
    "    tags_indices = np.concatenate(list(map(list, tag_list)), axis=0)\n",
    "    tags_data = np.ones(len(tags_indices), dtype=bool)\n",
    "    tags_matrix = sp.sparse.csr_matrix((tags_data, tags_indices, tags_indptr), \n",
    "                                   shape=[len(tag_list), n_neu])\n",
    "    return tags_matrix\n",
    "\n",
    "def plot_odor_tags(tag_list, tag_times, n_kc):\n",
    "    tag_lengths = list(map(len, tag_list))\n",
    "    tag_vectors = tags_list_to_csr_matrix(tag_list, n_kc)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    fig.set_size_inches(8, 4)\n",
    "    axes[0].plot(tag_lengths, tag_times/1000, ls=\"-\", marker=\"s\", \n",
    "                 ms=4, color=\"k\", lw=1.0)\n",
    "    axes[0].set(ylabel=\"Time (x1000)\", xlabel=\"Background tag length\")\n",
    "    axes[0].invert_yaxis()\n",
    "    barprops = dict(aspect='auto', interpolation='nearest')\n",
    "    # extent: (left, right, bottom, top)\n",
    "    axes[1].imshow(tag_vectors.toarray(), **barprops, cmap=\"binary\", \n",
    "                   extent=(0, n_kc, tag_times[-1]/1000, tag_times[0]/1000))\n",
    "    axes[1].set(xlabel=\"Kenyon cell index\")\n",
    "    fig.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that background tags are silenced\n",
    "tag_slice = slice(0, int(duration) // skp, 3000 // skp)\n",
    "tag_slice_range = range(0, int(duration) // skp, 3000 // skp)\n",
    "tag_times = tser[tag_slice]\n",
    "back_tags = []\n",
    "for i in tag_slice_range:\n",
    "    back_tags.append(project_neural_tag(sser[i], bkvecser[i], proj_mat, \n",
    "                        kc_sparsity=0.05, adapt_kc=True, n_pn_per_kc=3, fix_thresh=None))\n",
    "\n",
    "fig, axes = plot_odor_tags(back_tags, tag_times, n_kenyon)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bdb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that new odors make it through still\n",
    "n_new_odors = 100\n",
    "test_slice = slice(200000 // skp, int(duration) // skp, 10000 // skp)\n",
    "test_slice_range = range(200000 // skp, int(duration) // skp, 10000 // skp)\n",
    "test_slice_times = tser[test_slice]\n",
    "new_odors = generate_odorant([n_new_odors, n_dimensions], rgen_meta, lambda_in=0.1)\n",
    "new_odors /= l2_norm(new_odors).reshape(*new_odors.shape[:-1], 1)\n",
    "mix_svecs = np.zeros([n_new_odors, len(test_slice_times), n_dimensions])\n",
    "mix_xvecs = np.zeros([n_new_odors, len(test_slice_times), n_dimensions])\n",
    "#mix_tags = SparseNDArray((n_new_odors, len(test_slice_times), n_kenyon_tag), dtype=bool)\n",
    "mix_tags = {(i, j):{} for i in range(n_new_odors) for j in range(len(test_slice_times))}\n",
    "mix_jaccards = np.zeros([n_new_odors, len(test_slice_times)])\n",
    "new_odors_tags = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abe8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_frac = 0.5\n",
    "projection_kwargs = dict(kc_sparsity=0.05, adapt_kc=True, n_pn_per_kc=3, fix_thresh=None)\n",
    "for i in range(n_new_odors):\n",
    "    mix_xvecs[i] = mix_frac*new_odors[i] + bkvecser[test_slice]\n",
    "    new_odors_tags.append(project_neural_tag(new_odors[i], new_odors[i], proj_mat, **projection_kwargs))\n",
    "for j, t in enumerate(test_slice_range):\n",
    "    mix_svecs[:, j] = respond_to_x(mix_xvecs[:, j], constant_m_basis, wser[t], activ_fct=\"ReLU\")\n",
    "    # Compute all tags now\n",
    "    for i in range(n_new_odors):\n",
    "        tag = project_neural_tag(mix_svecs[i, j], mix_svecs[i, j], proj_mat, **projection_kwargs)\n",
    "        mix_tags[(i, j)] = tag\n",
    "        mix_jaccards[i, j] = jaccard(new_odors_tags[i], tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(8, 4)\n",
    "axes[0].hist(mix_jaccards.flatten(), bins=10)\n",
    "#axes[1].hist(list(map(len, mix_tags.data)))\n",
    "mix_tag_lengths = {}\n",
    "for i in range(n_new_odors):\n",
    "    for j in range(len(test_slice_times)):\n",
    "        mix_tag_lengths[(i, j)] = len(mix_tags[(i, j)])\n",
    "\n",
    "axes[1].scatter(flattened_dict_vals(mix_tag_lengths, n_new_odors, len(test_slice_times)), mix_jaccards.flatten())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59214f4",
   "metadata": {},
   "source": [
    "## Attempt without ReLU\n",
    "The learnt W should be closer to the pseudo-inverse, but it turns out not to be the case, really. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c3b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_test(activ_fct=\"ReLU\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_init, update_bk, bk_init, ibcm_params, inhib_params, bk_params, tmax, dt, seed=None, noisetype=\"normal\"\n",
    "skp2 = 10\n",
    "sim_results = integrate_inhib_static_m(constant_m_basis, update_powerlaw_times_concs, \n",
    "                init_back_list, inhib_rates, back_params, duration, deltat, \n",
    "                seed=seed_from_gen(rgen_meta), noisetype=\"uniform\", skp=skp2, activ_fct=None)\n",
    "tser2, nuser2, bkvecser2, cbarser2, wser2, sser2 = sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c933f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, bknorm_ser2, snorm_ser2 = plot_background_norm_inhibition(tser2, bkvecser2, sser2, skp=10)\n",
    "\n",
    "# Compute noise reduction factor, annotate\n",
    "transient = 150000 // skp\n",
    "avg_bknorm2 = np.mean(bknorm_ser2[transient:])\n",
    "avg_snorm2 = np.mean(snorm_ser2[transient:])\n",
    "avg_reduction_factor2 = avg_snorm2 / avg_bknorm2\n",
    "std_bknorm2 = np.std(bknorm_ser2[transient:])\n",
    "std_snorm2 = np.std(snorm_ser2[transient:])\n",
    "std_reduction_factor2 = std_snorm / std_bknorm2\n",
    "\n",
    "print(\"Mean activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(avg_reduction_factor * 100))\n",
    "print(\"Standard deviation of activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(std_reduction_factor * 100))\n",
    "ax.annotate(\"St. dev. reduced to {:.1f} %\".format(std_reduction_factor * 100), \n",
    "           xy=(0.98, 0.98), xycoords=\"axes fraction\", ha=\"right\", va=\"top\")\n",
    "\n",
    "ax.legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.8))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Check that background tags are silenced\n",
    "tag_slice = slice(0, int(duration) // skp2, 3000 // skp2)\n",
    "tag_slice_range = range(0, int(duration) // skp2, 3000 // skp2)\n",
    "tag_times = tser2[tag_slice]\n",
    "back_tags = []\n",
    "for i in tag_slice_range:\n",
    "    back_tags.append(project_neural_tag(sser2[i], bkvecser2[i], proj_mat, \n",
    "                        kc_sparsity=0.05, adapt_kc=True, n_pn_per_kc=3, fix_thresh=None))\n",
    "\n",
    "fig, axes = plot_odor_tags(back_tags, tag_times, n_kenyon)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that new odors make it through still\n",
    "n_new_odors = 100\n",
    "test_slice = slice(200000 // skp2, int(duration) // skp2, 10000 // skp2)\n",
    "test_slice_range = range(200000 // skp2, int(duration) // skp2, 10000 // skp2)\n",
    "test_slice_times = tser2[test_slice]\n",
    "new_odors2 = generate_odorant([n_new_odors, n_dimensions], rgen_meta, lambda_in=0.1)\n",
    "new_odors2 /= l2_norm(new_odors2).reshape(*new_odors2.shape[:-1], 1)\n",
    "mix_svecs = np.zeros([n_new_odors, len(test_slice_times), n_dimensions])\n",
    "mix_xvecs = np.zeros([n_new_odors, len(test_slice_times), n_dimensions])\n",
    "#mix_tags = SparseNDArray((n_new_odors, len(test_slice_times), n_kenyon), dtype=bool)\n",
    "mix_tags = {(i, j):{} for i in range(n_new_odors) for j in range(len(test_slice_times))}\n",
    "mix_jaccards = np.zeros([n_new_odors, len(test_slice_times)])\n",
    "new_odors_tags2 = []\n",
    "\n",
    "mix_frac = 0.5\n",
    "projection_kwargs = dict(kc_sparsity=0.05, adapt_kc=True, n_pn_per_kc=3, fix_thresh=None)\n",
    "for i in range(n_new_odors):\n",
    "    mix_xvecs[i] = mix_frac*new_odors2[i] + bkvecser2[test_slice]\n",
    "    new_odors_tags2.append(project_neural_tag(new_odors2[i], new_odors2[i], proj_mat, **projection_kwargs))\n",
    "for j, t in enumerate(test_slice_range):\n",
    "    mix_svecs[:, j] = respond_to_x(mix_xvecs[:, j], constant_m_basis, wser2[t], activ_fct=None)\n",
    "    # Compute all tags now\n",
    "    for i in range(n_new_odors):\n",
    "        tag = project_neural_tag(mix_svecs[i, j], mix_svecs[i, j], proj_mat, **projection_kwargs)\n",
    "        mix_tags[(i, j)] = tag\n",
    "        mix_jaccards[i, j] = jaccard(new_odors_tags2[i], tag)\n",
    "        \n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(8, 4)\n",
    "axes[0].hist(mix_jaccards.flatten(), bins=10)\n",
    "#axes[1].hist(list(map(len, mix_tags.data)))\n",
    "mix_tag_lengths = {}\n",
    "for i in range(n_new_odors):\n",
    "    for j in range(len(test_slice_times)):\n",
    "        mix_tag_lengths[(i, j)] = len(mix_tags[(i, j)])\n",
    "\n",
    "axes[1].scatter(flattened_dict_vals(mix_tag_lengths, n_new_odors, len(test_slice_times)), mix_jaccards.flatten())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73649c",
   "metadata": {},
   "source": [
    "## Attempt without $W$ decay\n",
    "The regularization term is what prevents W from being $M^+$. If we do not use ReLU and set $\\beta = 0$, then $W$ converges to an approximate pseudo-inverse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97093a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inhib_rates3 = [1e-3, 0.0]  # alpha, beta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
