{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Habituation with IBCM neurons gating inhibitory neurons\n",
    "The details of the model are described in other Jupyter notebooks (e.g., ibcm_inhibition_three_components.ipynb). The goal here is to include this model in the full olfactory network down to Kenyon cells, apply it to increasingly realistic olfactory backgrounds and estimate its performance at 1) inhibiting the fluctuating background, and 2) still recognizing new odors. \n",
    "\n",
    "Here, in particular, we focus on log-normal concentration fluctuations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from time import perf_counter\n",
    "\n",
    "from utils.statistics import seed_from_gen\n",
    "from modelfcts.ibcm import (\n",
    "    integrate_inhib_ibcm_network, \n",
    "    integrate_inhib_ibcm_network_tanh,\n",
    "    relu_inplace, \n",
    "    compute_mbars_cgammas_cbargammas\n",
    ")\n",
    "# Functions to update the fluctuating background variable\n",
    "from modelfcts.backgrounds import (\n",
    "    update_logou_kinputs, \n",
    "    decompose_nonorthogonal_basis, \n",
    "    generate_odorant, \n",
    "    logof10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a simulation\n",
    "Hopefully, the inhibitory neurons can be combined to perfectly inhibit the input. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### General simulation parameters\n",
    "n_dimensions = 3  # Half the real number for faster simulations\n",
    "# The larger the dimension, the more likely the odors are orthogonal. \n",
    "n_components = 3  # no need to look at super complicated odors for now; keep effective space 3D\n",
    "# Can actually look at this latent space by Gram-Schmidt to find orthogonal axes spanning the input odors. \n",
    "n_neurons = 16  # Start small\n",
    "\n",
    "# Simulation times\n",
    "duration = 160000.0\n",
    "deltat = 1.0\n",
    "learnrate = 0.001\n",
    "tau_avg = 200\n",
    "coupling_eta = 0.05 / n_neurons\n",
    "\n",
    "inhib_rates = [0.00025, 0.00005]  # alpha, beta\n",
    "\n",
    "# Initial synaptic weights: small positive noise near origin\n",
    "rgen_meta = np.random.default_rng(seed=92387)\n",
    "init_synapses = 0.1*rgen_meta.random(size=[n_neurons, n_dimensions])\n",
    "\n",
    "# Choose random exponential LI vectors\n",
    "back_components = np.zeros([n_components, n_dimensions])\n",
    "for i in range(n_components):\n",
    "    back_components[i] = generate_odorant(n_dimensions, rgen_meta, lambda_in=1.0)\n",
    "print(back_components)\n",
    "\n",
    "\n",
    "init_back_altern = [np.zeros(1), back_components[0]]  # Start with component 0\n",
    "back_params_altern = [np.arange(n_components)/n_components, back_components]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# m_init, update_bk, bk_init, inhib_params, bk_params, tmax, dt, learnrate, seed=14345124, noisetype=\"normal\", tavg=10, coupling=0.1\n",
    "sim_results = integrate_inhib_ibcm_network(init_synapses, update_alternating_inputs, init_back_altern, inhib_rates,\n",
    "                    back_params_altern, duration, deltat, learnrate=learnrate, seed=509811537, \n",
    "                    noisetype=\"uniform\", tavg=tau_avg, coupling=coupling_eta)\n",
    "tser, mser, nuser, cser, cbarser, _, wser, bkvecser = sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General simulation parameters\n",
    "n_dimensions = 4  # Half the real number for faster simulations\n",
    "# The larger the dimension, the more likely the odors are orthogonal. \n",
    "n_components = 3  # no need to look at super complicated odors for now; keep effective space 3D\n",
    "# Can actually look at this latent space by Gram-Schmidt to find orthogonal axes spanning the input odors. \n",
    "n_neurons = 12  # Start small\n",
    "\n",
    "# Simulation times\n",
    "duration = 160000.0\n",
    "deltat = 1.0\n",
    "learnrate = 0.0015\n",
    "tau_avg = 200\n",
    "coupling_eta = 0.05 / n_neurons\n",
    "saturation_ampli = 50.0\n",
    "\n",
    "inhib_rates = [0.00025, 0.00005]  # alpha, beta\n",
    "lambd_ibcm = 1.0  # Absolute scale of M\n",
    "ibcm_rates = [learnrate, tau_avg, coupling_eta, lambd_ibcm, saturation_ampli]\n",
    "\n",
    "# Symmetric components to begin with\n",
    "back_components = 0.1*np.ones([n_components, n_dimensions])\n",
    "for i in range(n_components):\n",
    "    if i < n_dimensions:\n",
    "        back_components[i, i] = 0.8\n",
    "    else:  # If there are more components than there are dimensions (ORNs)\n",
    "        back_components[i, i % n_dimensions] = 0.8 - i\n",
    "    # Normalize\n",
    "    back_components[i] = back_components[i] / np.sqrt(np.sum(back_components[i]**2))\n",
    "print(back_components)\n",
    "\n",
    "# Initial synaptic weights: small positive noise near origin\n",
    "# Issue: the neurons do not seem to distribute equally to the 3 fixed points with this choice.\n",
    "# Maybe because of lack of symmetry there are not 3 stable fixed points anymore? Tricky. \n",
    "# Try other initial conditions\n",
    "rgen_meta = np.random.default_rng(seed=0x959905bd65b43006c10a3b72fb9ab60f)\n",
    "#init_synapses = 0.1*rgen_meta.random(size=[n_neurons, n_dimensions])\n",
    "init_synapses = 0.5*rgen_meta.random(size=[n_neurons, n_components]).dot(back_components) * lambd_ibcm\n",
    "\n",
    "# Try forcing a third of the neurons to each fixed point\n",
    "# By initializing them orthogonal to two of three background components. \n",
    "force_init = False\n",
    "if force_init:\n",
    "    init_synapses = np.zeros([n_neurons, n_components])\n",
    "    orthogonal1 = np.cross(back_components[0], back_components[1])\n",
    "    orthogonal2 = np.cross(back_components[1], back_components[2])\n",
    "    orthogonal3 = np.cross(back_components[2], back_components[0])\n",
    "    init_synapses[:n_neurons // 3] = orthogonal1[np.newaxis, :]\n",
    "    init_synapses[n_neurons // 3:2*n_neurons//3] = orthogonal2[np.newaxis, :]\n",
    "    init_synapses[2*n_neurons//3:] = orthogonal3[np.newaxis, :]\n",
    "    init_synapses += (rgen_meta.random(size=[n_neurons, n_components]) - 0.5) * 0.25\n",
    "\n",
    "# Initial background vector and initial nu values\n",
    "# Log-normal concentrations, nus are the logs of concentrations\n",
    "averages_nu = -0.5*np.ones(n_components)  # Average of log(c); for c < 1, these averages are < 0\n",
    "init_nu = averages_nu.copy()\n",
    "init_bkvec = np.exp(averages_nu*logof10).dot(back_components)\n",
    "# nus are first in the list of initial background params\n",
    "init_back_list = [init_nu, init_bkvec]\n",
    "\n",
    "## Compute the matrices in the Ornstein-Uhlenbeck update equation\n",
    "# Update matrix for the mean term: \n",
    "# Exponential decay with time scale tau_nu over time deltat\n",
    "tau_nu = 2.0  # Fluctuation time scale of the background nu_alphas (same for all)\n",
    "update_mat_A = np.identity(n_components)*np.exp(-deltat/tau_nu)\n",
    "\n",
    "# Steady-state covariance matrix\n",
    "sigma2 = 0.09\n",
    "correl_rho = 0.0\n",
    "steady_covmat = correl_rho * sigma2 * np.ones([n_components, n_components])  # Off-diagonals: rho\n",
    "steady_covmat[np.eye(n_components, dtype=bool)] = sigma2  # diagonal: ones\n",
    "\n",
    "# Mean and variance of the concentrations themselves\n",
    "# Using moments of log-normal: https://en.wikipedia.org/wiki/Log-normal_distribution\n",
    "mean_nu_lnbase = averages_nu.mean() * logof10\n",
    "vari_nu_lnbase = sigma2 * logof10**2\n",
    "lognorm_mean = np.exp(mean_nu_lnbase + vari_nu_lnbase/2.0)\n",
    "lognorm_vari = (np.exp(vari_nu_lnbase) - 1.0)*np.exp(2*mean_nu_lnbase + vari_nu_lnbase)\n",
    "# Third centered moment: rom skewness, multiply by its variance**3\n",
    "lognorm_skewness = (np.exp(vari_nu_lnbase) + 2)*np.sqrt(np.exp(vari_nu_lnbase) - 1)\n",
    "lognorm_thirdmom = lognorm_skewness * lognorm_vari**1.5\n",
    "\n",
    "# Cholesky decomposition of steady_covmat gives sqrt(tau/2) B\n",
    "# Update matrix for the noise term: \\sqrt(tau/2(1 - exp(-2*deltat/tau))) B\n",
    "psi_mat = np.linalg.cholesky(steady_covmat)\n",
    "update_mat_B = np.sqrt(1.0 - np.exp(-2.0*deltat/tau_nu)) * psi_mat\n",
    "\n",
    "back_params = [update_mat_A, update_mat_B, back_components, averages_nu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_synapses, update_ou_kinputs, init_back_list, ibcm_rates, \n",
    "# inhib_rates, back_params, duration, deltat, seed=seed_from_gen(rgen_meta), noisetype=\"normal\"\n",
    "#init_synapses = mser[-1]\n",
    "sim_results = integrate_inhib_ibcm_network_tanh(init_synapses, update_logou_kinputs, init_back_list, \n",
    "                    ibcm_rates, inhib_rates, back_params, duration, deltat, \n",
    "                    seed=seed_from_gen(rgen_meta), noisetype=\"normal\")\n",
    "# tseries, bk_series, bkvec_series, m_series, cbar_series, w_series, s_series\n",
    "tser, nuser, bkvecser, mser, cbarser, _, wser, sser = sim_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background statistics\n",
    "Useful figure for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All odors have the same statistics, flatten before taking histogram\n",
    "odor_concs_ser = np.exp((nuser+averages_nu[None, :])*logof10)\n",
    "odor_concs_histo, odor_concs_binseps = np.histogram(odor_concs_ser, bins=100, density=True)\n",
    "\n",
    "# Plot histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar((odor_concs_binseps[1:]+odor_concs_binseps[:-1])/2.0, odor_concs_histo, \n",
    "       width=np.diff(odor_concs_binseps), color=\"grey\")\n",
    "ax.set(xlabel=\"Odor concentration\", ylabel=\"Probability density\", yscale=\"log\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the synaptic weights against fixed points\n",
    "The analytical prediction neglecting correlations between $\\vec{m}$ and $\\nu$ is verified, provided that the time scales $\\tau_{\\nu}$ and $\\frac{1}{\\mu}$ are different enough. Computing corrections to account for incompletely separated time scales would be very hard, since the equation for $\\vec{m}$ is a multivariate, non-linear stochastic differential equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelfcts.ibcm_analytics import fixedpoint_thirdmoment_perturbtheory, fixedpoint_thirdmoment_exact\n",
    "from simulfcts.plotting import plot_cbars_gammas_sums, plot_cbars_gamma_series, plot_3d_series, plot_w_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cgammas_bar and mbars\n",
    "transient = 120000\n",
    "# Dot products \\bar{c}_{\\gamma} = \\bar{\\vec{m}} \\cdot \\vec{x}_{\\gamma}\n",
    "mbarser, c_gammas, cbars_gamma = compute_mbars_cgammas_cbargammas(mser, coupling_eta, back_components)\n",
    "# Compute analytical prediction for sum of cgammas and (cgamma squared)s. \n",
    "# Uses perturbation theory even though the third moment isn't exactly small\n",
    "res = fixedpoint_thirdmoment_perturbtheory(lognorm_mean, lognorm_vari, lognorm_thirdmom, \n",
    "                                           1, n_components-1, m3=1.0, order=1, lambd=lambd_ibcm)\n",
    "\n",
    "pred_cbars_gamma = res[:2]\n",
    "pred_sums_cbars = list(res[2:])\n",
    "# The function returns c_d, which is sum of c_gammas times average concentration\n",
    "pred_sums_cbars[0] = pred_sums_cbars[0] / lognorm_mean\n",
    "pred_sums_cbars = tuple(pred_sums_cbars)\n",
    "\n",
    "# Compare to the exact solution\n",
    "res = fixedpoint_thirdmoment_exact([lognorm_mean, lognorm_vari, lognorm_thirdmom], \n",
    "                                   1, n_components-1, lambd=lambd_ibcm)\n",
    "\n",
    "pred_cbars_gamma_exact = res[:2]\n",
    "pred_sums_cbars_exact = list(res[2:])\n",
    "# The function returns c_d, which is sum of c_gammas times average concentration\n",
    "pred_sums_cbars_exact[0] = pred_sums_cbars_exact[0] / lognorm_mean\n",
    "pred_sums_cbars_exact = tuple(pred_sums_cbars_exact)\n",
    "\n",
    "sums_cbars_gamma = np.sum(cbars_gamma, axis=2)\n",
    "sums_cbars_gamma2 = np.sum(cbars_gamma*cbars_gamma, axis=2)\n",
    "\n",
    "# Constaint 1: sum of c_gammas for each neuron, equal to 1 plus correction\n",
    "print(\"Comparison to analytical fixed points\")\n",
    "print(\"This should be approximately zeros:\", np.mean(sums_cbars_gamma[transient:], axis=0) / pred_sums_cbars[0] - 1.0)\n",
    "print(\"This should be all zeros, exact analytical solution:\", np.mean(sums_cbars_gamma[transient:], axis=0) / pred_sums_cbars_exact[0] - 1.0)\n",
    "# Constraint 2: sum of c_gammas^2 for each neuron, compared to 1/sigma^2 + correction\n",
    "print(\"This should be all approximately zeros:\", np.mean(sums_cbars_gamma2[transient:], axis=0) / pred_sums_cbars[1] - 1.0)\n",
    "print(\"This should be all zeros, exact analytical solution:\", np.mean(sums_cbars_gamma2[transient:], axis=0) / pred_sums_cbars_exact[1] - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_cbars_gammas_sums(tser, sums_cbars_gamma, sums_cbars_gamma2, skp=200, skp_lbl=1)\n",
    "axes[0].axhline(pred_sums_cbars[0], ls=\"--\", color=\"k\", label=r\"Perturb. $1 / \\langle \\nu \\rangle$\")\n",
    "axes[1].axhline(pred_sums_cbars[1], ls=\"--\", color=\"k\", label=r'Perturb. $1 / \\sigma^2$')\n",
    "axes[0].axhline(pred_sums_cbars_exact[0], ls=\"-.\", color=\"grey\", label=r\"Exact $1 / \\langle \\nu \\rangle$\")\n",
    "axes[1].axhline(pred_sums_cbars_exact[1], ls=\"-.\", color=\"grey\", label=r'Exact $1 / \\sigma^2$')\n",
    "for ax in axes:\n",
    "    ax.get_legend().set_visible(False)\n",
    "axes[0].legend(*[a[-2:] for a in axes[0].get_legend_handles_labels()])\n",
    "axes[1].legend(*[a[-2:] for a in axes[1].get_legend_handles_labels()])\n",
    "# fig.savefig(\"figures/three_odors/sum_cgammas_squared_lognormal_background.pdf\", transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprisingly good!\n",
    "fig, ax, _ = plot_cbars_gamma_series(tser, cbars_gamma, skp=100, transient=50000)\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "# Annotate with analytical prediction. Might fail because third moment is high. \n",
    "ax.axhline(pred_cbars_gamma[0], ls=\"--\", color=\"k\", label=r\"Perturbative $\\bar{c}_{\\gamma=\\mathrm{specific}}$\")  # higher value\n",
    "ax.axhline(pred_cbars_gamma[1], ls=\":\", color=\"k\", label=r\"Perturbative $\\bar{c}_{\\gamma=\\mathrm{non}}$\")  # lower value\n",
    "# Exact solution should align well nevertheless\n",
    "ax.axhline(pred_cbars_gamma_exact[0], ls=\"--\", color=\"grey\", label=r\"Exact $\\bar{c}_{\\gamma=\\mathrm{specific}}$\")  # higher value\n",
    "ax.axhline(pred_cbars_gamma_exact[1], ls=\":\", color=\"grey\", label=r\"Exact $\\bar{c}_{\\gamma=\\mathrm{non}}$\")  # lower value\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_3d_series(mbarser, dim_idx=[0, 1, 2], transient=10000, skp=1000)\n",
    "\n",
    "# Annotate with vectors representing the odor components\n",
    "orig = np.zeros([n_components, n_components])\n",
    "xlim, ylim, zlim = ax.get_xlim(), ax.get_ylim(), ax.get_zlim()\n",
    "scale = 3\n",
    "vecs = back_components.copy()\n",
    "for i in range(n_components):\n",
    "    vecs[i] = back_components[i] / np.sqrt(np.sum(back_components[i]**2)) * scale\n",
    "ax.quiver(*orig, *(vecs[:, :3].T), color=\"k\", lw=2.0)\n",
    "ax.view_init(azim=45, elev=30)\n",
    "ax.set(xlabel=r\"$\\overline{m}_1$\", ylabel=r\"$\\overline{m}_2$\", zlabel=r\"$\\overline{m}_3$\")\n",
    "# fig.savefig(\"figures/three_odors/points_fixes_ibcm_3_odeurs_lognormal.pdf\", transparent=True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of the inhibitory neurons' weights $\\vec{w}_i$\n",
    "Analytically, I find that, on average, $\\vec{w}_i$ converges to $\\vec{x}(\\pm \\sigma)$, i.e. to either input vector one standard deviation away from the mean input. So, here, I compare the numerical results for $\\vec{w}$ to the possible fixed points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the time course of the dot products -- not interesting with gaussian degeneracy\n",
    "# Unclear what it shows. \n",
    "fig, axes = plot_w_matrix(tser, wser, skp=500, lw=1.5)\n",
    "        \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background before and after inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulfcts.plotting import plot_background_norm_inhibition, plot_background_neurons_inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, bknorm_ser, snorm_ser = plot_background_norm_inhibition(tser, bkvecser, sser)\n",
    "\n",
    "# Compute noise reduction factor, annotate\n",
    "transient = 50000\n",
    "avg_bknorm = np.mean(bknorm_ser[transient:])\n",
    "avg_snorm = np.mean(snorm_ser[transient:])\n",
    "avg_reduction_factor = avg_snorm / avg_bknorm\n",
    "std_bknorm = np.std(bknorm_ser[transient:])\n",
    "std_snorm = np.std(snorm_ser[transient:])\n",
    "std_reduction_factor = std_snorm / std_bknorm\n",
    "\n",
    "print(\"Mean activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(avg_reduction_factor * 100))\n",
    "print(\"Standard deviation of activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(std_reduction_factor * 100))\n",
    "ax.annotate(\"St. dev. reduced to {:.1f} %\".format(std_reduction_factor * 100), \n",
    "           xy=(0.98, 0.98), xycoords=\"axes fraction\", ha=\"right\", va=\"top\")\n",
    "\n",
    "ax.legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.8))\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"figures/three_odors/inhibition_lognormal_background_norm_3odors.pdf\", \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes_mat, axes = plot_background_neurons_inhibition(tser, bkvecser, sser)\n",
    "axes[-1].legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.6), fontsize=8, handlelength=1.5)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"figures/three_odors/inhibition_lognormal_background_neurons_3odors.pdf\", \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3D plot of the original and inhibited odors, sampled sparsely in time\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Raw background\n",
    "skp = 1000\n",
    "tslice = slice(transient, None, skp)\n",
    "ax.scatter(bkvecser[tslice, 0], bkvecser[tslice, 1], bkvecser[tslice, 2], color=\"r\", label=\"Background\")\n",
    "# Compare to inhibition of the mean\n",
    "mean_inhibition = bkvecser - np.mean(bkvecser[transient:], axis=0)*inhib_rates[0]/sum(inhib_rates)\n",
    "ax.scatter(mean_inhibition[tslice, 0], mean_inhibition[tslice, 1], mean_inhibition[tslice, 2], \n",
    "           color=\"xkcd:light blue\", label=\"Average subtraction\")\n",
    "ax.scatter(sser[tslice, 0], sser[tslice, 1], sser[tslice, 2], \n",
    "           color=\"b\", label=\"IBCM inhibition\")\n",
    "ax.scatter(0, 0, 0, color=\"k\", s=200, alpha=1)\n",
    "ax.view_init(azim=160, elev=20)\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 0.85))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some results for re-plotting\n",
    "Use as a sample simulation of a log-normal background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"results/for_plots/\"\n",
    "#np.savez_compressed(results_dir + \"sample_lognormal_simulation.npz\", nuser=nuser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding correlation between odors\n",
    "Not sure what happens then. Analytical predictions fail for non-gaussian distributions. For gaussian, this amounts to a re-definition of $\\vec{x}_{\\gamma}$s, but extra third moment terms appear otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgen_meta_cr = np.random.default_rng(seed=0x91117e6a405e752c66db7f05127e03a6)\n",
    "#init_synapses = 0.1*rgen_meta.random(size=[n_neurons, n_dimensions])\n",
    "init_synapses_cr = 0.5*rgen_meta_cr.random(size=[n_neurons, n_components]).dot(back_components)\n",
    "\n",
    "# Steady-state covariance matrix\n",
    "sigma2_cr = 0.09\n",
    "correl_rho_cr = 0.5\n",
    "steady_covmat_cr = correl_rho_cr * sigma2_cr * np.ones([n_components, n_components])  # Off-diagonals: rho\n",
    "steady_covmat_cr[np.eye(n_components, dtype=bool)] = sigma2_cr  # diagonal: ones\n",
    "\n",
    "# Mean and variance of the concentrations themselves\n",
    "# Using moments of log-normal: https://en.wikipedia.org/wiki/Log-normal_distribution\n",
    "# Not sure what they are when correlated; TODO\n",
    "\n",
    "# Cholesky decomposition of steady_covmat gives sqrt(tau/2) B\n",
    "# Update matrix for the noise term: \\sqrt(tau/2(1 - exp(-2*deltat/tau))) B\n",
    "psi_mat_cr = np.linalg.cholesky(steady_covmat_cr)\n",
    "update_mat_B_cr = np.sqrt(1.0 - np.exp(-2.0*deltat/tau_nu)) * psi_mat_cr\n",
    "\n",
    "back_params_cr = [update_mat_A, update_mat_B_cr, back_components, averages_nu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_synapses, update_ou_kinputs, init_back_list, ibcm_rates, \n",
    "# inhib_rates, back_params, duration, deltat, seed=seed_from_gen(rgen_meta), noisetype=\"normal\"\n",
    "#init_synapses = mser[-1]\n",
    "sim_results = integrate_inhib_ibcm_network_tanh(init_synapses_cr, update_logou_kinputs, init_back_list, \n",
    "                    ibcm_rates, inhib_rates, back_params_cr, duration, deltat, \n",
    "                    seed=seed_from_gen(rgen_meta_cr), noisetype=\"normal\")\n",
    "# tseries, bk_series, bkvec_series, m_series, cbar_series, w_series, s_series\n",
    "tser_cr, nuser_cr, bkvecser_cr, mser_cr, cbarser_cr, _, wser_cr, sser_cr = sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations between odors\n",
    "# All odors have the same statistics, flatten before taking histogram\n",
    "odor_concs_ser_cr = np.exp((nuser_cr+averages_nu[None, :])*logof10)\n",
    "\n",
    "# Plot a time slice\n",
    "tslice = slice(0, 200, 1)\n",
    "fig, ax = plt.subplots()\n",
    "odor_colors = sns.color_palette(\"Greys\", n_colors=n_components)\n",
    "for i in range(n_components):\n",
    "    ax.plot(tser_cr[tslice], odor_concs_ser_cr[tslice, i], label=r\"$\\gamma = {}$\".format(i), \n",
    "            color=odor_colors[i])\n",
    "ax.set(xlabel=\"Time (steps)\", ylabel=\"Odor concentration\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cgammas_bar and mbars\n",
    "transient = 120000\n",
    "# Dot products \\bar{c}_{\\gamma} = \\bar{\\vec{m}} \\cdot \\vec{x}_{\\gamma}\n",
    "mbarser_cr, c_gammas_cr, cbars_gamma_cr = compute_mbars_cgammas_cbargammas(mser_cr, coupling_eta, back_components)\n",
    "\n",
    "# Analytical predictions already computed, not assuming correlations \n",
    "# change anything -- to see how wrong it is to suppose that\n",
    "sums_cbars_gamma_cr = np.sum(cbars_gamma_cr, axis=2)\n",
    "sums_cbars_gamma2_cr = np.sum(cbars_gamma_cr**2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The analytical prediction is quantitatively off, but the principle holds\n",
    "# Each neuron becomes specific to one $\\vec{x}_{\\gamma}$, non-specific to others. \n",
    "fig, ax, _ = plot_cbars_gamma_series(tser_cr, cbars_gamma_cr, skp=100, transient=50000)\n",
    "ax.get_legend().set_visible(False)\n",
    "\n",
    "# Annotate with analytical prediction. Might fail because third moment is high. \n",
    "ax.axhline(pred_cbars_gamma[0], ls=\"--\", color=\"k\", label=r\"Analytic $\\bar{c}_{\\gamma=\\mathrm{specific}}$\")  # higher value\n",
    "ax.axhline(pred_cbars_gamma[1], ls=\":\", color=\"grey\", label=r\"Analytic $\\bar{c}_{\\gamma=\\mathrm{non-specif}}$\")  # lower value\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
