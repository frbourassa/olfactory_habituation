{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W stability in turbulent odor backgrounds\n",
    "Look at a 6-odor case, use a large $\\Lambda$ scale in the IBCM model or the PCA model that just makes the W numerical integration blow up, and check whether this is reflected by the stability anaysis of either the Euler integrator or the equation's fixed point itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from time import perf_counter\n",
    "import os, json\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from modelfcts.ibcm import (\n",
    "    integrate_inhib_ibcm_network_options,\n",
    "    compute_mbars_cgammas_cbargammas\n",
    ")\n",
    "from modelfcts.ibcm_analytics import (\n",
    "    fixedpoint_thirdmoment_exact, \n",
    "    fixedpoint_thirdmoment_perturbtheory,\n",
    "    ibcm_fixedpoint_w_thirdmoment, \n",
    "    ibcm_all_largest_eigenvalues\n",
    ")\n",
    "from modelfcts.biopca import (\n",
    "    integrate_inhib_ifpsp_network_skip,\n",
    "    build_lambda_matrix,\n",
    "    biopca_respond_new_odors\n",
    ")\n",
    "from modelfcts.ideal import (\n",
    "    find_projector, \n",
    "    find_parallel_component, \n",
    "    ideal_linear_inhibitor, \n",
    "    compute_ideal_factor\n",
    ")\n",
    "from modelfcts.checktools import (\n",
    "    check_conc_samples_powerlaw_exp1,\n",
    "    compute_pca_meankept, \n",
    "    compute_projector_series, \n",
    "    analyze_pca_learning, \n",
    "    jacobian_row_wmat_l2_avgstats,\n",
    "    stability_row_wmat_l2_instant\n",
    ")\n",
    "from modelfcts.backgrounds import (\n",
    "    update_powerlaw_times_concs, \n",
    "    logof10, \n",
    "    sample_background_powerlaw,\n",
    "    sample_ss_conc_powerlaw, \n",
    "    decompose_nonorthogonal_basis, \n",
    "    update_alternating_inputs, \n",
    "    generate_odorant\n",
    ")\n",
    "from utils.statistics import seed_from_gen\n",
    "from modelfcts.distribs import (\n",
    "    truncexp1_inverse_transform, \n",
    "    truncexp1_density, \n",
    "    truncexp1_average,\n",
    "    powerlaw_cutoff_inverse_transform\n",
    ")\n",
    "from simulfcts.plotting import (\n",
    "    plot_cbars_gammas_sums, \n",
    "    plot_cbars_gamma_series, \n",
    "    plot_3d_series, \n",
    "    plot_w_matrix, \n",
    "    plot_background_norm_inhibition, \n",
    "    plot_background_neurons_inhibition, \n",
    "    plot_pca_results, \n",
    "    hist_outline\n",
    ")\n",
    "from simulfcts.analysis import compute_back_reduction_stats\n",
    "from utils.metrics import jaccard, l1_norm, l2_norm, linf_norm, cosine_dist\n",
    "from utils.smoothing_function import moving_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.style.use(['dark_background'])\n",
    "plt.rcParams[\"figure.figsize\"] = (4.5, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"ibcm\", \"biopca\", \"avgsub\", \"ideal\", \"orthogonal\", \"none\"]\n",
    "model_nice_names = {\n",
    "    \"ibcm\": \"IBCM\",\n",
    "    \"biopca\": \"BioPCA\",\n",
    "    \"avgsub\": \"Average\",\n",
    "    \"ideal\": \"Ideal\",\n",
    "    \"orthogonal\": \"Orthogonal\",\n",
    "    \"none\": \"None\"\n",
    "}\n",
    "model_colors = {\n",
    "    \"ibcm\": \"xkcd:turquoise\",\n",
    "    \"biopca\": \"xkcd:orangey brown\",\n",
    "    \"avgsub\": \"xkcd:navy blue\",\n",
    "    \"ideal\": \"xkcd:powder blue\",\n",
    "    \"orthogonal\": \"xkcd:pale rose\",\n",
    "    \"none\": \"grey\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize common simulation parameters\n",
    "n_dimensions = 25  # Half the real number for faster simulations\n",
    "n_components = 6  # Number of background odors\n",
    "\n",
    "inhib_rates = [0.0001, 0.00002]  # alpha, beta  [0.00025, 0.00005]\n",
    "\n",
    "# Simulation duration\n",
    "duration = 360000.0\n",
    "deltat = 1.0\n",
    "n_chunks = 10\n",
    "skp = 1 * int(1.0 / deltat)\n",
    "\n",
    "# Common model options\n",
    "activ_function = \"identity\"  #\"ReLU\"\n",
    "\n",
    "# Background process\n",
    "update_fct = update_powerlaw_times_concs\n",
    "\n",
    "# Choose randomly generated background vectors\n",
    "rgen_meta = np.random.default_rng(seed=0x8896ce0154295ba29df7e93dc277af2d)\n",
    "#rgen_meta = np.random.default_rng(seed=0x85dfce01542492a29df7e93dc277ad2d)\n",
    "back_components = np.zeros([n_components, n_dimensions])\n",
    "for i in range(n_components):\n",
    "    back_components[i] = generate_odorant(n_dimensions, rgen_meta, lambda_in=0.1)\n",
    "back_components = back_components / l2_norm(back_components).reshape(-1, 1)\n",
    "\n",
    "# Seed for background simulation, to make sure all models are the same\n",
    "simul_seed = seed_from_gen(rgen_meta)\n",
    "\n",
    "# Turbulent background parameters: same rates and constants for all odors\n",
    "back_params = [\n",
    "    np.asarray([1.0] * n_components),        # whiff_tmins\n",
    "    np.asarray([500.] * n_components),       # whiff_tmaxs\n",
    "    np.asarray([1.0] * n_components),        # blank_tmins\n",
    "    np.asarray([800.0] * n_components),      # blank_tmaxs\n",
    "    np.asarray([0.6] * n_components),        # c0s\n",
    "    np.asarray([0.5] * n_components),        # alphas\n",
    "]\n",
    "back_params.append(back_components)\n",
    "\n",
    "# Initial values of background process variables (t, c for each variable)\n",
    "init_concs = sample_ss_conc_powerlaw(*back_params[:-1], size=1, rgen=rgen_meta)\n",
    "init_times = powerlaw_cutoff_inverse_transform(\n",
    "                rgen_meta.random(size=n_components), *back_params[2:4])\n",
    "tc_init = np.stack([init_times, init_concs.squeeze()], axis=1)\n",
    "\n",
    "# Initial background vector \n",
    "init_bkvec = tc_init[:, 1].dot(back_components)\n",
    "# nus are first in the list of initial background params\n",
    "init_back_list = [tc_init, init_bkvec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise similarity between background odors\n",
    "Determines how well-posed the PCA is and how easy it is for the IBCM model to disentangle odors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBCM habituation\n",
    "### IBCM simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBCM model parameters\n",
    "n_i_ibcm = 24  # Number of inhibitory neurons for IBCM case\n",
    "\n",
    "# Model rates\n",
    "learnrate_ibcm = 0.00125  #5e-5\n",
    "tau_avg_ibcm = 1600  # 2000\n",
    "coupling_eta_ibcm = 0.6/n_i_ibcm\n",
    "ssat_ibcm = 50.0\n",
    "k_c2bar_avg = 0.1\n",
    "decay_relative_ibcm = 0.005\n",
    "lambd_ibcm = 3.0\n",
    "ibcm_rates = [\n",
    "    learnrate_ibcm, \n",
    "    tau_avg_ibcm, \n",
    "    coupling_eta_ibcm, \n",
    "    lambd_ibcm,\n",
    "    ssat_ibcm, \n",
    "    k_c2bar_avg,\n",
    "    decay_relative_ibcm \n",
    "]\n",
    "ibcm_options = {\n",
    "    \"activ_fct\": activ_function, \n",
    "    \"saturation\": \"tanh\", \n",
    "    \"variant\": \"law\", \n",
    "    \"decay\": True\n",
    "}\n",
    "\n",
    "# Initial synaptic weights: small positive noise\n",
    "init_synapses_ibcm = 0.3*rgen_meta.standard_normal(size=[n_i_ibcm, n_dimensions])*lambd_ibcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompute_theta_series(cbser, tau, dt):\n",
    "    theta = np.zeros([cbser.shape[0], cbser.shape[1]])\n",
    "    theta[0] = cbser[0]**2\n",
    "    for i in range(cbser.shape[0]-1):\n",
    "        theta[i+1] = theta[i] + dt/tau*(cbser[i]*cbser[i] - theta[i])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the IBCM simulations\n",
    "# Perform successive shorter runs/restarts for memory efficiency\n",
    "tser_ibcm = []\n",
    "nuser_ibcm = []\n",
    "bkvecser_ibcm = []\n",
    "mser_ibcm = []\n",
    "cbarser_ibcm = []\n",
    "wser_ibcm = []\n",
    "yser_ibcm = []\n",
    "thetaser_ibcm = []\n",
    "if n_chunks > 1:\n",
    "    seed_spawns = np.random.SeedSequence(simul_seed).spawn(10)\n",
    "else:\n",
    "    seed_spawns = [simul_seed]\n",
    "for i in range(n_chunks):\n",
    "    tstart = perf_counter()\n",
    "    if i == 0:\n",
    "        init_vari = init_synapses_ibcm\n",
    "        init_back = init_back_list\n",
    "    else:\n",
    "        init_vari = [mser_ibcm[i-1][-1], thetaser_ibcm[i-1][-1], wser_ibcm[i-1][-1]]\n",
    "        init_back = [nuser_ibcm[i-1][-1], bkvecser_ibcm[i-1][-1]]\n",
    "    sim_results = integrate_inhib_ibcm_network_options(\n",
    "                init_vari, update_fct, init_back, \n",
    "                ibcm_rates, inhib_rates, back_params, duration/n_chunks, \n",
    "                deltat, seed=seed_spawns[i], noisetype=\"uniform\",  \n",
    "                skp=skp, **ibcm_options\n",
    "    )\n",
    "    tser_ibcm.append(sim_results[0] + i/n_chunks*duration)\n",
    "    nuser_ibcm.append(sim_results[1])\n",
    "    bkvecser_ibcm.append(sim_results[2])\n",
    "    mser_ibcm.append(sim_results[3]) \n",
    "    cbarser_ibcm.append(sim_results[4]) \n",
    "    thetaser_ibcm.append(sim_results[5])\n",
    "    wser_ibcm.append(sim_results[6])\n",
    "    yser_ibcm.append(sim_results[7])\n",
    "    tend = perf_counter()\n",
    "    print(\"Finished chunk\", i, \"in {:.2f} s\".format(tend - tstart))\n",
    "\n",
    "# Concatenate\n",
    "tser_ibcm = np.concatenate(tser_ibcm, axis=0)\n",
    "nuser_ibcm = np.concatenate(nuser_ibcm)\n",
    "bkvecser_ibcm = np.concatenate(bkvecser_ibcm)\n",
    "mser_ibcm = np.concatenate(mser_ibcm)\n",
    "cbarser_ibcm = np.concatenate(cbarser_ibcm)\n",
    "thetaser_ibcm = np.concatenate(thetaser_ibcm)\n",
    "wser_ibcm = np.concatenate(wser_ibcm)\n",
    "yser_ibcm = np.concatenate(yser_ibcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBCM habituation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cgammas_bar and mbars\n",
    "transient = int(5/6*duration / deltat) // skp\n",
    "# Dot products \\bar{c}_{\\gamma} = \\bar{\\vec{m}} \\cdot \\vec{x}_{\\gamma}\n",
    "mbarser, c_gammas, cbars_gamma = compute_mbars_cgammas_cbargammas(\n",
    "                                    mser_ibcm, coupling_eta_ibcm, back_components)\n",
    "sums_cbars_gamma = np.sum(cbars_gamma, axis=2)\n",
    "sums_cbars_gamma2 = np.sum(cbars_gamma*cbars_gamma, axis=2)\n",
    "\n",
    "# Analytical prediction, exact: need moments of nu. Easiest to compute numerically. \n",
    "conc_ser = nuser_ibcm[:, :, 1]\n",
    "# Odors are all iid so we can average over all odors\n",
    "mean_conc = np.mean(conc_ser)\n",
    "sigma2_conc = np.var(conc_ser)\n",
    "thirdmom_conc = np.mean((conc_ser - mean_conc)**3)\n",
    "moments_conc = [mean_conc, sigma2_conc, thirdmom_conc]\n",
    "\n",
    "# Analytical prediction\n",
    "res = fixedpoint_thirdmoment_exact(moments_conc, 1, n_components-1, lambd=lambd_ibcm)\n",
    "c_specif, c_nonspecif = res[:2]\n",
    "cs_cn = res[:2]\n",
    "\n",
    "# Count how many dot products are at each possible value. Use cbar = 1.0 as a split. \n",
    "split_val = 2.0 * lambd_ibcm\n",
    "cbars_gamma_mean = np.mean(cbars_gamma[transient:], axis=0)\n",
    "cgammas_bar_counts = {\"above\": int(np.sum(cbars_gamma_mean.flatten() > split_val)), \n",
    "                      \"below\": int(np.sum(cbars_gamma_mean.flatten() <= split_val))}\n",
    "print(cgammas_bar_counts)\n",
    "\n",
    "specif_gammas = np.argmax(np.mean(cbars_gamma[transient:], axis=0), axis=1)\n",
    "print(specif_gammas)\n",
    "\n",
    "# Analytical W\n",
    "analytical_w = ibcm_fixedpoint_w_thirdmoment(inhib_rates, moments_conc, back_components, cs_cn, specif_gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.plot(tser_ibcm[:300], nuser_ibcm[:300, :, 1])\n",
    "neurons_cmap = sns.color_palette(\"Greys\", n_colors=n_i_ibcm)\n",
    "for i in range(n_i_ibcm):\n",
    "    ax.plot(tser_ibcm/1000, thetaser_ibcm[:, i], lw=0.5, color=neurons_cmap[i])\n",
    "ax.set(xlabel=\"Time (x1000 steps)\", ylabel=r\"$\\bar{\\Theta} = \\bar{c}^2$ moving average\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax, _ = plot_cbars_gamma_series(tser_ibcm, cbars_gamma, \n",
    "                        skp=20, transient=320000 // skp)\n",
    "# Compare to exact analytical fixed point solution\n",
    "#ax.set_xlim([350, 360])\n",
    "ax.axhline(c_specif, ls=\"--\", color=\"grey\", \n",
    "           label=r\"Analytical $\\bar{c}_{\\gamma=\\mathrm{specific}}$\")\n",
    "ax.axhline(c_nonspecif, ls=\"--\", color=\"grey\", \n",
    "           label=r\"Analytical $\\bar{c}_{\\gamma=\\mathrm{non}}$\")\n",
    "fig.tight_layout()\n",
    "leg = ax.legend(loc=\"upper left\", bbox_to_anchor=(1., 1.))\n",
    "\n",
    "#fig.savefig(\"figures/powerlaw/cbargammas_series_turbulent_background_example.pdf\", \n",
    "#            transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(leg,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between nu's and c's, see if some neurons are specific to odors\n",
    "# Each neuron turns out to correlate its response to  one concentration\n",
    "# that means it is specific to that odor. \n",
    "cbarser_norm_centered = cbarser_ibcm - np.mean(cbarser_ibcm[transient:], axis=0)\n",
    "conc_ser_centered = (nuser_ibcm[:, :, 1] \n",
    "                     - np.mean(nuser_ibcm[transient:, :, 1], axis=0))\n",
    "correl_c_nu = np.mean(cbarser_norm_centered[transient:, :, None] \n",
    "                      * conc_ser_centered[transient:, None, :], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(correl_c_nu.T)\n",
    "ax.set(ylabel=r\"Component $\\gamma$\", xlabel=r\"Neuron $i$\")\n",
    "fig.colorbar(img, label=r\"$\\langle (\\bar{c}^i - \\langle \\bar{c}^i \\rangle)\"\n",
    "             r\"(\\nu_{\\gamma} - \\langle \\nu_{\\gamma} \\rangle) \\rangle$\", \n",
    "            location=\"top\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Check if each component has at least one neuron\n",
    "for comp in range(n_components):\n",
    "    print(\"Number of neurons specific to component {}: {}\".format(\n",
    "            comp, np.sum(np.mean(cbars_gamma[-2000:, :, comp], axis=0) > split_val*1.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, bknorm_ser, ynorm_ser = plot_background_norm_inhibition(\n",
    "                                tser_ibcm, bkvecser_ibcm, yser_ibcm, skp=1)\n",
    "\n",
    "# Compute noise reduction factor, annotate\n",
    "transient = 100000 // skp\n",
    "norm_stats = compute_back_reduction_stats(bknorm_ser, ynorm_ser, trans=transient)\n",
    "\n",
    "print(\"Mean activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(norm_stats['avg_reduction'] * 100))\n",
    "print(\"Standard deviation of activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(norm_stats['std_reduction'] * 100))\n",
    "ax.annotate(\"St. dev. reduced to {:.1f} %\".format(norm_stats['std_reduction'] * 100), \n",
    "           xy=(0.98, 0.98), xycoords=\"axes fraction\", ha=\"right\", va=\"top\")\n",
    "\n",
    "ax.legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.8))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_w_matrix(tser_ibcm, wser_ibcm, skp=100)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability of average fixed points\n",
    "Check the eigenvalues of the jacobian for one neuron, for every possible specificity. There are $2^{n_B}$ possibilities: choosing specific or not for each odor. \n",
    "\n",
    "Also check the stability of the W matrix equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_max_eigenvalues = ibcm_all_largest_eigenvalues(\n",
    "    moments_conc, ibcm_rates, back_components, m3=1.0, cut=1e-16, options=ibcm_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ibcm_specif_keys = list(all_max_eigenvalues.keys())\n",
    "ibcm_eig_values = np.asarray([all_max_eigenvalues[a] for a in ibcm_specif_keys])\n",
    "reals, imags = np.real(ibcm_eig_values), np.imag(ibcm_eig_values)\n",
    "ibcm_eig_values_specif1 = np.asarray([len(s) == 1 for s in ibcm_specif_keys], dtype=bool)\n",
    "highlights = ibcm_eig_values_specif1\n",
    "ax.axvline(0.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "ax.axhline(0.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "scaleup = 1e3\n",
    "ax.plot(reals[~highlights]*scaleup, imags[~highlights]*scaleup, marker=\"o\", mfc=\"k\", mec=\"k\", \n",
    "       ls=\"none\", label=\"0 or 2+ odors\", ms=6)\n",
    "ax.plot(reals[highlights]*scaleup, imags[highlights]*scaleup, marker=\"*\", mfc=\"b\", mec=\"b\", \n",
    "        ls=\"none\", label=\"One odor\", ms=8)\n",
    "for side in (\"top\", \"right\"):\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.legend(title=\"Specificity\")\n",
    "ax.set(xlabel=r\"$\\mathrm{Re}(\\lambda_{\\mathrm{max}})$    ($\\times 10^{-3}$)\", \n",
    "      ylabel=r\"$\\mathrm{Im}(\\lambda_{\\mathrm{max}})$     ($\\times 10^{-3}$)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand what happens when $W$ blows up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the fixed point stability for W.\n",
    "# Use analytical cgammas assigned based on the neurons' specificities in this simulation\n",
    "cgammas_mat = np.full([n_i_ibcm, n_components], fill_value=c_nonspecif)\n",
    "cgammas_mat[np.arange(n_i_ibcm), specif_gammas] = c_specif\n",
    "jac_w = jacobian_row_wmat_l2_avgstats(cgammas_mat, moments_conc[:2], inhib_rates)\n",
    "jac_w_eigvals = np.linalg.eigvalsh(jac_w)\n",
    "if np.all(np.real(jac_w_eigvals) < 0):\n",
    "    print(\"W fixed point is stable, jacobian eigenvalues all negative\")\n",
    "    print(\"Largest eigenvalue:\", jac_w_eigvals.max())\n",
    "    print(\"Smallest eigenvalue:\", jac_w_eigvals.min())\n",
    "else:\n",
    "    print(\"W fixed point unstable, some eigenvalues positive\")\n",
    "    print(\"All eigenvalues:\", jac_w_eigvals[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a blowup instance\n",
    "idx_blow = np.argmax(wser_ibcm[:, 0, 0] > 1e2)\n",
    "if idx_blow > 0:\n",
    "    t_blow = tser_ibcm[idx_blow]\n",
    "    print(\"Blow-up detected at time\", t_blow, \", index\", idx_blow, \n",
    "          \"for Lambda = {}\".format(lambd_ibcm))\n",
    "\n",
    "    # Compute the numerical stability at that point\n",
    "    euler_eigvals = stability_row_wmat_l2_instant(cbarser_ibcm[idx_blow], inhib_rates, deltat)\n",
    "    print(\"Euler eigenvalues then:\", euler_eigvals)\n",
    "    \n",
    "    # Plot the w time series then\n",
    "    fig, ax = plt.subplots()\n",
    "    slic = slice(idx_blow-20, idx_blow+20, 1)\n",
    "    ax.plot(tser_ibcm[slic], wser_ibcm[slic, 0, 0], marker=\"o\")\n",
    "    ax.set(xlabel=\"Time (steps)\", ylabel=r\"$W_{00}$\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    if np.any(np.abs(euler_eigvals) > 1.0):\n",
    "        print(\"Conclusion: this is a numerical instability of the Euler integrator\")\n",
    "    else:\n",
    "        print(\"Cannot identify the reason of this instability\")\n",
    "\n",
    "else:\n",
    "    print(\"No blowup found for Lambda = {}\".format(lambd_ibcm))\n",
    "    # Compute Euler eigenvalues over time, at different steps, check if they\n",
    "    # ever go below -1 or above 1. \n",
    "    largest_abs_eigval_ser = []\n",
    "    smallest_abs_eigval_ser = []\n",
    "    ev_skp = 1\n",
    "    for i in range(0, tser_ibcm.shape[0], ev_skp):\n",
    "        euler_eigvals = stability_row_wmat_l2_instant(cbarser_ibcm[i], inhib_rates, deltat)\n",
    "        largest_abs_eigval_ser.append(np.abs(euler_eigvals).max())\n",
    "        smallest_abs_eigval_ser.append(abs(euler_eigvals[0]))\n",
    "    largest_abs_eigval_ser = np.asarray(largest_abs_eigval_ser)\n",
    "    problematic_points = (largest_abs_eigval_ser > 1.0)\n",
    "    if not np.any(problematic_points):\n",
    "        print(\"Confirmed by the stability analysis: no time where an eigenvalue \"\n",
    "              + \"has a magnitude > 1\")\n",
    "    else:\n",
    "        print(\"This is despite having found an eigenvalue > 1, see plot below\")\n",
    "    # Plotting to confirm\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(tser_ibcm[::ev_skp]/1000.0, largest_abs_eigval_ser, label=\"Largest\")\n",
    "    ax.plot(np.arange(0.0, duration, deltat*ev_skp)[problematic_points]/1000.0, \n",
    "            largest_abs_eigval_ser[problematic_points], \"ro\", label=\"Problem (if any)\")\n",
    "    #ax.plot(tser_ibcm[::100]/1000.0, smallest_abs_eigval_ser, label=\"Smallest\")\n",
    "    ax.legend()\n",
    "    ax.set(xlabel=\"Time (x1000 steps)\", ylabel=\"Euler eigenvalues magnitude\")\n",
    "    ax.axhline(1.0, ls=\"--\", color=\"grey\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximal Lambda for stability: we need dt*(beta + alpha Lambda**2 csat**2) < 2\n",
    "# to ensure eigenvalue magnitude < 1\n",
    "lambda_max = np.sqrt((2.0 / deltat - inhib_rates[1])/(inhib_rates[0]*ssat_ibcm**2))\n",
    "print(\"Largest safe Lambda for IBCM:\", lambda_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioPCA simulation\n",
    "### BioPCA habituation simulation\n",
    "\n",
    "Also try to choose a $\\Lambda$ which creates blow-ups in $W$. \n",
    "\n",
    "Note that in the PCA model, as in IBCM, it is entirely $M$ which is scaled by $\\Lambda$. The matrix $L' = L^{-1}$, which is returned by my integration function, has the PCA's principal values on its diagonal, irrespective of $\\Lambda$. Meanwhile, $M$ is scaled with $\\Lambda$ and $L'$, so $\\Lambda^{-1} L'^{-1}M = U$, the matrix of orthonormal eigenvectors from the PCA (vectors are the rows of $U$), while the projector $LM$ still has scale $\\Lambda_i$ for the eigenvector in row $i$.\n",
    "\n",
    "In BioPCA, $\\vec{\\overline{c}} = LM \\vec{x}$, so it also has scale $\\Lambda$ in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioPCA model parameters\n",
    "n_i_pca = n_components  # Number of inhibitory neurons for BioPCA case\n",
    "\n",
    "# Model rates\n",
    "learnrate_pca = 1e-4  # Learning rate of M\n",
    "# Choose Lambda diagonal matrix as advised in Minden et al., 2018\n",
    "# but scale it up to counteract W regularization\n",
    "lambda_range_pca = 0.5\n",
    "lambda_max_pca = 40.0\n",
    "# Learning rate of L, relative to learnrate. Adjusted to Lambda in the integration function\n",
    "rel_lrate_pca = 2.0  #  / lambda_max_pca**2 \n",
    "lambda_mat_diag = build_lambda_matrix(lambda_max_pca, lambda_range_pca, n_i_pca)\n",
    "\n",
    "xavg_rate_pca = learnrate_pca\n",
    "pca_options = {\n",
    "    \"activ_fct\": activ_function, \n",
    "    \"remove_lambda\": False, \n",
    "    \"remove_mean\": True\n",
    "}\n",
    "biopca_rates = [learnrate_pca, rel_lrate_pca, lambda_max_pca, lambda_range_pca, xavg_rate_pca]\n",
    "\n",
    "\n",
    "# Initial synaptic weights: small positive noise\n",
    "rgen_pca = np.random.default_rng(seed=0x8b6664612cfeda4a121436fcfbbca449)\n",
    "init_synapses_pca = rgen_pca.standard_normal(size=[n_i_pca, n_dimensions]) / np.sqrt(n_i_pca)\n",
    "init_mmat_pca = rgen_pca.standard_normal(size=[n_i_pca, n_dimensions]) / np.sqrt(n_dimensions)\n",
    "init_lmat_pca = np.eye(n_i_pca, n_i_pca)  # Supposed to be near-identity, start as identity\n",
    "ml_inits_pca = [init_mmat_pca, init_lmat_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "sim_results = integrate_inhib_ifpsp_network_skip(\n",
    "                ml_inits_pca, update_fct, init_back_list, biopca_rates, \n",
    "                inhib_rates, back_params, duration, deltat, \n",
    "                seed=simul_seed, noisetype=\"uniform\", skp=skp, **pca_options)\n",
    "(tser_pca, \n",
    " nuser_pca, \n",
    " bkvecser_pca, \n",
    " mser_pca, \n",
    " lser_pca, \n",
    " xser_pca, \n",
    " cbarser_pca, \n",
    " wser_pca, \n",
    " yser_pca) = sim_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioPCA simulation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = analyze_pca_learning(bkvecser_pca, mser_pca, lser_pca, \n",
    "                           lambda_mat_diag, demean=pca_options[\"remove_mean\"])\n",
    "true_pca, learnt_pca, fser, off_diag_l_avg_abs, align_error_ser = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.statistics import principal_component_analysis\n",
    "from modelfcts.checktools import compute_pca_meankept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_pca_results(tser_pca/1000, true_pca, learnt_pca, align_error_ser, \n",
    "                             off_diag_l_avg_abs, skp=20)\n",
    "axes[-1].set_xlabel(\"Time (x1000 steps)\")\n",
    "fig.set_size_inches(fig.get_size_inches()[0], 3*2.5)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, bknorm_ser, ynorm_ser = plot_background_norm_inhibition(\n",
    "                                tser_pca, bkvecser_pca, yser_pca, skp=10)\n",
    "\n",
    "# Compute noise reduction factor, annotate\n",
    "transient = 100000 // skp\n",
    "norm_stats = compute_back_reduction_stats(bknorm_ser, ynorm_ser, trans=transient)\n",
    "\n",
    "print(\"Mean activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(norm_stats['avg_reduction'] * 100))\n",
    "print(\"Standard deviation of activity norm reduced to \"\n",
    "      + \"{:.1f} % of input\".format(norm_stats['std_reduction'] * 100))\n",
    "ax.annotate(\"St. dev. reduced to {:.1f} %\".format(norm_stats['std_reduction'] * 100), \n",
    "           xy=(0.98, 0.98), xycoords=\"axes fraction\", ha=\"right\", va=\"top\")\n",
    "\n",
    "ax.legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.8))\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, _ = plot_background_neurons_inhibition(tser_pca, bkvecser_pca, yser_pca, skp=10)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_w_matrix(tser_pca, wser_pca, skp=10)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for W blowups in the PCA simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the stability of the W fixed point by\n",
    "# computing the c_gammas matrix from the simulation\n",
    "projmean_pca = np.mean(fser[:transient*2], axis=0)\n",
    "cgammas_pca = projmean_pca.dot(back_components.T)\n",
    "\n",
    "jac_w = jacobian_row_wmat_l2_avgstats(cgammas_pca, moments_conc[:2], inhib_rates)\n",
    "jac_w_eigvals = np.linalg.eigvalsh(jac_w)\n",
    "if np.all(np.real(jac_w_eigvals) < 0):\n",
    "    print(\"W fixed point is stable, jacobian eigenvalues all negative\")\n",
    "    print(\"Largest eigenvalue:\", jac_w_eigvals.max())\n",
    "    print(\"Smallest eigenvalue:\", jac_w_eigvals.min())\n",
    "else:\n",
    "    print(\"W fixed point unstable, some eigenvalues positive\")\n",
    "    print(\"All eigenvalues:\", jac_w_eigvals[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a blowup instance\n",
    "idx_blow = np.argmax(wser_pca[:, 0, 0] > 1e2)\n",
    "if idx_blow > 0:\n",
    "    t_blow = tser_pca[idx_blow]\n",
    "    print(\"Blow-up detected at time\", t_blow, \", index\", idx_blow, \n",
    "          \"for Lambda = {}\".format(lambda_max_pca))\n",
    "\n",
    "    # Compute the numerical stability at that point\n",
    "    euler_eigvals = stability_row_wmat_l2_instant(cbarser_pca[idx_blow], inhib_rates, deltat)\n",
    "    print(\"Euler eigenvalues then:\", euler_eigvals)\n",
    "    \n",
    "    # Plot the w time series then\n",
    "    fig, ax = plt.subplots()\n",
    "    slic = slice(idx_blow-20, idx_blow+20, 1)\n",
    "    ax.plot(tser_pca[slic], wser_pca[slic, 0, 0], marker=\"o\")\n",
    "    ax.set(xlabel=\"Time (steps)\", ylabel=r\"$W_{00}$\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    if np.any(np.abs(euler_eigvals) > 1.0):\n",
    "        print(\"Conclusion: this is a numerical instability of the Euler integrator\")\n",
    "    else:\n",
    "        print(\"Cannot identify the reason of this instability\")\n",
    "\n",
    "else:\n",
    "    print(\"No blowup found for Lambda = {}\".format(lambda_max_pca))\n",
    "    # Compute Euler eigenvalues over time, at different steps, check if they\n",
    "    # ever go below -1 or above 1. \n",
    "    largest_abs_eigval_ser = []\n",
    "    smallest_abs_eigval_ser = []\n",
    "    ev_skp = 1\n",
    "    for i in range(0, tser_pca.shape[0], ev_skp):\n",
    "        euler_eigvals = stability_row_wmat_l2_instant(cbarser_pca[i], inhib_rates, deltat)\n",
    "        largest_abs_eigval_ser.append(np.abs(euler_eigvals).max())\n",
    "        smallest_abs_eigval_ser.append(abs(euler_eigvals[0]))\n",
    "    largest_abs_eigval_ser = np.asarray(largest_abs_eigval_ser)\n",
    "    problematic_points = (largest_abs_eigval_ser > 1.0)\n",
    "    if not np.any(problematic_points):\n",
    "        print(\"Confirmed by the stability analysis: no time where an eigenvalue \"\n",
    "              + \"has a magnitude > 1\")\n",
    "    else:\n",
    "        print(\"This is despite having found an eigenvalue > 1, see plot below\")\n",
    "    # Plotting to confirm\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(tser_pca[::ev_skp]/1000.0, largest_abs_eigval_ser, label=\"Largest\")\n",
    "    ax.plot(np.arange(0.0, duration, deltat*ev_skp)[problematic_points]/1000.0, \n",
    "            largest_abs_eigval_ser[problematic_points], \"ro\", label=\"Problem (if any)\")\n",
    "    #ax.plot(tser_pca[::100]/1000.0, smallest_abs_eigval_ser, label=\"Smallest\")\n",
    "    ax.legend()\n",
    "    ax.set(xlabel=\"Time (x1000 steps)\", ylabel=\"Euler eigenvalues magnitude\")\n",
    "    ax.axhline(1.0, ls=\"--\", color=\"grey\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximal Lambda for PCA stability: we need dt*(beta + alpha Lambda**2 c_norm**2) < 2\n",
    "# to ensure eigenvalue magnitude < 1\n",
    "# For the typical norm of Lambda*c, use the average norm of the\n",
    "# PCA simulation's largest c value, c = LMx\n",
    "# divided by PCA's Lambda scale to recover the default scale for Lambda=1\n",
    "# Smooth out over a few steps to identify really unstable bouts that would diverge, \n",
    "# not a single step where maybe the accuracy is bad but not long enough. \n",
    "mean_cbar_pca_norm = np.max(moving_average(cbarser_pca, 9) / lambda_mat_diag)\n",
    "lambda_max_pca_stable = np.sqrt((2.0 / deltat - inhib_rates[1]) \n",
    "                         / (inhib_rates[0]*mean_cbar_pca_norm**2))\n",
    "print(\"Largest safe Lambda for PCA:\", lambda_max_pca_stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynorm_series = {\n",
    "    \"ibcm\": l2_norm(yser_ibcm), \n",
    "    \"biopca\": l2_norm(yser_pca), \n",
    "    \"avgsub\": l2_norm(yser_avg), \n",
    "    \"none\": l2_norm(bkvecser_ibcm), \n",
    "    \"ideal\": l2_norm(yser_ideal)\n",
    "}\n",
    "std_options = dict(kernelsize=2001, boundary=\"free\")\n",
    "mean_options = dict(kernelsize=2001, boundary=\"free\")\n",
    "std_series = {\n",
    "    a: np.sqrt(moving_var(ynorm_series[a], **std_options)) for a in ynorm_series\n",
    "} \n",
    "mean_series = {\n",
    "    a: moving_average(ynorm_series[a], **mean_options) for a in ynorm_series\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "axes = axes.flatten()\n",
    "for model in std_series.keys():\n",
    "    props = dict(label=model_nice_names[model], color=model_colors[model])\n",
    "    axes[0].plot(tser_ibcm / 1000, mean_series[model], **props)\n",
    "    axes[1].plot(tser_ibcm / 1000, std_series[model], **props)\n",
    "ynorm_string = r\"$\\|\\vec{s}\\|$\"\n",
    "axes[0].set_ylabel(r\"PN activity norm, \" + ynorm_string)\n",
    "axes[1].set(xlabel=\"Time (x1000 steps)\", ylabel=r\"Standard deviation \" + ynorm_string)\n",
    "axes[0].legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.0), frameon=False)\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(4.5, 2.5*2)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
