{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Habituation to weakly non-Gaussian backgrounds as a function of background scale and moments\n",
    "\n",
    "Check how the mean, variance, and third moment of the concentrations affect the convergence time scale, using the $\\epsilon$ parameters to control the third moment without changing the first two moments too much. \n",
    "\n",
    "We analyze uncoupled networks, because $\\eta$ coupling changes individual neurons' initial conditions and dynamics, making it very hard to predict anything analytically beyond a rough scaling argument. So, in other words, we consider a single IBCM neuron. \n",
    "\n",
    "We can predict convergence in two phases: first, convergence to the saddle point, where $h_d = \\langle c \\rangle \\sum_\\gamma h_\\gamma$ reaches approximately $1$, and second, exponential divergence from the saddle point, at the time scale predicted from the Jacobian matrix diagonalized numerically. \n",
    "\n",
    "The starting point is the equation for one of the alignments $h_\\gamma$ averaged over fast background fluctuations, and neglecting temporal correlations between $\\Theta$ and $\\mathbf{m}$, \n",
    "\n",
    "$$ \\frac{1}{\\mu} \\frac{\\mathrm{d} h_\\nu}{\\mathrm{d} t} = \\sum_\\gamma \\left[ \\langle c \\rangle (h_\\mathrm{d}^2 +  \\sigma^2 u^2)(1 - h_\\mathrm{d}) - \\sigma^2 h_\\gamma (h_\\mathrm{d}^2 + \\sigma^2 u^2 - 2 h_\\mathrm{d}) + m_3 h_\\gamma^2 \\right] \\mathbf{\\hat{s}}_\\nu^T \\mathbf{\\hat{s}}_\\gamma $$\n",
    "\n",
    "where $\\langle c \\rangle$, $\\sigma^2$, and $m_3$ are the average, variance, and third centered moment of the background concentration process. \n",
    "\n",
    "## Phase I\n",
    "For phase I, the convergence to the saddle point can be analyzed by looking at the equation for $h_\\mathrm{d}$, obtained by simming the above ODE over $\\nu$ and multiplying by $\\langle c \\rangle$. For small $h_\\mathrm{d}$, $u^2$, it takes the form $\\mathrm{d}h_\\mathrm{d}/\\mathrm{d}t \\sim h_\\mathrm{d}^2$ . We can thus predict the convergence time from a divergence time of this purely second-order equation when neglecting the higher-order terms, resulting in a time of\n",
    "\n",
    "$$ t_\\mathrm{ds} = \\frac1A \\left(\\frac{1}{h_\\mathrm{d,0}} - 1 \\right) $$\n",
    "\n",
    "where $A = mu f_0 (N_\\mathrm{B} \\langle c \\rangle^2 + 2 \\sigma^2)$ and $f_0$ is the mean-field approximation to the sum of dot products between one odor vector with all others, $f_0 \\approx \\sum_{\\gamma} \\mathbf{\\hat{s}}_\\gamma^T \\mathbf{\\hat{s}}_0 \\approx 1 + (N_\\mathrm{B}-1) d_\\mathrm{cos}$, with $d_\\mathrm{cos}$ the average cosine similarity between two odor vectors in the ensemble. This $d_\\mathrm{cos}$ is computed for $N_\\mathrm{S}$ dimensions in the notebook. For odors with exponential elements and unit-normed, $d_\\mathrm{cos} = 0.516 \\pm 0.002$ for $N_\\mathrm{S} = 50$ dimensions, $d_\\mathrm{cos} = 0.531 \\pm 0.002$ for $N_\\mathrm{S} = 25$ dimensions. \n",
    "\n",
    "## Phase II\n",
    "We use the largest eigenvalue of the Jacobian matrix computed at the saddle point. We use our analytical predictions of IBCM fixed points for this, and compute the eigenvalues numerically (not much of a choice), the matrix is large. \n",
    "\n",
    "We look at the value of $u^2$ in phase II, since it encompasses the specific $h_\\nu$ converging to $h_\\mathrm{sp}$ and diverging away from the other $h_\\nu'$ which go to the non-specific value $h_\\mathrm{ns}$. We compute the convergence time by asking how long it takes for this exponential exit from the saddle to reach a target $u^2$ value away from the value at the saddle $u^2_\\mathrm{saddle}$, starting from an initial $u^2$ value near the saddle, at $u^2_\\mathrm{saddle} + \\Delta u^2_s$ (because the solution never lands perfectly on the saddle, it approaches near it). This exponential increases in $u^2$ has the form\n",
    "\n",
    "$$ u^2(t) = u^2_\\mathrm{saddle} +  \\Delta u^2_s e^{(t - t_{ds})/\\tau_\\mathrm{jac}} $$\n",
    "\n",
    "where $\\tau_\\mathrm{jac}$ is the inverse of the largest eigenvalue real part of the Jacobian matrix, and this exponential increase starts at time $t_{ds}$ (end of phase 1) near the saddle. We solve for the time $t_u$ it takes for $u^2$ to reach a target value below its fixed point value; $u^2_\\mathrm{target} = 1/\\sigma^2$ is a good choice because it is below the fixed point for any $\\epsilon > 0$ (i.e. any background with a non-zero third moment). This gives a time\n",
    "\n",
    "$$ t_u = t_{ds} + \\tau_\\mathrm{jac} \\log \\left(\\frac{u^2_\\mathrm{target}-u^2_\\mathrm{saddle}}{\\Delta u^2}  \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse, special\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from time import perf_counter\n",
    "import os, json\n",
    "from os.path import join as pj\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(1, \"..\")\n",
    "\n",
    "\n",
    "from modelfcts.ibcm import (\n",
    "    integrate_inhib_ibcm_network_options,\n",
    "    ibcm_respond_new_odors,\n",
    "    compute_mbars_hgammas_hbargammas,\n",
    "    ibcm_respond_new_odors\n",
    ")\n",
    "from modelfcts.ibcm_analytics import (\n",
    "    fixedpoint_thirdmoment_exact, \n",
    "    ibcm_fixedpoint_w_thirdmoment, \n",
    "    ibcm_all_largest_eigenvalues,\n",
    "    jacobian_fixedpoint_thirdmoment\n",
    ")\n",
    "from modelfcts.biopca import (\n",
    "    integrate_inhib_biopca_network_skip,\n",
    "    build_lambda_matrix,\n",
    "    biopca_respond_new_odors\n",
    ")\n",
    "from modelfcts.average_sub import (\n",
    "    integrate_inhib_average_sub_skip, \n",
    "    average_sub_respond_new_odors\n",
    ")\n",
    "from modelfcts.ideal import (\n",
    "    find_projector, \n",
    "    find_parallel_component, \n",
    "    ideal_linear_inhibitor, \n",
    "    compute_ideal_factor\n",
    ")\n",
    "from modelfcts.checktools import (\n",
    "    analyze_pca_learning, \n",
    ")\n",
    "from modelfcts.backgrounds import (\n",
    "    update_thirdmoment_kinputs, \n",
    "    sample_ss_distrib_thirdmoment, \n",
    "    generate_odorant\n",
    ")\n",
    "from utils.statistics import seed_from_gen\n",
    "from utils.smoothing_function import (\n",
    "    moving_average, \n",
    "    moving_var\n",
    ")\n",
    "from simulfcts.plotting import (\n",
    "    plot_hbars_gamma_series, \n",
    "    plot_w_matrix, \n",
    "    plot_background_norm_inhibition, \n",
    "    plot_background_neurons_inhibition, \n",
    "    plot_pca_results, \n",
    "    hist_outline\n",
    ")\n",
    "from simulfcts.analysis import compute_back_reduction_stats\n",
    "from utils.metrics import jaccard, l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_save_plots = False\n",
    "do_save_outputs = False\n",
    "\n",
    "root_dir = pj(\"..\")\n",
    "outputs_folder = pj(root_dir, \"results\", \"for_plots\", \"convergence\")\n",
    "panels_folder = pj(root_dir, \"figures\", \"convergence\")\n",
    "params_folder = pj(root_dir, \"results\", \"common_params\")\n",
    "\n",
    "# rcParams\n",
    "with open(pj(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(pj(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(pj(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(pj(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(pj(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full24 = np.asarray(json.load(f))\n",
    "# Here, 32 neurons, need to make a new palette with same parameters\n",
    "neuron_colors_full = np.asarray(sns.husl_palette(n_colors=32, h=0.01, s=0.9, l=0.4, as_cmap=False))\n",
    "\n",
    "with open(pj(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(pj(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)\n",
    "\n",
    "models = list(model_colors.keys())\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background generation and initialization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_combi(concs, backs):\n",
    "    \"\"\" concs: shaped [..., n_odors]\n",
    "        backs: 2D array, shaped [n_odors, n_osn]\n",
    "    \"\"\"\n",
    "    return concs.dot(backs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global choice of background and odor mixing functions\n",
    "update_fct = update_thirdmoment_kinputs\n",
    "combine_fct = linear_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given epsilon and the first three moment parameters, \n",
    "# compute all related background update parameter (matrices e^A, e^B, etc.)\n",
    "def default_nongauss_background_params(n_comp, avgnu, sigma2, epsilon_nu, \n",
    "                                       tau_nu, dt=1.0, correl_rho=0.0):\n",
    "    \"\"\" Build background parameter lists from :\n",
    "    Args:\n",
    "        n_comp: number of background vectors\n",
    "        avgnu: average concentration, default is 1/sqrt(n_comp)\n",
    "        sigma2: variance\n",
    "        epsilon_nu: controls the third moment amplitude, epsilon*sigma^4\n",
    "        tau_nu: autocorrelation time of the underlying O-U process\n",
    "        dt: Euler time steps, in units of 10 ms (default is 1.0)\n",
    "        correl_rho: correlation between odors, default 0.0\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial background vector and initial nu values\n",
    "    averages_nu = np.full(n_comp, avgnu)\n",
    "\n",
    "    ## Compute the matrices in the Ornstein-Uhlenbeck update equation\n",
    "    # Update matrix for the mean term: \n",
    "    # Exponential decay with time scale tau_nu over time deltat\n",
    "    update_mat_A = np.identity(n_comp)*np.exp(-dt/tau_nu)\n",
    "\n",
    "    # Steady-state covariance matrix\n",
    "    steady_covmat = correl_rho * sigma2 * np.ones([n_comp, n_comp])  # Off-diagonals: rho\n",
    "    steady_covmat[np.eye(n_comp, dtype=bool)] = sigma2  # diagonal: ones\n",
    "\n",
    "    # Cholesky decomposition of steady_covmat gives sqrt(tau/2) B\n",
    "    # Update matrix for the noise term: \\sqrt(tau/2(1 - exp(-2*deltat/tau))) B\n",
    "    psi_mat = np.linalg.cholesky(steady_covmat)\n",
    "    update_mat_B = np.sqrt(1.0 - np.exp(-2.0*dt/tau_nu)) * psi_mat\n",
    "\n",
    "    back_params = [update_mat_A, update_mat_B, None, averages_nu, epsilon_nu]\n",
    "    return back_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background initialization, given parameters and a seeded random generator\n",
    "def initialize_given_background(back_pms, rgen, n_comp):\n",
    "    # Initial values of background process variables (t, c for each variable)\n",
    "    init_nu = np.zeros(n_comp)\n",
    "    back_comp = back_pms[2]\n",
    "    init_bkvec = combine_fct(init_nu, back_comp)\n",
    "    init_back = [init_nu, init_bkvec]\n",
    "    return init_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBCM simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze to establish convergence to specific fixed points. \n",
    "def analyze_ibcm_simulation(sim_results, ibcm_rates_loc, back_pms, \n",
    "                            skp_loc=20, dt=1.0, duration_loc=360000.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        sim_results = (tser_ibcm, nuser_ibcm, bkvecser_ibcm, mser_ibcm, \n",
    "            hbarser_ibcm, thetaser_ibcm, wser_ibcm, yser_ibcm)\n",
    "        ibcm_rates_loc: learnrate_ibcm, tau_avg_ibcm, coupling_eta_ibcm, ...\n",
    "            \n",
    "    Returns:\n",
    "        alignment_gaps, indexed [neuron]\n",
    "        specif_gammas, indexed [neuron]\n",
    "        gamma_vari, indexed [neuron, component]\n",
    "    \"\"\"\n",
    "    coupling = ibcm_rates_loc[2]\n",
    "    (tser_ibcm, nuser_ibcm, bkvecser_ibcm, mser_ibcm, \n",
    "        hbarser_ibcm, thetaser_ibcm, wser_ibcm, yser_ibcm) = sim_results\n",
    "    # Calculate hgammas_bar and mbars\n",
    "    transient = int(5/6*duration_loc / dt) // skp_loc\n",
    "    basis = back_pms[2]\n",
    "    \n",
    "    # Dot products \\bar{c}_{\\gamma} = \\bar{\\vec{m}} \\cdot \\vec{x}_{\\gamma}\n",
    "    mbarser, c_gammas, hbars_gamma = compute_mbars_hgammas_hbargammas(mser_ibcm, coupling, basis)\n",
    "    hbars_gamma_mean = np.mean(hbars_gamma[transient:], axis=0)\n",
    "    # Sorted odor indices, from min to max, of odor alignments for each neuron\n",
    "    aligns_idx_sorted = np.argsort(hbars_gamma_mean, axis=1) \n",
    "    specif_gammas = np.argmax(hbars_gamma_mean, axis=1)\n",
    "    assert np.all(specif_gammas == aligns_idx_sorted[:, -1])\n",
    "    \n",
    "    \n",
    "    # Gap between first and second largest alignments for each neuron\n",
    "    n_i = hbars_gamma_mean.shape[0]\n",
    "    alignment_gaps = (hbars_gamma_mean[np.arange(n_i), specif_gammas]\n",
    "                     - hbars_gamma_mean[np.arange(n_i), aligns_idx_sorted[:, -2]])\n",
    "    \n",
    "    # Variance (fluctuations) of hbars gamma in the last 20 minutes of the simul\n",
    "    # Increases when the learning rate increases\n",
    "    last_steps = int(2.0*duration_loc/3.0 / dt) // skp_loc\n",
    "    hbars_gamma_vari = np.var(hbars_gamma[last_steps:], axis=0)\n",
    "    \n",
    "    return hbars_gamma, alignment_gaps, specif_gammas, hbars_gamma_vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analyze_ibcm_one_back_seed_nongauss(\n",
    "        ibcm_rates_loc, back_rates, inhib_rates_loc, \n",
    "        options_loc, dimensions, seedseq, init_ampli=0.001,\n",
    "        duration_loc=360000.0, dt_loc=1.0, skp_loc=20, full_returns=False\n",
    "    ):\n",
    "    \"\"\" Given IBCM model rates and background parameters except\n",
    "    background odors (but incl. number odors, c0), and a main seed sequence, \n",
    "    run and analyze convergence of IBCM on the background generated from that seed. \n",
    "    The seedseq should itself have been spawned from a root seed to have a distinct\n",
    "    one per run; this still makes seeds reproducible yet distinct for different runs. \n",
    "    The seedseq here is spawned again for a background gen. seed and a simul. seed. \n",
    "    \n",
    "    Args:\n",
    "        dimensions: gives [n_components, n_dimensions, n_i_ibcm]\n",
    "    \n",
    "    Returns:\n",
    "        iff full_return:\n",
    "            gaps, specifs, hgamvari, hgammas_ser, sim_results\n",
    "        else:\n",
    "            gaps, specifs, hgamvari, None, None\n",
    "        alignment_gaps: indexed [neuron]\n",
    "        specif_gammas: indexed [neuron]\n",
    "        gamma_vari: indexed [neuron, component]\n",
    "    \"\"\"\n",
    "    #print(\"Initializing IBCM simulation...\")\n",
    "    # Get dimensions\n",
    "    n_comp, n_dim, n_i = dimensions\n",
    "    \n",
    "    # Spawn back. generation seed and simul seed\n",
    "    initseed, simseed = seedseq.spawn(2)\n",
    "    \n",
    "    # Duplicate back params before including locally-generated odor vectors to them\n",
    "    back_pms_loc = list(back_rates)\n",
    "    \n",
    "    # Create background\n",
    "    rgen_init = np.random.default_rng(initseed)\n",
    "    back_comps_loc = generate_odorant((n_comp, n_dim), rgen_init)\n",
    "    back_comps_loc = back_comps_loc / l2_norm(back_comps_loc, axis=1)[:, None]\n",
    "\n",
    "    # Put generated odors in the list of background parameters\n",
    "    back_pms_loc[2] = back_comps_loc\n",
    "\n",
    "    # Initialize background with the random generator with seed rgenseed\n",
    "    rgen_init = np.random.default_rng(initseed)\n",
    "    init_back = initialize_given_background(back_pms_loc, rgen_init, n_comp)\n",
    "\n",
    "    # Initial synaptic weights: small positive noise\n",
    "    lambd_loc = ibcm_rates_loc[3]\n",
    "    # Random initial magnitudes\n",
    "    init_magnitudes = init_ampli * 0.5 * (1.0 + rgen_init.random(size=[n_i, 1]))*lambd_loc\n",
    "    init_synapses_ibcm = init_magnitudes * np.abs(rgen_init.normal(size=[n_i, n_dim]))\n",
    "    \n",
    "    # Run the IBCM simulation\n",
    "    #print(\"Running IBCM simulation...\")\n",
    "    tstart = perf_counter()\n",
    "    sim_results = integrate_inhib_ibcm_network_options(\n",
    "                init_synapses_ibcm, update_fct, init_back, \n",
    "                ibcm_rates_loc, inhib_rates_loc, back_pms_loc, \n",
    "                duration_loc, dt_loc, seed=simseed, \n",
    "                noisetype=\"normal\",  skp=skp_loc, **options_loc\n",
    "    )\n",
    "    tend = perf_counter()\n",
    "    #print(\"Finished IBCM simulation in {:.2f} s\".format(tend - tstart))\n",
    "    # IBCM results: [tseries, bk_series, bkvec_series, m_series,\n",
    "    #        cbar_series, theta_series, w_series, y_series]\n",
    "    \n",
    "    # Now analyze IBCM simul for convergence\n",
    "    #print(\"Starting to analyze IBCM simulation...\")\n",
    "    tstart = perf_counter()\n",
    "    hgammas_ser, gaps, specifs, hgamvari = analyze_ibcm_simulation(sim_results, \n",
    "                        ibcm_rates_loc, back_pms_loc, skp_loc=skp_loc, duration_loc=duration_loc)\n",
    "    tend = perf_counter()\n",
    "    #print(\"Finished analyzing IBCM simulation\")\n",
    "    \n",
    "    # Doesn't return full c gamma series, only the summary statistics of convergence\n",
    "    if full_returns:\n",
    "        hgammas_ser_ret = hgammas_ser\n",
    "        sim_results_ret = sim_results\n",
    "        back_comps_loc_ret = back_comps_loc\n",
    "    else:\n",
    "        hgammas_ser_ret = None\n",
    "        sim_results_ret = None\n",
    "        back_comps_loc_ret = None\n",
    "    \n",
    "    return gaps, specifs, hgamvari, hgammas_ser_ret, sim_results_ret, back_comps_loc_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy a simplification for once: we do not need to consider other models like average subtraction, optimal $P$, orthogonal projection since all we care about in this notebook is the convergence of the two biologically plausible models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions for IBCM\n",
    "def plot_ibcm_results(res_ibcm_raw, hbars_gamma, skp=20, dtscale=10.0 / 60.0 / 1000.0):\n",
    "    # tseries, bk_series, bkvec_series, m_series,\n",
    "    # hbar_series, theta_series, w_series, y_series\n",
    "    tser, bkser, bkvecser, _, _, _, _, yser = res_ibcm_raw\n",
    "    tser_scaled = tser * dtscale  # in min\n",
    "    # but will multiply by 1000 to compensate /1000 in plotting functions\n",
    "    # Plot of hbars gamma series\n",
    "    fig , ax, _ = plot_hbars_gamma_series(tser_scaled*1000, hbars_gamma,\n",
    "                            skp=skp, transient=320000 // skp)\n",
    "    fig.tight_layout()\n",
    "    leg = ax.legend(loc=\"upper left\", bbox_to_anchor=(1., 1.))\n",
    "    ax.set_xlabel(\"Time (min)\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot of background inhibition\n",
    "    fig, ax, bknorm_ser, ynorm_ser = plot_background_norm_inhibition(\n",
    "                                    tser_scaled*1000, bkvecser, yser, skp=skp)\n",
    "    ax.set_xlabel(\"Time (min)\")\n",
    "\n",
    "    # Compute noise reduction factor, annotate\n",
    "    transient = 250000 // skp\n",
    "    norm_stats = compute_back_reduction_stats(bknorm_ser, ynorm_ser, trans=transient)\n",
    "\n",
    "    print(\"Mean activity norm reduced to \"\n",
    "          + \"{:.1f} % of input\".format(norm_stats['avg_reduction'] * 100))\n",
    "    print(\"Standard deviation of activity norm reduced to \"\n",
    "          + \"{:.1f} % of input\".format(norm_stats['std_reduction'] * 100))\n",
    "    ax.annotate(\"St. dev. reduced to {:.1f} %\".format(norm_stats['std_reduction'] * 100), \n",
    "               xy=(0.98, 0.98), xycoords=\"axes fraction\", ha=\"right\", va=\"top\")\n",
    "\n",
    "    ax.legend(loc=\"center right\", bbox_to_anchor=(1.0, 0.8))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameter choices\n",
    "\n",
    "## Simulation parameters common to all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters for all simulations\n",
    "# Dimensions: 25 is enough?\n",
    "n_dimensions = 25\n",
    "n_components = 3  # try with 3 for simplicity by default\n",
    "\n",
    "# Inhibition W learning and decay rates\n",
    "inhib_rates_default = [0.0001, 0.00002]  # alpha, beta  [0.00025, 0.00005]\n",
    "\n",
    "# Simulation duration and integration time step\n",
    "duration = 360000.0\n",
    "deltat = 1.0  # time step units, each is 10 ms\n",
    "dtscale = 10.0 / 1000.0 / 60.0  # convert time steps to minutes\n",
    "\n",
    "# Saving every skp simulation point, 50 is enough for plots, \n",
    "# here use 20 to get convergence time accurately\n",
    "skp_default = 20 * int(1.0 / deltat)\n",
    "tser_common = np.arange(0.0, duration, deltat*skp_default)\n",
    "\n",
    "# Common model options\n",
    "activ_function = \"identity\"  #\"ReLU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBCM default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBCM model parameters\n",
    "n_i_ibcm = 9  # Number of inhibitory neurons for IBCM case\n",
    "\n",
    "# Default model rates\n",
    "learnrate_ibcm = 0.001 #5e-5\n",
    "tau_avg_ibcm = 200  # 2000\n",
    "# Coupling changes the convergence time prediction\n",
    "# because fluctuations or convergence of one neuron change the small initial\n",
    "# conditions of the others and thus the escape time\n",
    "# So here we do uncoupled neurons\n",
    "coupling_eta_ibcm = 0.0/n_i_ibcm\n",
    "ssat_ibcm = 50.0\n",
    "k_c2bar_avg = 0.1\n",
    "decay_relative_ibcm = 0.005\n",
    "lambd_ibcm = 1.0\n",
    "ibcm_rates_default = [\n",
    "    learnrate_ibcm, \n",
    "    tau_avg_ibcm, \n",
    "    coupling_eta_ibcm, \n",
    "    lambd_ibcm,\n",
    "    ssat_ibcm, \n",
    "    k_c2bar_avg,\n",
    "    decay_relative_ibcm \n",
    "]\n",
    "ibcm_options = {\n",
    "    \"activ_fct\": activ_function, \n",
    "    \"saturation\": \"linear\", \n",
    "    \"variant\": \"intrator\", \n",
    "    \"decay\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run for now\n",
    "# Create a default background for testing purposes\n",
    "meta_seedseq = np.random.SeedSequence(0xfc3b3f6fd61dd7742adcb9e4c7f99d30)\n",
    "\n",
    "# Choose background statistics parameters\n",
    "avgnu = 1.0 / np.sqrt(n_components)\n",
    "sigma2 = 0.16\n",
    "epsilon_nu = 0.2  # this works even at large epsilon, 0.4 OK\n",
    "tau_nu = 2.0\n",
    "back_rates_default = default_nongauss_background_params(\n",
    "                        n_components, avgnu, sigma2, epsilon_nu, tau_nu)\n",
    "\n",
    "dimensions_ibcm = [n_components, n_dimensions, n_i_ibcm]\n",
    "\n",
    "#ibcm_rates_loc, back_rates, inhib_rates_loc, \n",
    "#        options_loc, dimensions, seedseq, \n",
    "#        duration_loc=360000.0, dt_loc=1.0, skp_loc=20, full_return=False\n",
    "\n",
    "# Run and analyze simulation derived from the meta seedsequence\n",
    "all_res = run_analyze_ibcm_one_back_seed_nongauss(ibcm_rates_default, back_rates_default, inhib_rates_default, \n",
    "                        ibcm_options, dimensions_ibcm, meta_seedseq, init_ampli=0.0008,\n",
    "                        duration_loc=duration, dt_loc=deltat, skp_loc=skp_default, full_returns=True)\n",
    "\n",
    "gaps, specifs, hgamvari, hgammas_ser, ibcm_results, back_components = all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize convergence dynamics first\n",
    "plot_ibcm_results(ibcm_results, hgammas_ser, skp=skp_default, dtscale=dtscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some other convergence analysis results\n",
    "print(\"{} out of {} odors covered\".format(np.unique(specifs).size, n_components))\n",
    "print(\"Variance of the largest hbar_gamma for each neuron:\\n\", hgamvari[np.arange(n_i_ibcm), specifs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(n_i_ibcm), gaps, marker=\"o\", mfc=\"w\", ms=8)\n",
    "for i in range(n_i_ibcm):\n",
    "    ax.annotate(str(specifs[i]), xy=(i, gaps[i]), ha=\"center\", va=\"center\")\n",
    "ax.set_ylim([0.0, gaps.max()*1.1])\n",
    "ax.set(ylabel=\"Alignment gap\", xlabel=\"Neuron\", xticks=np.arange(0, n_i_ibcm, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical concentration moments\n",
    "conc_ser = avgnu + ibcm_results[1] + epsilon_nu * ibcm_results[1]**2\n",
    "mean_conc_sim = np.mean(conc_ser)  # all odors i.i.d., can average over them. \n",
    "variance_conc_sim = np.mean((conc_ser - mean_conc_sim)**2)\n",
    "thirdmoment_conc_sim = np.mean((conc_ser - mean_conc_sim)**3)\n",
    "\n",
    "moments_conc_sim = [\n",
    "    mean_conc_sim, \n",
    "    variance_conc_sim,\n",
    "    thirdmoment_conc_sim\n",
    "]\n",
    "print(moments_conc_sim)\n",
    "\n",
    "# Analytical prediction, exact: need moments of nu. \n",
    "variance_conc_pred = sigma2 + 2*(epsilon_nu*sigma2)**2\n",
    "mean_conc_pred = avgnu + epsilon_nu*sigma2\n",
    "thirdmoment_conc_pred = 6*epsilon_nu*sigma2**2 + 8*(epsilon_nu*sigma2)**3\n",
    "moments_conc_pred = [\n",
    "    mean_conc_pred,\n",
    "    variance_conc_pred,\n",
    "    thirdmoment_conc_pred\n",
    "]\n",
    "print(moments_conc_pred)\n",
    "\n",
    "# Predictions of fixed point u^2\n",
    "hs_hn_hd_u2 = fixedpoint_thirdmoment_exact(moments_conc_pred, 1, n_components-1)\n",
    "fixed_u2 = hs_hn_hd_u2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_conc_pred**2/mean_conc_pred - thirdmoment_conc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence as dx/dt = x^2 of h_d in phase one, approaching the saddle point\n",
    "def convergence_predict_phase1(cdsum, moments_conc, n_comp, learnrate, cosin=0.531):\n",
    "    \"\"\" For vectors with exponential elements and unit-normed, cosine similarity\n",
    "    is 0.516 for N_S=50 dimensions, 0.531 for N_S=25 dimensions\"\"\"\n",
    "    f0 = 1 + (n_components-1) * cosin  # sum of dot products between one odor vector and all others, \n",
    "    # 1 for the vector with itself and approx. the average cosine distance between vectors of the ensemble\n",
    "    # for the rest. This cosine is approx 0.6. \n",
    "    mean, vari, third = moments_conc\n",
    "    aneuron = learnrate*f0*(n_comp*mean**2 + 2*vari)\n",
    "    first_positive_cdsum = cdsum[cdsum > 0.0][0]\n",
    "    th = 1.0 / aneuron * (1.0 / (first_positive_cdsum*mean) - 1.0)\n",
    "    return th\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: exponential divergence away from the saddle\n",
    "# along the fastest direction. We use the analytical results for the saddle point,\n",
    "# which is the fixed point solution where all h_gammas are equal\n",
    "# and the time scale of divergence is the largest eigenvalue of the jacobian matrix\n",
    "# around that fixed point, which we find numerically.\n",
    "# Unclear analytically what sets this eigenvalue, \n",
    "# but at least we can compute how long an exponential increase from initial u^2 - u^2_saddle\n",
    "# takes to reach a final time\n",
    "def saddle_tscale_predict_phase2(moments_conc, ibcm_rates, n_comp, back_vecs, lambd=1.0):\n",
    "    \"\"\" Exponential exit time scale away from saddle point \"\"\"\n",
    "    # Check the saddle point where all h_gammas are equal, the model goes there at time t_d. \n",
    "    saddle_h = fixedpoint_thirdmoment_exact(moments_conc, n_components, 0, lambd=lambd_ibcm)[0]\n",
    "    # Value of u^2 and h_d at the saddle\n",
    "    mean_conc = moments_conc[0]\n",
    "    saddle_hd = saddle_h * mean_conc * n_comp\n",
    "    saddle_u2 = n_comp * saddle_h**2\n",
    "\n",
    "    # Get the largest eigenvalue at the saddle for the divergence time scale\n",
    "    specif_saddle = np.zeros(n_comp)\n",
    "    jacob_saddle = jacobian_fixedpoint_thirdmoment(\n",
    "                        moments_conc, ibcm_rates, specif_saddle, back_vecs, m3=1.0,\n",
    "                    )\n",
    "    jacob_eigvals = np.linalg.eigvals(jacob_saddle)  #eigenvalues are rates\n",
    "    saddle_tscale = 1.0 / np.amax(np.real(jacob_eigvals))  # in time step units\n",
    "    return saddle_tscale, [saddle_h, saddle_hd, saddle_u2]\n",
    "    \n",
    "def convergence_predict_phase2(tscale, u2_delta_init, u2_delta_target):\n",
    "    \"\"\" Time after t_d (phase 1) to converge to u2_delta_target above saddle when starting\n",
    "    at u2_delta above the saddle point value of u2. Based on setting \n",
    "    u2_delta_target = u2_delta_init * exp(t/tscale)\"\"\"\n",
    "    return np.log(u2_delta_target / u2_delta_init) * tscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saddle_exit_tscale, saddlevals = saddle_tscale_predict_phase2(moments_conc_pred, \n",
    "                        ibcm_rates_default, n_components, back_components, lambd=lambd_ibcm)\n",
    "saddle_h, saddle_hd, saddle_u2 = saddlevals\n",
    "saddle_exit_tscale_scaled = saddle_exit_tscale * dtscale\n",
    "print(\"Saddle exit time scale:\", saddle_exit_tscale_scaled, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convergence, track sums of h_gammas within each neuron\n",
    "cdsums = np.sum(hgammas_ser, axis=2)\n",
    "u2sums = np.sum(hgammas_ser**2, axis=2)\n",
    "tser_scaled = ibcm_results[0] * dtscale  # in min\n",
    "\n",
    "target_u2 = 1.0 / sigma2\n",
    "\n",
    "ncols = 5\n",
    "nrows = n_i_ibcm // ncols + min(1, n_i_ibcm % ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.55*ncols, \n",
    "                    plt.rcParams[\"figure.figsize\"][1]*0.7*nrows)\n",
    "colors = sns.color_palette(\"tab20\", n_colors=n_i_ibcm*2)\n",
    "tsl = slice(0, len(tser_scaled), 4)\n",
    "tu_predictions = []\n",
    "th_predictions = []\n",
    "for i in range(n_i_ibcm):\n",
    "    colors2 = colors[0], colors[1]  # Same two colors for each subplot\n",
    "    axes.flat[i].plot(tser_scaled[tsl], cdsums[tsl, i], \n",
    "                 alpha=1.0, color=colors2[0], ls=\"-\", \n",
    "                label=r\"$ h_d \\,/\\langle c \\rangle = \\sum_{\\gamma} h_{\\gamma}$\")\n",
    "    axes.flat[i].plot(tser_scaled[tsl], u2sums[tsl, i], \n",
    "                 alpha=1.0, color=colors2[1], ls=\"--\", label=r\"$u^2 = \\sum_{\\gamma} h_{\\gamma}^2$\")\n",
    "    axes.flat[i].set_title(\"Neuron {}, specif: {}\".format(i, specifs[i]), y=0.9)\n",
    "    #axes.flat[i].axhline(1.0 / avgnu, ls=\"-\", color=\"k\", lw=0.5)\n",
    "    axes.flat[i].axhline(saddle_hd/mean_conc_pred, ls=\"-\", color=\"k\", lw=0.75)\n",
    "    # saddle and final h_d are pretty much the same\n",
    "    axes.flat[i].axhline(saddle_u2, ls=\":\", color=\"grey\", lw=0.75)\n",
    "\n",
    "    # u^2 at stable fixed point? Not worth showing\n",
    "    #axes.flat[i].axhline(fixed_u2, ls=\"-.\", color=\"grey\", lw=0.75)\n",
    "    \n",
    "    # Prediction of convergence time?\n",
    "    th_pred = convergence_predict_phase1(cdsums[:, i], moments_conc_pred, n_components, learnrate_ibcm)\n",
    "    th_scaled = th_pred * dtscale\n",
    "    th_scaled = min(th_scaled, 60)  # Clip to 60 minutes for plotting purposes\n",
    "    th_predictions.append(th_scaled)\n",
    "    axes.flat[i].axvline(th_scaled, ymax=0.9, \n",
    "        color=\"r\", lw=0.75, ls=\"-\", label=\"$t_d$ predict.\")\n",
    "    #axes.flat[i].axhline(0.0, ls=\"-\", color=\"k\", lw=0.5)\n",
    "    \n",
    "    # Phase 2: predict from actual t_d, using the exponential exit rate\n",
    "    # obtained from the Jacobian matrix at the saddle point\n",
    "    # Use for the initial value of u^2 the value at the actual t_h\n",
    "    th_actual_idx = np.argmax(cdsums[:, i] > saddle_hd/mean_conc_pred)\n",
    "    u2delta_at_th = u2sums[th_actual_idx, i] - saddle_u2\n",
    "    u2delta_at_target = target_u2 - saddle_u2\n",
    "    th_tu_pred = convergence_predict_phase2(\n",
    "        saddle_exit_tscale_scaled, u2delta_at_th, u2delta_at_target)\n",
    "    tu_pred = tser_scaled[th_actual_idx] + th_tu_pred\n",
    "    tu_predictions.append(tu_pred)\n",
    "    clr_tu = colors[3*2+1]\n",
    "    axes.flat[i].axvline(tu_pred, ymax=0.9, \n",
    "        color=clr_tu, lw=0.75, ls=\"-\", label=r\"$t_u$ predict.\")  # after true t_d\n",
    "    axes.flat[i].axhline(target_u2, ls=\"--\", color=clr_tu, lw=0.75)\n",
    "    \n",
    "    # Annotations where there is space\n",
    "    if th_scaled > 25.0:\n",
    "        xannot, yshiftd, yshiftu, halign = 0.0, 0.0, 0.15, \"left\"\n",
    "    else:\n",
    "        xannot, yshiftd, yshiftu, halign = 60.0, 0.5, 0.0, \"right\"\n",
    "    axes.flat[i].annotate(r\"Saddle $h_\\mathrm{d}/\\langle c \\rangle$\", \n",
    "                          xy=(xannot, saddle_hd/mean_conc_pred + yshiftd), fontsize=5, ha=halign, va=\"bottom\")\n",
    "    axes.flat[i].annotate(r\"Saddle $u^2$\", xy=(xannot, saddle_u2 + yshiftu), fontsize=5, \n",
    "                          ha=halign, va=\"top\", color=\"grey\")\n",
    "    axes.flat[i].annotate(r\"Target $u^2$\", xy=(xannot, target_u2), fontsize=5, \n",
    "                          ha=halign, va=\"top\", color=clr_tu)\n",
    "for i in range(n_i_ibcm, axes.size):\n",
    "    if i == n_i_ibcm:\n",
    "        handles, labels = axes.flat[0].get_legend_handles_labels()\n",
    "        handles[1], handles[0] = handles[0], handles[1]\n",
    "        labels[1], labels[0] = labels[0], labels[1]\n",
    "        axes.flat[i].legend(handles, labels, frameon=False, loc=\"upper left\")\n",
    "    axes.flat[i].set_axis_off()\n",
    "for i in range(n_i_ibcm-ncols, n_i_ibcm):\n",
    "    axes.flat[i].set_xlabel(\"Time (min)\")\n",
    "for j in range(2):\n",
    "    axes[j, 0].set_ylabel(r\"Sums of $h_\\gamma$s\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save for final plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bknorm_ser = l2_norm(ibcm_results[2], axis=1)\n",
    "ynorm_ser = l2_norm(ibcm_results[7], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBCM results\n",
    "fname = pj(outputs_folder, \"non-gaussian_ibcm_convergence_analysis.npz\")\n",
    "# saddle hd, saddle u2, target u2\n",
    "horiz_lines = np.asarray([saddle_hd/mean_conc_pred, saddle_u2, target_u2])\n",
    "if do_save_outputs:\n",
    "    np.savez_compressed(\n",
    "        fname, \n",
    "        tser_scaled=tser_scaled,\n",
    "        hgammas_ser=hgammas_ser,\n",
    "        hgammas_specifs=specifs,\n",
    "        th_predictions=np.asarray(th_predictions),\n",
    "        tu_predictions=np.asarray(tu_predictions),  # actual th plus second phase duration prediction\n",
    "        horiz_lines=horiz_lines,\n",
    "        backnorm_ser=bknorm_ser,\n",
    "        ynorm_ser=ynorm_ser,\n",
    "        moments_conc=moments_conc_pred,\n",
    "        fixed_point_preds=hs_hn_hd_u2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioPCA results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
