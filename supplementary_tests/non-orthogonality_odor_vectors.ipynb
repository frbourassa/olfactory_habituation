{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-orthogonality of odor vectors\n",
    "\n",
    "Illustrate that the background vectors and resulting mixture are non-negative and non-orthogonal; also compute the average dot product between two vectors with exponentially-distributed elements afterwise unit-normed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "import os, json, sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(1, \"..\")\n",
    "from os.path import join as pj\n",
    "\n",
    "from modelfcts.average_sub import integrate_inhib_average_sub_skip\n",
    "\n",
    "from modelfcts.ideal import (\n",
    "    find_projector, \n",
    "    find_parallel_component, \n",
    "    ideal_linear_inhibitor, \n",
    "    compute_ideal_factor\n",
    ")\n",
    "from modelfcts.checktools import (\n",
    "    analyze_pca_learning, \n",
    "    check_conc_samples_powerlaw_exp1\n",
    ")\n",
    "from modelfcts.backgrounds import (\n",
    "    update_powerlaw_times_concs,\n",
    "    sample_ss_conc_powerlaw,\n",
    "    sample_ss_mixed_concs_powerlaw,\n",
    "    generate_odorant, \n",
    "    generate_gamma_odorant\n",
    ")\n",
    "from utils.statistics import seed_from_gen\n",
    "from modelfcts.distribs import (\n",
    "    truncexp1_average,\n",
    "    powerlaw_cutoff_inverse_transform\n",
    ")\n",
    "from utils.metrics import jaccard, l2_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_save_plots = True\n",
    "\n",
    "root_dir = pj(\"..\")\n",
    "panels_folder = pj(root_dir, \"figures\", \"powerlaw\")\n",
    "params_folder = pj(root_dir, \"results\", \"common_params\")\n",
    "\n",
    "# rcParams\n",
    "plt.rcParams[\"figure.figsize\"] = (4.5, 3.0)\n",
    "with open(pj(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(pj(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(pj(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(pj(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(pj(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full24 = np.asarray(json.load(f))\n",
    "# Here, 32 neurons, need to make a new palette with same parameters\n",
    "neuron_colors_full = np.asarray(sns.husl_palette(n_colors=32, h=0.01, s=0.9, l=0.4, as_cmap=False))\n",
    "\n",
    "with open(pj(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(pj(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)\n",
    "\n",
    "models = list(model_colors.keys())\n",
    "print(models)\n",
    "    \n",
    "models = list(model_colors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize common simulation parameters\n",
    "n_dimensions = 50  # Fly dimensions\n",
    "n_components = 4  # Number of background odors\n",
    "\n",
    "inhib_rates = [5e-5, 1e-5]  # alpha, beta  [0.00025, 0.00005]\n",
    "\n",
    "# Simulation duration\n",
    "duration = 360000.0\n",
    "deltat = 1.0\n",
    "n_chunks = 1\n",
    "skp = 50 * int(1.0 / deltat)\n",
    "\n",
    "# Common model options\n",
    "activ_function = \"identity\"  # \"ReLU\"\n",
    "\n",
    "# Background process\n",
    "update_fct = update_powerlaw_times_concs\n",
    "\n",
    "# Choose randomly generated background vectors\n",
    "# This seed gave nicely spread out odors easier to learn 0xe329714605b83365e67b44ed7e001ec\n",
    "# Another random seed: 0xb7bf767bbad297aeeee19d0ccdc3647e\n",
    "rgen_meta = np.random.default_rng(seed=0x47cf767aaab807aeeee19d0cfdc3629c)\n",
    "back_components = np.zeros([n_components, n_dimensions])\n",
    "for i in range(n_components):\n",
    "    back_components[i] = generate_odorant(n_dimensions, rgen_meta, lambda_in=0.1)\n",
    "back_components = back_components / l2_norm(back_components).reshape(-1, 1)\n",
    "\n",
    "# Seed for background simulation, to make sure all models are the same\n",
    "simul_seed = seed_from_gen(rgen_meta)\n",
    "\n",
    "# Turbulent background parameters: same rates and constants for all odors\n",
    "back_params = [\n",
    "    np.asarray([1.0] * n_components),        # whiff_tmins\n",
    "    np.asarray([500.] * n_components),       # whiff_tmaxs\n",
    "    np.asarray([1.0] * n_components),        # blank_tmins\n",
    "    np.asarray([800.0] * n_components),      # blank_tmaxs\n",
    "    np.asarray([0.6] * n_components),        # c0s\n",
    "    np.asarray([0.5] * n_components),        # alphas\n",
    "]\n",
    "\n",
    "# Compute mean of independent underlying variables, \n",
    "# to determine the mean and target covariance of mixed variables\n",
    "tblo, tbhi, twlo, twhi = back_params[2], back_params[3], back_params[0], back_params[1]\n",
    "whiffprob = np.mean(1.0 / (1.0 + np.sqrt(tblo*tbhi/twlo/twhi)))\n",
    "avg_whiff_conc = np.mean(truncexp1_average(*back_params[4:6]))\n",
    "mean_conc = whiffprob * avg_whiff_conc  # average time in whiffs vs blanks * average whiff conc\n",
    "print(\"Analytical mean conc:\", mean_conc)\n",
    "#print(\"Numerical mean conc:\", mean_conc_empirical)\n",
    "\n",
    "# Then add background odor vectors last to that list\n",
    "back_params.append(back_components)\n",
    "\n",
    "# Initial values of background process variables (t, c for each variable)\n",
    "init_concs = sample_ss_conc_powerlaw(*back_params[:-1], size=1, rgen=rgen_meta)\n",
    "init_times = powerlaw_cutoff_inverse_transform(\n",
    "                rgen_meta.random(size=n_components), *back_params[2:4])\n",
    "tc_init = np.stack([init_times, init_concs.squeeze()], axis=1)\n",
    "\n",
    "# Initial background vector \n",
    "init_bkvec = tc_init[:, 1].dot(back_components)\n",
    "# nus are first in the list of initial background params\n",
    "init_back_list = [tc_init, init_bkvec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background process example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a dense simulation to extract mixed concentrations for\n",
    "# global correl_rho chosen above (0.7)\n",
    "# Dummy initialization\n",
    "avg_options = {\"activ_fct\": activ_function}\n",
    "init_synapses_avg = np.zeros([1, n_dimensions])\n",
    "\n",
    "sim_avg_res = integrate_inhib_average_sub_skip(\n",
    "                init_synapses_avg, update_fct, init_back_list, \n",
    "                [], inhib_rates, back_params, duration, deltat,\n",
    "                seed=simul_seed, noisetype=\"uniform\", skp=1, **avg_options\n",
    ")\n",
    "\n",
    "_, bkser_avg, bkvecser_avg, _, _ = sim_avg_res\n",
    "del sim_avg_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background vectors time series with mixed concentrations\n",
    "tslice = slice(0, 50000, 200)\n",
    "n_cols = 6\n",
    "n_plots = n_dimensions // 4  # Only show first 24 OSNs\n",
    "n_rows = n_plots // n_cols + min(1, n_plots % n_cols)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True)\n",
    "fig.set_size_inches(n_cols*1.25, n_rows*1.25)\n",
    "for i in range(n_plots):\n",
    "    ax = axes.flat[i]\n",
    "    ax.scatter(bkvecser_avg[tslice, 2*i+1], bkvecser_avg[tslice, 2*i], \n",
    "               s=9, alpha=0.5, color=\"k\")\n",
    "    for j in range(n_components):\n",
    "        ax.plot(*zip([0.0, 0.0], 3.0*back_components[j, 2*i:2*i+2:][::-1]), lw=2.0)\n",
    "    ax.set(xlabel=\"OSN {}\".format(2*i+2), ylabel=\"OSN {}\".format(2*i+1))\n",
    "for i in range(n_plots, n_rows*n_cols):\n",
    "    axes.flat[i].set_axis_off()\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(\"..\", \"figures\", \"correlation\", \"osn_background_vectors.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition of odor-specific tag elements vs distance to background\n",
    "\n",
    "Reanalyzing the simulation results with a different metric, which measures the fraction of new odor tag elements (Kenyon cells) not present in the background sample's tag which are preserved in the tag for the response to the mixture. Habituation should emphasize these tag KCs while potentially removing elements common with background vectors. \n",
    "\n",
    "$$ F(z_\\mathrm{mix}, z_\\mathrm{new}; z_\\mathrm{back}) = \\frac{\\mathrm{card}(z_\\mathrm{mix} \\cup z_\\mathrm{new} / z_\\mathrm{back})}{\\mathrm{card}(z_\\mathrm{new} / z_\\mathrm{back})} $$\n",
    "\n",
    "where $x/y$ denotes the difference between sets $x$ and $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load computed F across models, backgrounds, new odor samples.\n",
    "data_folder = pj(\"..\", \"results\", \"for_plots\")\n",
    "all_frac_tags_file = np.load(pj(data_folder, \"frac_distinct_tag_elements_identity.npz\"))\n",
    "available_models = list(all_frac_tags_file.keys())\n",
    "\n",
    "# Plot as a function of Euclidean distance between new odor and background\n",
    "new_back_dists = np.load(pj(data_folder, \"new_back_distances_identity.npz\"))[\"new_back_distances\"]\n",
    "\n",
    "# New odor concentrations\n",
    "all_dists = np.load(pj(data_folder, \"new_mix_distances_identity.npz\"))\n",
    "new_concs = all_dists[\"new_concs\"]\n",
    "rel_new_concs = [a/new_concs[1] for a in new_concs]\n",
    "del all_dists\n",
    "\n",
    "assert len(new_concs) == all_frac_tags_file[\"ibcm\"].shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_models = [\"none\", \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "assert np.all([a in available_models for a in show_models]), \"missing model\"\n",
    "\n",
    "# Sort scores per pair of odors and per new odor concentration\n",
    "# Concatenated scores shaped [n_background, n_new_odors, n_times, n_new_concs, n_back_samples]\n",
    "# new_back_dists shaped background, new_odor\n",
    "# Just need median along axes 2, 4 to get one per [back, conc, new] triplet\n",
    "scores_per_triplet = {}\n",
    "for m in show_models:\n",
    "    scores_per_triplet[m] = np.median(all_frac_tags_file[m], axis=(2, 4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://github.com/mwaskom/seaborn/issues/2280\n",
    "def move_legend(ax, new_loc, **kws):\n",
    "    old_legend = ax.legend_\n",
    "    handles = old_legend.legendHandles\n",
    "    labels = [t.get_text() for t in old_legend.get_texts()]\n",
    "    title = old_legend.get_title().get_text()\n",
    "    ax.legend(handles, labels, loc=new_loc, title=title, **kws)\n",
    "    \n",
    "move_legend(ax, \"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: with kdeplot, this figure is slow to generate, taking around 1 min\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.8, plt.rcParams[\"figure.figsize\"][1]*1.1)\n",
    "ax = axes.flatten()\n",
    "plot_type = \"kde\"  # or \"kde\"\n",
    "if plot_type == \"kde\":\n",
    "    for i, c in enumerate(rel_new_concs):\n",
    "        ax = axes[i]\n",
    "        data = pd.concat({m:pd.DataFrame(np.stack([scores_per_triplet[m][:, :, i].flatten(), \n",
    "                            new_back_dists.flatten()], axis=1), columns=pd.Index([\"jaccard\", \"new-back\"]))\n",
    "                        for m in show_models}, names=[\"Model\"])\n",
    "        data = data.rename(model_nice_names, level=\"Model\")\n",
    "        model_nice_colors = {model_nice_names[m]:model_colors[m] for m in show_models}\n",
    "        g = sns.kdeplot(data=data.reset_index(), x=\"new-back\", y=\"jaccard\", hue=\"Model\", \n",
    "                palette=model_nice_colors, ax=ax, fill=True, alpha=0.5, legend=(i==0))\n",
    "        g.set_title(r\"New conc. $= {:.1f} \\langle c \\rangle$\".format(c), y=0.98)\n",
    "        if i == 0:\n",
    "            old_legend = g.get_legend()\n",
    "            handles = old_legend.legend_handles\n",
    "            labels = [t.get_text() for t in old_legend.get_texts()]\n",
    "            g.legend(handles[::-1], labels[::-1], title=old_legend.get_title().get_text())\n",
    "            sns.move_legend(g, frameon=False, loc=\"upper left\")\n",
    "            #g.get_legend().set(labels=[model_nice_names[m] for m in show_models[::-1]])\n",
    "            \n",
    "        \n",
    "elif plot_type == \"scatter\":\n",
    "    for i, c in enumerate(rel_new_concs):\n",
    "        ax = axes[i]\n",
    "        for m in show_models:\n",
    "            scores_m_i = scores_per_triplet[m][:, :, i]\n",
    "            xy = np.stack([new_back_dists.flatten(), scores_m_i.flatten()], axis=0)\n",
    "            xy = np.unique(xy, axis=1)  # Find unique (x, y) pairs\n",
    "            ax.scatter(xy[0], xy[1], color=model_colors[m], label=model_nice_names[m], s=0.9, alpha=0.1)\n",
    "            ax.set_title(r\"New conc.: $= {:.1f} \\langle c \\rangle$\".format(c), y=0.98)\n",
    "    # Legend\n",
    "    handles, labels = axes[1].get_legend_handles_labels()\n",
    "    handles_new = []\n",
    "    for h in handles:\n",
    "        #handles_new.append(mpl.patches.Patch(facecolor=h.get_facecolor(), edgecolor=h.get_facecolor()))\n",
    "        handles_new.append(mpl.lines.Line2D([0], [0], marker='o', color=h.get_facecolor(), \n",
    "                              markerfacecolor=h.get_facecolor(), markersize=4, alpha=1.0, ls=\"none\"))\n",
    "    axes[1].legend(handles_new[::-1], labels[::-1], fontsize=6, frameon=False, handlelength=1.0, handletextpad=0.3, \n",
    "              borderaxespad=0.3, labelspacing=0.3)\n",
    "\n",
    "\n",
    "xlbl = r\"New odor orthogonal part, $\\|\\mathbf{s}_\\mathrm{new, \\perp}\\|$\"\n",
    "axes[0].set(xlabel=xlbl, ylabel=\"Fraction distinct tag elements\\n\" \n",
    "                   + r\"$F(z_{\\mathrm{mix}}, z_{\\mathrm{new}}; z_{\\mathrm{back}})$\")\n",
    "axes[1].set(xlabel=xlbl, ylabel=None)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"frac_distinct_kc_new_odor_distance_{}.pdf\".format(plot_type)), \n",
    "                dpi=300, transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One plot across concentrations now?\n",
    "# Warning: with kdeplot, this figure is slow to generate, taking around 1 min\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.9, plt.rcParams[\"figure.figsize\"][1]*1.1)\n",
    "plot_type = \"scatter\"  # or \"kde\"\n",
    "if plot_type == \"kde\":\n",
    "    data = pd.concat({m:pd.DataFrame(np.stack([np.median(scores_per_triplet[m], axis=2).flatten(), \n",
    "                        new_back_dists.flatten()], axis=1), columns=pd.Index([\"jaccard\", \"new-back\"]))\n",
    "                    for m in show_models}, names=[\"Model\"])\n",
    "    data = data.rename(model_nice_names, level=\"Model\")\n",
    "    model_nice_colors = {model_nice_names[m]:model_colors[m] for m in show_models}\n",
    "    g = sns.kdeplot(data=data.reset_index(), x=\"new-back\", y=\"jaccard\", hue=\"Model\", \n",
    "            palette=model_nice_colors, ax=ax, fill=True, alpha=0.5)\n",
    "    g.set_title(r\"New conc. $= {:.1f} \\langle c \\rangle$\".format(c), y=0.98)\n",
    "    old_legend = g.get_legend()\n",
    "    handles = old_legend.legend_handles\n",
    "    labels = [t.get_text() for t in old_legend.get_texts()]\n",
    "    g.legend(handles[::-1], labels[::-1], title=old_legend.get_title().get_text())\n",
    "    sns.move_legend(g, frameon=False, loc=\"upper left\")\n",
    "    #g.get_legend().set(labels=[model_nice_names[m] for m in show_models[::-1]])\n",
    "\n",
    "        \n",
    "elif plot_type == \"scatter\":\n",
    "    for m in show_models:\n",
    "        scores_m_i = np.median(scores_per_triplet[m], axis=2)\n",
    "        xy = np.stack([new_back_dists.flatten(), scores_m_i.flatten()], axis=0)\n",
    "        xy = np.unique(xy, axis=1)  # Find unique (x, y) pairs\n",
    "        ax.scatter(xy[0], xy[1], color=model_colors[m], label=model_nice_names[m], s=0.9, alpha=0.1)\n",
    "        ax.set_title(r\"New conc.: $= {:.1f} \\langle c \\rangle$\".format(c), y=0.98)\n",
    "    # Legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles_new = []\n",
    "    for h in handles:\n",
    "        #handles_new.append(mpl.patches.Patch(facecolor=h.get_facecolor(), edgecolor=h.get_facecolor()))\n",
    "        handles_new.append(mpl.lines.Line2D([0], [0], marker='o', color=h.get_facecolor(), \n",
    "                              markerfacecolor=h.get_facecolor(), markersize=4, alpha=1.0, ls=\"none\"))\n",
    "    ax.legend(handles_new[::-1], labels[::-1], fontsize=6, frameon=False, handlelength=1.0, handletextpad=0.3, \n",
    "              borderaxespad=0.3, labelspacing=0.3)\n",
    "\n",
    "\n",
    "xlbl = r\"New odor orthogonal part, $\\|\\mathbf{s}_\\mathrm{new, \\perp}\\|$\"\n",
    "ax.set(xlabel=xlbl, ylabel=\"Fraction distinct tag elements\\n\" \n",
    "                   + r\"$F(z_{\\mathrm{mix}}, z_{\\mathrm{new}}; z_{\\mathrm{back}})$\")\n",
    "ax.set(xlabel=xlbl, ylabel=None)\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#if do_save_plots:\n",
    "#    fig.savefig(pj(panels_folder, \"frac_distinct_kc_new_odor_distance_oneplot_{}.pdf\".format(plot_type)), \n",
    "#                dpi=300, transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average dot product between random odors\n",
    "Generate a bunch of odors and bootstrap the average dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap by sampling s_i and s_j with replacement, computing s_i.dot(s_j)\n",
    "n_samp = int(1e5)\n",
    "samp_size = int(1e4)\n",
    "n_boot = 10000\n",
    "boot_dots = np.zeros(n_boot)\n",
    "\n",
    "start_t = perf_counter()\n",
    "odors = generate_odorant((n_samp, n_dimensions), rgen_meta)\n",
    "odors = odors / l2_norm(odors, axis=1)[:, None]\n",
    "for i in range(n_boot):\n",
    "    od_choice_i = rgen_meta.choice(n_samp, size=samp_size, replace=True)\n",
    "    od_choice_j = rgen_meta.choice(n_samp, size=samp_size, replace=True)\n",
    "    odors_sample_i = odors[od_choice_i]\n",
    "    odors_sample_j = odors[od_choice_j]\n",
    "    dotprods = np.sum(odors_sample_i * odors_sample_j, axis=1)\n",
    "    boot_dots[i] = np.mean(dotprods)\n",
    "end_t = perf_counter()\n",
    "print(\"Finished {} bootstrap repeats with {} samples each in {:.2f} s\".format(\n",
    "    n_boot, samp_size, end_t - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dot = np.mean(boot_dots)\n",
    "vari_dot = np.var(boot_dots, ddof=1)  # unbiased estimator\n",
    "print(\"Mean dot product:\", mean_dot)\n",
    "print(\"Standard dev.:\", np.sqrt(vari_dot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to generating new odors every time\n",
    "n_boot2 = n_boot // 2\n",
    "samp_size2 = samp_size // 2\n",
    "boot_dots2 = np.zeros(n_boot2)\n",
    "start_t = perf_counter()\n",
    "for i in range(n_boot2):\n",
    "    odors_sample_i = generate_odorant((samp_size2, n_dimensions), rgen_meta)\n",
    "    odors_sample_i = odors_sample_i / l2_norm(odors_sample_i, axis=1)[:, None]\n",
    "    odors_sample_j = generate_odorant((samp_size2, n_dimensions), rgen_meta)\n",
    "    odors_sample_j = odors_sample_j / l2_norm(odors_sample_j, axis=1)[:, None]\n",
    "    dotprods = np.sum(odors_sample_i * odors_sample_j, axis=1)\n",
    "    boot_dots2[i] = np.mean(dotprods)\n",
    "end_t = perf_counter()\n",
    "print(\"Finished {} bootstrap repeats with {} samples each in {:.2f} s\".format(\n",
    "    n_boot2, samp_size2, end_t - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dot2 = np.mean(boot_dots2)\n",
    "vari_dot2 = np.var(boot_dots2, ddof=1)  # unbiased estimator\n",
    "print(\"Mean dot product:\", mean_dot2)\n",
    "print(\"Standard dev. of estimate:\", np.sqrt(vari_dot2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same drill, but for gamma-distributed vector elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to generating new odors every time\n",
    "start_t = perf_counter()\n",
    "\n",
    "boot_dots_gam = np.zeros(n_boot2)\n",
    "mean_norms_gam = np.zeros(n_boot2)\n",
    "samp_size3 = samp_size2 // 2\n",
    "for i in range(n_boot2):\n",
    "    odors_sample_i = generate_gamma_odorant((samp_size3, n_dimensions), rgen_meta)\n",
    "    odors_sample_j = generate_gamma_odorant((samp_size3, n_dimensions), rgen_meta)\n",
    "    dotprods = np.sum(odors_sample_i * odors_sample_j, axis=1)\n",
    "    norms_ij = np.concatenate([l2_norm(odors_sample_i, axis=1), l2_norm(odors_sample_j, axis=1)])\n",
    "    boot_dots_gam[i] = np.mean(dotprods)\n",
    "    mean_norms_gam[i] = np.mean(norms_ij)\n",
    "end_t = perf_counter()\n",
    "print(\"Finished {} bootstrap repeats with {} samples each in {:.2f} s\".format(\n",
    "    n_boot2, samp_size3, end_t - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dot_gam = np.mean(boot_dots_gam)\n",
    "vari_dot_gam = np.var(boot_dots_gam, ddof=1)  # unbiased estimator\n",
    "print(\"Mean dot product:\", mean_dot_gam)\n",
    "print(\"Standard dev. of estimate:\", np.sqrt(vari_dot_gam))\n",
    "\n",
    "# Compare to average vector norm \n",
    "mean_norm_gam = np.mean(mean_norms_gam)\n",
    "vari_norm_gam = np.var(mean_norms_gam, ddof=1)\n",
    "print(\"Mean vector norm:\", mean_norm_gam)\n",
    "print(\"Standard dev. of estimate:\", np.sqrt(vari_norm_gam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
