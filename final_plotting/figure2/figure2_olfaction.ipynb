{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea92fd9f",
   "metadata": {},
   "source": [
    "# Figure 2: new odor recognition performance tests\n",
    "This version is with a six-odor, turbulent background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import os, colorsys, json\n",
    "pj = os.path.join\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072da4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "root_dir = pj(\"..\", \"..\")\n",
    "data_folder = pj(root_dir, \"results\", \"for_plots\")\n",
    "panels_folder = \"panels/\"\n",
    "params_folder = pj(root_dir, \"results\", \"common_params\")\n",
    "\n",
    "do_save_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcd12d",
   "metadata": {},
   "source": [
    "# Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ee39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams\n",
    "with open(pj(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(pj(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(pj(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(pj(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(pj(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full = np.asarray(json.load(f))\n",
    "\n",
    "with open(pj(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(pj(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neu = np.load(pj(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"cbars_gamma\"].shape[1]\n",
    "n_components, n_orn = np.load(pj(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"back_vecs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33912f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra aesthetic parameters for this figure\n",
    "\n",
    "# More legend rcParams: make everything smaller by 30 %\n",
    "plt.rcParams[\"patch.linewidth\"] = 0.75\n",
    "legend_rc = {\"labelspacing\":0.5, \"handlelength\":2.0, \"handleheight\":0.7, \n",
    "             \"handletextpad\":0.8, \"borderaxespad\":0.5, \"columnspacing\":2.0}\n",
    "for k in legend_rc:\n",
    "    plt.rcParams[\"legend.\"+k] = 0.75 * legend_rc[k]\n",
    "\n",
    "new_color = \"r\"\n",
    "linestyles = [\"-\", \"--\", \":\", (0, (5, 1, 2, 1)), \"-.\"]\n",
    "neuron_styles = linestyles + [(0, (1, 2, 1, 2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcc6e5",
   "metadata": {},
   "source": [
    "# Panel A: habituation narrow long trace\n",
    "Part of the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute norm of PN activity\n",
    "ex = np.load(pj(data_folder, \"sample_turbulent_ibcm_simulation.npz\"))\n",
    "tser_example = np.arange(*ex[\"tser_range\"])\n",
    "sser_example = ex[\"yser\"]\n",
    "dt_u = 10.0  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(100.0 / 25.4, 18.0 / 25.4)\n",
    "snorm_ser = np.sqrt(np.sum(sser_example**2, axis=1))\n",
    "ax.plot(tser_example * dt_u / 1000 / 60, snorm_ser, color=back_color, lw=0.5)\n",
    "last_times = np.linspace(tser_example[-1] - 2000*10, tser_example[-1], 10)\n",
    "for t in last_times:\n",
    "    ax.plot(np.asarray([t-20, t, t+20])*dt_u/1000/60, \n",
    "            np.asarray([0.0, snorm_ser.max()/3+0.2*np.random.uniform(), 0.0]), \n",
    "            color=\"r\", lw=0.85, alpha=0.8)\n",
    "ymax = snorm_ser.max()\n",
    "ax.annotate(\"Habituation period\", xy=(28.0, ymax), ha=\"center\", va=\"center\", fontsize=6)\n",
    "ax.annotate(\"Tests\", xy=(last_times[4]*dt_u/60/1000, ymax), \n",
    "            color=\"r\", ha=\"center\", va=\"center\", fontsize=6)\n",
    "ax.annotate(\"\", xy=(1.0, ymax), xytext=(17.0, ymax), \n",
    "            arrowprops={\"color\":\"k\", \"width\":0.1, \"headwidth\":2.0, \"headlength\":2.0})\n",
    "ax.annotate(\"\", xy=(last_times[0]*dt_u/60/1000 - 2, ymax), xytext=(40.0, ymax), \n",
    "            arrowprops={\"color\":\"k\", \"width\":0.1, \"headwidth\":2.0, \"headlength\":2.0})\n",
    "ax.fill_between([0, last_times[0]*dt_u/60/1000 - 1.5], [0, 0], [ymax-0.4, ymax-0.4], \n",
    "               color=back_color_samples, alpha=0.3)\n",
    "ax.set_ylabel(\"PN\\nactivity\\nnorm\", fontsize=6)\n",
    "#lbl = ax.set_xlabel(\"Time (min)\", fontsize=6, labelpad=-6, ha=\"left\", x=1.0)\n",
    "lbl = ax.set_xlabel(\"Time (min)\", fontsize=6)\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"habituation_time_axis.pdf\"), \n",
    "                transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(lbl,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db250c",
   "metadata": {},
   "source": [
    "# Former panel B, now in figure 1: background process\n",
    "Histograms of concentrations, whiff duration and blank duration, overlaid with analytical distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = np.load(pj(data_folder, \"sample_turbulent_background.npz\"))\n",
    "# Time units per simulation step, for plotting, in ms\n",
    "dt_u = 10.0  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_outline(ax, bins, height, **plot_kwargs):\n",
    "    plot_hist = np.stack([height, height], axis=1).flatten()\n",
    "    plot_edges = np.stack([bins[:-1], bins[1:]], axis=1).flatten()\n",
    "    ax.plot(plot_edges, plot_hist, **plot_kwargs)\n",
    "    ax.fill_between(plot_edges, min(0.0, height.min()), plot_hist,\n",
    "                    color=plot_kwargs.get(\"color\"), alpha=0.3)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44560a-30d5-4e41-9479-2bdf89374498",
   "metadata": {},
   "source": [
    "# Panel C: habituation, response to background goes down\n",
    "Just show how different models fare in this respect: it does habituate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52e96f-d2cb-4cbc-8683-a7645b436ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ysers = {}\n",
    "for mod in [\"ibcm\", \"pca\", \"avgsub\"]:\n",
    "    k = \"biopca\" if mod == \"pca\" else mod\n",
    "    all_ysers[k] = np.load(pj(data_folder, \n",
    "        \"{}_full_habituation_run_example.npz\".format(mod)))[\"s_snaps\"]\n",
    "all_ysers[\"none\"] = np.load(pj(data_folder, \n",
    "        \"ibcm_full_habituation_run_example.npz\"))[\"back_vec_snaps\"]\n",
    "\n",
    "# Should show the optimum too. \n",
    "all_ysers[\"optimal\"] = all_ysers[\"none\"] - all_ysers[\"none\"].dot(\n",
    "    np.load(pj(data_folder, \"optimal_habituation_example.npz\"))[\"optimal_ws\"][0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24261d81-fbf0-4ca8-a3d9-5d958b1fb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot habituation time series. \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.9, fig.get_size_inches()[1]*1.1)\n",
    "# We know the time series of these simulations: \n",
    "# 360000 steps, skipping 20, 10 ms each step\n",
    "extra_skp = 10\n",
    "tser = np.arange(0.0, 360000.0, 20.0*extra_skp) * 0.01 / 60.0  # 0.01 s/step\n",
    "# Choose plotting order wisely: no habituation first, smallest last\n",
    "yser_norm = np.sqrt(np.sum(all_ysers[\"none\"]**2, axis=1))[::extra_skp]\n",
    "ax.plot(tser, yser_norm, label=\"None\", color=model_colors[\"none\"], lw=0.5, alpha=0.8)\n",
    "for m in [ \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]:\n",
    "    lbl = model_nice_names.get(m)\n",
    "    yser_norm = np.sqrt(np.sum(all_ysers[m]**2, axis=1))[::extra_skp]\n",
    "    ax.plot(tser, yser_norm, label=lbl, color=model_colors[m], lw=0.5, alpha=0.7)\n",
    "\n",
    "leg_props = dict(borderaxespad=0.3, handlelength=1.2, facecolor=(1,1,1,0.8), edgecolor=(1,1,1,0.8))\n",
    "ax.legend(loc=\"upper center\", title=\"Model\", **leg_props, ncol=2)\n",
    "\n",
    "ax.set(ylabel=r\"PN activity norm $\\|\\mathbf{y}(t)\\|$\", xlabel=\"Time (min)\")\n",
    "ax.set_title(\"Habituation\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", pad=15)\n",
    "ylims_orig = ax.get_ylim()\n",
    "ax.set_ylim([ylims_orig[0], ylims_orig[1]*0.9])\n",
    "#ax.set_xlim([0.0, 5.0])\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"habituation_examples_turbulent_back.pdf\"), \n",
    "                transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f68406-fd0b-4c31-bf16-a4566dfa0e7d",
   "metadata": {},
   "source": [
    "# Panel D: odor recognition performance, distance to new odor vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49185be-af07-407d-955f-74278f386d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = np.load(pj(data_folder, \"new_mix_distances_identity.npz\"))\n",
    "all_models = list(all_dists.keys())\n",
    "all_models.remove(\"new_concs\")\n",
    "print(all_dists[\"ibcm\"].shape)\n",
    "print(all_models)\n",
    "new_concs = all_dists[\"new_concs\"]\n",
    "# I know these are 0.5x and 1x the average concentration, so use these relative measures instead\n",
    "rel_new_concs = [a/new_concs[1] for a in new_concs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25748c8-b0f4-43a4-be0a-53b124ed381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interesting statistics\n",
    "show_models = [\"none\", \"avgsub\", \"orthogonal\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "dist_histograms = {}\n",
    "dist_cdfs = {}\n",
    "dist_stats = {}\n",
    "min_dist_to_show = np.log10((all_dists[\"optimal\"] / np.asarray(new_concs).reshape(1, 1, 1, 2, 1)).min())\n",
    "for m in show_models:\n",
    "    dist_histograms[m] = []\n",
    "    dist_cdfs[m] = []\n",
    "    dist_stats[m] = []\n",
    "    dists = []\n",
    "    for i in range(len(new_concs)):\n",
    "        # Normalize by new odor magnitude = 1.0 * conc\n",
    "        # Combine all concentrations this way. \n",
    "        conc = new_concs[i]\n",
    "        # Distances in log scale\n",
    "        dists_i = all_dists[m][:, :, :, i].flatten() / conc\n",
    "        dists_i = np.log10(dists_i[dists_i > 0.0])  # Drop exact zeros\n",
    "        dists.append(dists_i)\n",
    "    dists = np.concatenate(dists)\n",
    "    dist_stats[m] = [\n",
    "        np.mean(dists), \n",
    "        np.median(dists), \n",
    "        np.var(dists),\n",
    "    ]\n",
    "    # Remove extremely small distances for plotting purposes\n",
    "    dists_clipped = dists[dists > min_dist_to_show]\n",
    "    dist_histograms[m] = np.histogram(dists_clipped, bins=\"doane\", density=True)\n",
    "    # Cumulative distribution function of distances\n",
    "    n_bins_dists = 300\n",
    "    dists_axis = np.linspace(dists_clipped.min(), dists_clipped.max(), n_bins_dists)\n",
    "    dists_counts = np.histogram(dists_clipped, bins=dists_axis)[0] / dists_clipped.size\n",
    "    dists_cdf = np.concatenate([[0.0], np.cumsum(dists_counts)])\n",
    "    dist_cdfs[m] = dists_cdf, dists_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66635ac-d120-455f-a632-d7b0a614bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.9, fig.get_size_inches()[1]*1.1)\n",
    "for m in show_models:\n",
    "    lbl = model_nice_names.get(m)\n",
    "    hist_outline(ax, 10.0**dist_histograms[m][1], dist_histograms[m][0], \n",
    "                color=model_colors[m], lw=1.0, label=lbl)\n",
    "handles1, labels1 = ax.get_legend_handles_labels()\n",
    "for m in show_models:\n",
    "    lbl = \"Medians\" if m == \"none\" else None\n",
    "    li = ax.axvline(10.0**dist_stats[m][1], ls=\"--\", color=model_colors[m], \n",
    "               lw=0.75)\n",
    "    if lbl is not None:\n",
    "        handles2, labels2 = [li], [lbl]\n",
    "ax.set(xlabel=r\"Distance $\\|\\mathbf{y}_{\\mathrm{new}} - \\mathbf{y}_{\\mathrm{mix}}\\| / \\|\\mathbf{y}_{\\mathrm{new}}\\|$\", \n",
    "       ylabel=\"Probability density\", xscale=\"log\")\n",
    "ax.set_title(\"Distance to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", pad=15)\n",
    "\n",
    "# Create a legend for the first line.\n",
    "leg_props = dict(frameon=False, borderaxespad=0.3, handlelength=1.2)\n",
    "first_legend = ax.legend(handles=handles1, labels=labels1, loc=\"upper left\", title=\"Model\", **leg_props)\n",
    "# Add the legend manually to the Axes.\n",
    "ax.add_artist(first_legend)\n",
    "# Create another legend for the second line.\n",
    "ax.legend(handles=handles2, labels=labels2, loc='upper right', handletextpad=0.1, **leg_props)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"distance_to_new_odor_histograms_turbulent_back.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfa1e9-63db-4e87-89fb-591203e21ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF. I don't want to show the \"Orthogonal\" model in this figure\n",
    "# but the histograms above show that IBCM and PCA peak at the norm of y_n, perp, \n",
    "# so they implement very well the strategy for which W was optimized. \n",
    "show_models = [\"none\", \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.85, fig.get_size_inches()[1]*1.1)\n",
    "ax.set_title(\"Distance to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", pad=15)\n",
    "for m in show_models:\n",
    "    ax.plot(10.0**dist_cdfs[m][1], dist_cdfs[m][0], \n",
    "                color=model_colors[m], lw=1.0, label=model_nice_names.get(m))\n",
    "ax.set(xlabel=r\"Distance $\\|\\mathbf{y}_{\\mathrm{new}} - \\mathbf{y}_{\\mathrm{mix}}\\| / \\|\\mathbf{y}_{\\mathrm{new}}\\|$\", \n",
    "       ylabel=\"Cumulative distribution\", xscale=\"log\")\n",
    "ax.legend(title=\"Model\", frameon=False)\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"distance_to_new_odor_cdf_turbulent_back.pdf\"), \n",
    "           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fccbb1",
   "metadata": {},
   "source": [
    "# Panel E: odor recognition performance, Jaccard\n",
    "Should highlight somewhere that larger is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jacs = np.load(pj(data_folder, \"jaccard_similarities_identity.npz\"))\n",
    "all_models = list(all_jacs.keys())\n",
    "all_models.remove(\"new_concs\")\n",
    "print(all_jacs[\"ibcm\"].shape)\n",
    "print(all_models)\n",
    "new_concs = all_jacs[\"new_concs\"]\n",
    "# I know these are 0.5x and 1x the average concentration, so use these relative measures instead\n",
    "rel_new_concs = [a/new_concs[1] for a in new_concs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interesting statistics\n",
    "show_models = [\"none\", \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "jac_histograms = {}\n",
    "jac_cdfs = {}\n",
    "jac_stats = {}\n",
    "for m in show_models:\n",
    "    jac_histograms[m] = {}\n",
    "    jac_cdfs[m] = {}\n",
    "    jac_stats[m] = {}\n",
    "    for i in range(len(new_concs)):\n",
    "        conc = new_concs[i]\n",
    "        jacs_sim = all_jacs[m][:, :, :, i].flatten()\n",
    "        jac_histograms[m][conc] = np.histogram(jacs_sim, bins=\"doane\", density=True)\n",
    "        jacs_dists = 1.0 - jacs_sim\n",
    "        # There is only a discrete number of possible J, increments of card(z_n \\cap z_mix)\n",
    "        # So count each value\n",
    "        dists_axis, dists_counts = np.unique(jacs_dists, return_counts=True)\n",
    "        reorder = np.argsort(dists_axis)\n",
    "        dists_axis = dists_axis[reorder]\n",
    "        dists_counts = dists_counts[reorder] / jacs_dists.size\n",
    "        dists_cdf = np.cumsum(dists_counts) \n",
    "        jac_cdfs[m][conc] = dists_cdf, dists_axis\n",
    "        jac_stats[m][conc] = [\n",
    "            np.mean(jacs_sim), \n",
    "            np.median(jacs_sim), \n",
    "            np.var(jacs_sim),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1]*1.1)\n",
    "fig.suptitle(\"Jaccard similarity to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", y=0.92)\n",
    "for i in range(len(new_concs)):\n",
    "    conc = new_concs[i]\n",
    "    conc_rel = rel_new_concs[i]\n",
    "    ax = axes[i]\n",
    "    for m in show_models:\n",
    "        lbl = model_nice_names.get(m) if i ==0 else \"\"\n",
    "        hist_outline(ax, jac_histograms[m][conc][1], jac_histograms[m][conc][0], \n",
    "                    color=model_colors[m], lw=1.0, label=lbl)\n",
    "        lbl = \"Median\" if i == 1 and m == \"none\" else \"\"\n",
    "        ax.axvline(jac_stats[m][conc][1], ls=\"--\", color=model_colors[m], \n",
    "                   lw=0.75, label=lbl)\n",
    "    ax.set(xlabel=r\"Jaccard similarity $(z_{\\mathrm{new}}, z_{\\mathrm{mix}})$\", \n",
    "           ylabel=\"Probability density\", title=r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(conc_rel))\n",
    "    leg_title = \"Model\" if i == 0 else \"\"\n",
    "    ax.legend(frameon=False, title=leg_title, borderaxespad=0.0, handlelength=1.0)\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"jaccard_histograms_turbulent_back.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b7d00-9650-4445-a09f-cb47b25952e8",
   "metadata": {},
   "source": [
    "# Supplementary panel: odor recognition performance cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb46431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDFs\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1])\n",
    "for i in range(len(new_concs)):\n",
    "    conc = new_concs[i]\n",
    "    conc_rel = rel_new_concs[i]\n",
    "    ax = axes[i]\n",
    "    for m in show_models:\n",
    "        ax.plot(jac_cdfs[m][conc][1], jac_cdfs[m][conc][0], \n",
    "                    color=model_colors[m], lw=1.0, label=model_nice_names.get(m))\n",
    "    ax.set(xlabel=r\"Jaccard distance $(z_{\\mathrm{new}}, z_{\\mathrm{mix}})$\", \n",
    "           ylabel=\"Cumulative distribution\", title=r\"New conc. $= {:.1f} \\langle c \\rangle$\".format(conc_rel))\n",
    "    ax.legend(title=\"Model\", frameon=False)\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"jaccard_distances_cdf_turbulent_back.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb28b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
