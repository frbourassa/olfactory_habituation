{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea92fd9f",
   "metadata": {},
   "source": [
    "# Figure 4: analysis of IBCM in turbulent backgrounds\n",
    "This version is with a six-odor, turbulent background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import os, colorsys, json\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072da4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "data_folder = os.path.join(\"..\", \"results\", \"for_plots\")\n",
    "panels_folder = \"panels/\"\n",
    "params_folder = os.path.join(\"..\", \"results\", \"common_params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcd12d",
   "metadata": {},
   "source": [
    "# Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ee39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams\n",
    "with open(os.path.join(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(os.path.join(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(os.path.join(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(os.path.join(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(os.path.join(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full = np.asarray(json.load(f))\n",
    "\n",
    "with open(os.path.join(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(os.path.join(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)\n",
    "model_colors[\"random\"] = \"k\"\n",
    "model_nice_names[\"random\"] = \"Rand. odors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neu = np.load(os.path.join(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"cbars_gamma\"].shape[1]\n",
    "n_components, n_orn = np.load(os.path.join(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"back_vecs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33912f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra aesthetic parameters for this figure\n",
    "\n",
    "# More legend rcParams: make everything smaller by 30 %\n",
    "plt.rcParams[\"patch.linewidth\"] = 0.75\n",
    "legend_rc = {\"labelspacing\":0.5, \"handlelength\":2.0, \"handleheight\":0.7, \n",
    "             \"handletextpad\":0.8, \"borderaxespad\":0.5, \"columnspacing\":2.0}\n",
    "for k in legend_rc:\n",
    "    plt.rcParams[\"legend.\"+k] = 0.75 * legend_rc[k]\n",
    "\n",
    "new_color = \"r\"\n",
    "linestyles = [\"-\", \"--\", \":\", (0, (5, 1, 2, 1)), \"-.\"]\n",
    "neuron_styles = linestyles + [(0, (1, 2, 1, 2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893bc63e",
   "metadata": {},
   "source": [
    "## Smoothing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e99599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_var(points, kernelsize, ddof=1, boundary=\"free\"):\n",
    "    \"\"\" Computing the variance of time series points in a sliding window.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): the data points\n",
    "        kernelsize (int): odd integer giving the window size. \n",
    "        boundary (str): how to deal with points within kernelsize//2 of edges\n",
    "            \"shrink\": the window for a point within distance d < w\n",
    "                is shrunk symmetrically to a kernel of size d\n",
    "            \"free\": the window is asymmetric, full on the inside and clipped\n",
    "                on the side near the edge.\n",
    "            \"noflux\": these points are set to the value of the closest point\n",
    "                with full window (i.e. distance kernelsize//2 of the edge)\n",
    "\n",
    "    Returns:\n",
    "        var_points (np.ndarray): standard deviation at every point\n",
    "    \"\"\"\n",
    "    var_points = np.zeros(points.shape)\n",
    "    # To compute std, we need to compute the average too\n",
    "    avg_points = np.zeros(points.shape)\n",
    "    if kernelsize < 3: raise ValueError(\"Need larger kernel for variance\")\n",
    "    if kernelsize % 2 == 0:  # if an even number was given\n",
    "        kernelsize -= 1\n",
    "    w = kernelsize // 2  # width\n",
    "    end = avg_points.shape[0]  # index of the last element\n",
    "\n",
    "    if boundary not in [\"shrink\", \"free\", \"noflux\"]:\n",
    "        raise ValueError(\"Unknown boundary {}\".format(boundary))\n",
    "\n",
    "    # Smooth the middle points using slicing.\n",
    "    # First store second moment in var_points\n",
    "    var_points[w:end - w] = points[w:end - w]**2\n",
    "    avg_points[w:end - w] = points[w: end - w]\n",
    "    for j in range(w):  # Add points around the middle one\n",
    "        avg_points[w:-w] += points[w - j - 1:end - w - j - 1]\n",
    "        avg_points[w:-w] += points[w + j + 1:end - w + j + 1]\n",
    "        var_points[w:-w] += points[w - j - 1:end - w - j - 1]**2\n",
    "        var_points[w:-w] += points[w + j + 1:end - w + j + 1]**2\n",
    "\n",
    "        # Use the loop to treat the two points at a distance j from boundaries\n",
    "        if j < w and j > 0 and boundary == \"shrink\":\n",
    "            avg_points[j] = np.sum(points[0:2*j + 1], axis=0) / (2*j + 1)\n",
    "            var_points[j] = (np.sum(points[0:2*j + 1]**2, axis=0)\n",
    "                    - avg_points[j]**2 * (2*j + 1)) / (2*j + 1 - ddof)\n",
    "            avg_points[-j - 1] = np.sum(points[-2*j - 1:], axis=0) / (2*j + 1)\n",
    "            var_points[-j - 1] = (np.sum(points[-2*j - 1:]**2, axis=0)\n",
    "                    - avg_points[-j - 1]**2 * (2*j + 1)) / (2*j + 1 - ddof)\n",
    "        elif j < w and boundary == \"free\":\n",
    "            avg_points[j] = np.sum(points[0:j + w + 1], axis=0) / (j + w + 1)\n",
    "            var_points[j] = (np.sum(points[0:j + w + 1]**2, axis=0)\n",
    "                    - avg_points[j]**2 * (j + w + 1)) / (j + w + 1 - ddof)\n",
    "            avg_points[-j - 1] = np.sum(points[-j - w - 1:], axis=0) / (j + w + 1)\n",
    "            var_points[-j - 1] = (np.sum(points[-j - w - 1:]**2, axis=0)\n",
    "                    - avg_points[-j - 1]**2 * (j + w + 1)) / (j + w + 1 - ddof)\n",
    "\n",
    "    # Normalize the middle points by kernelsize - ddof\n",
    "    avg_points[w:end - w] /= kernelsize\n",
    "    var_points[w:end - w] /= (kernelsize - ddof)\n",
    "\n",
    "    # Set the edge points to the nearest full point if boundary is no flux\n",
    "    if boundary == \"noflux\":\n",
    "        var_points[:w] = var_points[w]\n",
    "        var_points[-w:] = var_points[-w]\n",
    "\n",
    "    # Then subtract the average squared, taking ddof into account once\n",
    "    var_points[w:end - w] -= (avg_points[w:end - w]**2\n",
    "                                * kernelsize / (kernelsize - ddof))\n",
    "\n",
    "    return var_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcc6e5",
   "metadata": {},
   "source": [
    "# Panel A: IBCM learning $c_{\\gamma}$s time series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example concentration time series\n",
    "ex = np.load(os.path.join(data_folder, \"sample_turbulent_ibcm_simulation.npz\"))\n",
    "tser_example = np.arange(*ex[\"tser_range\"])\n",
    "cgammaser_example = ex[\"cbars_gamma\"]\n",
    "n_i_ibcm = cgammaser_example.shape[1]\n",
    "sser_example = ex[\"sser\"]\n",
    "analytical_cs_cn = ex[\"cs_cn\"]\n",
    "specif_gammas = ex[\"specif_gammas\"]\n",
    "back_components = ex[\"back_vecs\"]\n",
    "n_b = back_components.shape[0]\n",
    "\n",
    "# Time units per simulation step, for plotting, in ms\n",
    "dt_u = 10.0  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show three neurons\n",
    "# TODO: idea: highlight the specific component only, this way legend easier to read\n",
    "# We don't care about distinguishing the 5 non-specific trajectories, \n",
    "# they all bunch up at the bottom anyways\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(3, 4)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.25, \n",
    "                    plt.rcParams[\"figure.figsize\"][1])\n",
    "ax = fig.add_subplot(gs[:, :3])\n",
    "axi = fig.add_subplot(gs[1, 3:])\n",
    "\n",
    "#ax.axhline(0.0, ls=\"-\", color=(0.8,)*3, lw=0.8)\n",
    "t_axis = tser_example*dt_u/1000/60\n",
    "legend_styles = [[0,]*6, [0,]*6, [0,]*6]\n",
    "i_highlights = [2, 16, 21]  # Neurons to highlight\n",
    "neuron_colors3 = neuron_colors_full[[8, 17, 23]]\n",
    "clr_back = back_palette[-1]\n",
    "plot_skp = 25\n",
    "\n",
    "# plot all other neurons first, skip some points\n",
    "for i in range(n_i_ibcm):\n",
    "    if i in i_highlights: \n",
    "        continue\n",
    "    else: \n",
    "        for j in range(n_b):\n",
    "            ax.plot(t_axis[::plot_skp], cgammaser_example[::plot_skp, i, j], color=clr_back, \n",
    "                ls=\"-\", alpha=1.0-0.1*j, lw=plt.rcParams[\"lines.linewidth\"]-j*0.1)\n",
    "\n",
    "# Now plot the highlighted neuron\n",
    "for j in range(n_b):\n",
    "    for i in range(len(i_highlights)):\n",
    "        li, = ax.plot(t_axis[::plot_skp], cgammaser_example[::plot_skp, i_highlights[i], j], \n",
    "                      color=neuron_colors3[i], ls=\"-\", alpha=1.0-0.1*j, \n",
    "                      lw=plt.rcParams[\"lines.linewidth\"]-j*0.1)\n",
    "        legend_styles[i][j] = li\n",
    "\n",
    "# Annotate with analytical results\n",
    "for j in range(2):\n",
    "    ax.axhline(analytical_cs_cn[j], lw=1.0, ls=\"-.\", color=\"k\")\n",
    "#ax.annotate(r\"Analytical $c_{ns}$\", xy=(t_axis[-5], analytical_cs_cn[1]-0.4), \n",
    "#            ha=\"right\", va=\"top\", color=\"k\", size=6)\n",
    "#ax.annotate(r\"Analytical $c_s$\", xy=(t_axis[-5], analytical_cs_cn[0]+0.4), \n",
    "#            ha=\"right\", va=\"bottom\", color=\"k\", size=6)\n",
    "ax.set(xlabel=\"Time (min)\", \n",
    "       ylabel=r\"Alignments $\\bar{h}^i_{\\gamma} = \\mathbf{\\bar{m}}^i \\cdot \\mathbf{s}_{\\gamma}$\")\n",
    "\n",
    "axi.tick_params(labelleft=True, labelbottom=False, labeltop=True)\n",
    "for i in range(len(i_highlights)):\n",
    "    for j in range(n_b):\n",
    "        li = legend_styles[i][j]\n",
    "        axi.plot([0.0+j, 0.5+j], [0.8*i, 0.8*i], color=li.get_color(), \n",
    "                 ls=li.get_linestyle(), alpha=li.get_alpha(), lw=li.get_linewidth())\n",
    "for side in [\"bottom\", \"left\", \"top\", \"right\"]:\n",
    "    axi.spines[side].set_visible(False)\n",
    "axi.tick_params(axis=\"both\", length=0, pad=3)\n",
    "axi.set_xticks(np.arange(0.25, n_b+0.25, 2.0))\n",
    "#axi.set_xticklabels([r\"$\\mathbf{\\bar{m}}^i \\cdot \\mathbf{s}_a$\", r\"$\\mathbf{\\bar{m}} \\cdot \\mathbf{s}_b$\"])\n",
    "axi.set_xticklabels(list(range(0, n_b, 2)))\n",
    "axi.set_xlabel(r\"Odor $\\gamma$\", size=6, labelpad=3)\n",
    "axi.xaxis.set_label_position('top') \n",
    "axi.set_yticks([0, 0.8, 1.6])\n",
    "axi.invert_yaxis()\n",
    "axi.set_yticklabels([\"${}$\".format(i) for i in i_highlights])\n",
    "#axi.set_yticklabels([\"Neuron 2\", \"Neuron 1\"])\n",
    "axi.set_ylabel(\"Neuron $i$\", size=6, labelpad=1)\n",
    "\n",
    "gs.tight_layout(fig, w_pad=-0.2)\n",
    "fig.savefig(os.path.join(panels_folder, \"sample_turbulent_cgamma_series.pdf\"), \n",
    "           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6431d23f",
   "metadata": {},
   "source": [
    "# Panel B: dot products summary\n",
    "To really show the specificity. Could go to supplementary, or stay if we move analysis of individual simulations to a supplementary figure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95937b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "transient = int(3*tser_example.size/4)\n",
    "cgammas_matrix = np.mean(cgammaser_example[transient:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.6, plt.rcParams[\"figure.figsize\"][1])\n",
    "# Extent: left, right, bottom, top\n",
    "# Greyscale version\n",
    "#ax.imshow(cgammas_matrix, cmap=\"Greys\", aspect=0.6, extent=(0.5, n_b+0.5, 0.5, n_i_ibcm))\n",
    "#ax.set_xticks(list(range(1, n_b+1)))\n",
    "# Colorful version: add patches manually with fill_between. \n",
    "# Color highlighted neurons, leave others grayscale!\n",
    "normed_matrix = (cgammas_matrix - cgammas_matrix.min()) / (cgammas_matrix.max() - cgammas_matrix.min())\n",
    "for i in range(n_i_ibcm):\n",
    "    # Full rainbow version\n",
    "    #cmap = sns.light_palette(neuron_colors_full[i], as_cmap=True)\n",
    "    # Version where only highlights are colored\n",
    "    if i in i_highlights:\n",
    "        cmap = sns.light_palette(neuron_colors3[i_highlights.index(i)], as_cmap=True)\n",
    "    else:\n",
    "        cmap = sns.color_palette(\"Greys\", as_cmap=True)\n",
    "    for j in range(n_b):\n",
    "        ax.fill_between([-0.5+j, 0.5+j], -0.5+i, 0.5+i, color=cmap(normed_matrix[i, j]))\n",
    "        \n",
    "ax.set_xlim([-0.6, -0.6+n_b])\n",
    "ax.set_ylim([-0.6, -0.6+n_i_ibcm])\n",
    "ax.set_xticks(list(range(0, n_b)))\n",
    "ax.set_yticks(list(range(0, 19, 2)) + [21, 23])\n",
    "for i, lbl in enumerate(ax.get_yticklabels()):\n",
    "    if int(lbl.get_text()) in i_highlights:\n",
    "        clr = neuron_colors3[i_highlights.index(int(lbl.get_text()))]\n",
    "        lbl.set_color(clr)\n",
    "        ax.yaxis.get_ticklines()[i].set_color(clr)\n",
    "ax.set(xlabel=r\"Component $\\gamma$\", ylabel=\"IBCM neuron index $i$\")\n",
    "cbar = fig.colorbar(mpl.cm.ScalarMappable(\n",
    "    norm=mpl.colors.Normalize(cgammas_matrix.min(), cgammas_matrix.max()), \n",
    "    cmap=\"Greys\"), ax=ax, label=r\"Alignments ${\\bar{h}\\,}^i_{\\gamma}$ after 45 min\", aspect=30, pad=0.1)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(panels_folder, \"sample_turbulent_cgamma_matrix.pdf\"), \n",
    "            transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(cbar.ax,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e1e55",
   "metadata": {},
   "source": [
    "# Panels C-D: PCA model analysis\n",
    "Show that model is doing its job, when we're lucky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a0ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = np.load(os.path.join(data_folder, \"sample_turbulent_biopca_simulation.npz\"))\n",
    "true_pca_values = ex2[\"true_pca_values\"]\n",
    "true_pca_vectors = ex2[\"true_pca_vectors\"]\n",
    "learnt_pca_values = ex2[\"learnt_pca_values\"]\n",
    "learnt_pca_vectors = ex2[\"learnt_pca_vectors\"]\n",
    "align_error_ser = ex2[\"align_error_ser\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First plot: eigenvalues\n",
    "n_comp = learnt_pca_values.shape[1]\n",
    "pca_palette = sns.color_palette(\"colorblind\", n_colors=n_comp)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(n_comp):\n",
    "    li, = ax.plot(tser_example*dt_u/1000/60, learnt_pca_values[:, i], label=\"Value {}\".format(i),\n",
    "                  lw=plt.rcParams[\"lines.linewidth\"] - 0.5*i/n_comp, zorder=10-i, color=pca_palette[i])\n",
    "    if true_pca_values[i] / true_pca_values.max() > 1e-12:\n",
    "        ax.axhline(true_pca_values[i], ls=\"--\", color=pca_palette[i], \n",
    "                   lw=plt.rcParams[\"lines.linewidth\"] - 0.5*i/n_comp, zorder=n_comp-i)\n",
    "ax.set(ylabel=\"Principal values (diag$(L)$)\", yscale=\"log\", xlabel=\"Time (min)\")\n",
    "# TODO: custom legend to indicate analytical vs learnt?\n",
    "handles = [mpl.lines.Line2D([0], [0], color=\"grey\", ls=\"-\", label=r\"BioPCA ($L$ diagonal)\", \n",
    "                            lw=plt.rcParams[\"lines.linewidth\"]), \n",
    "          mpl.lines.Line2D([0], [0], color=\"grey\", ls=\"--\", label=\"True PCA\", \n",
    "                          lw=plt.rcParams[\"lines.linewidth\"])]\n",
    "leg = ax.legend(handles=handles, frameon=False)\n",
    "leg.set_zorder(30)\n",
    "ax.set_ylim([ax.get_ylim()[0]*0.8, ax.get_ylim()[1]])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(panels_folder, \"biopca_eigenvalues_turbulent_example.pdf\"), \n",
    "            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(tser_example*dt_u/1000/60, align_error_ser, color=\"k\")\n",
    "ax.set(yscale=\"log\", ylabel=\"Subspace alignment error\", xlabel=\"Time (min)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"biopca_align_error_turbulent_example.pdf\"), \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fada5-8b6f-41cd-a835-86ea65743a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved statistics\n",
    "all_jacs_stats = pd.read_hdf(os.path.join(data_folder, \"jaccard_similarities_stats_dimensionality_identity.hdf\"), key=\"df\")\n",
    "all_dists_stats = pd.read_hdf(os.path.join(data_folder, \"new_mix_distances_stats_dimensionality_identity.hdf\"), key=\"df\")\n",
    "animals_ns = {\"Fly\": 50.0, \"Human\": 300.0, \"Mouse\": 1000.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edfb72-5662-4377-9707-ed6ab3d6d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for two new odor concentrations? Or just one, keep the four tested concs. for supplementary. \n",
    "average_conc = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())[1]\n",
    "n_new_concs = 1\n",
    "keep_conc = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())[1:n_new_concs+1]\n",
    "ns_range = np.sort(all_jacs_stats.index.get_level_values(\"N_S\").unique())\n",
    "fig, axes = plt.subplots(1, n_new_concs, sharex=True, sharey=True)\n",
    "if n_new_concs == 1: axes = [axes]\n",
    "else: axes = axes.flatten()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.2, plt.rcParams[\"figure.figsize\"][1])\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        lower = (all_jacs_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 - np.sqrt(all_jacs_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(lower=0.0)\n",
    "        upper = (all_jacs_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 + np.sqrt(all_jacs_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(upper=1.0)\n",
    "        axes[i].fill_between(ns_range, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        axes[i].plot(ns_range, all_jacs_stats.loc[(m, ns_range, new_conc), \"mean\"], \n",
    "            label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "            ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "        )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "for i in range(n_new_concs):\n",
    "    axes[i].set_title(r\"New odor concentration $= \\langle c \\rangle$\".format(int(keep_conc[i]/average_conc)))\n",
    "    axes[i].set_xlabel(r\"OSN space dimensionality, $N_S$\")\n",
    "    axes[i].set_ylabel(\"Mean Jaccard similarity\")\n",
    "    ylim = axes[i].get_ylim()\n",
    "    axes[i].set_ylim([ylim[0], 1.05])\n",
    "    axes[i].set_xscale(\"log\")\n",
    "leg_title = \"Model\"\n",
    "axes[-1].legend(loc=\"upper left\", bbox_to_anchor=(0.98, 1.), frameon=False, \n",
    "                title=leg_title, borderaxespad=0.0, handlelength=1.5)\n",
    "for ani in animals_ns:\n",
    "    for i in range(n_new_concs):\n",
    "        axes[i].axvline(animals_ns[ani], ls=\":\", color=\"k\", lw=0.5, zorder=0)\n",
    "        axes[i].annotate(ani, (animals_ns[ani]*0.98, 1.05), ha=\"right\", va=\"top\", fontsize=6)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"jaccard_vs_dimension_oneconc.pdf\"),\n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b95113-eb1e-4a5c-adb1-151b8655fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for two new odor concentrations? Or just one, keep the four tested concs. for supplementary. \n",
    "chosen_ns = 50  # Fly case\n",
    "new_concs = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())\n",
    "new_concs_multiples = np.round(new_concs / average_conc, 1)\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.88, plt.rcParams[\"figure.figsize\"][1])\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    lower = (all_jacs_stats.loc[(m, chosen_ns, new_concs), \"mean\"] \n",
    "             - np.sqrt(all_jacs_stats.loc[(m, chosen_ns, new_concs), \"var\"])).clip(lower=0.0)\n",
    "    upper = (all_jacs_stats.loc[(m, chosen_ns, new_concs), \"mean\"] \n",
    "             + np.sqrt(all_jacs_stats.loc[(m, chosen_ns, new_concs), \"var\"])).clip(upper=1.0)\n",
    "    ax.fill_between(new_concs_multiples, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    ax.plot(new_concs_multiples, all_jacs_stats.loc[(m, chosen_ns, new_concs), \"mean\"], \n",
    "        label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "        ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "    )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "ns_animals = {v:k for k, v in animals_ns.items()}\n",
    "ax.set_title(r\"OSN dimension $N_S = {0:d}$ ({1})\".format(chosen_ns, ns_animals[chosen_ns]))\n",
    "ax.set_xlabel(r\"New odor conc. (multiple of $\\langle c \\rangle$)\")\n",
    "ax.set_ylabel(\"Mean Jaccard similarity\")\n",
    "ylim = ax.get_ylim()\n",
    "ax.set_ylim([ylim[0], 1.05])\n",
    "leg_title = \"Model\"\n",
    "#ax.legend(loc=\"upper left\", bbox_to_anchor=(0.98, 1.), frameon=False, \n",
    "#                title=leg_title, borderaxespad=0.0, handlelength=1.5)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"jaccard_vs_newconc_onedim.pdf\"),\n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bf5f4-7444-4102-baf9-341040c7f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary version with multiple panels for several OSN space sizes\n",
    "new_concs = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())\n",
    "ns_range = [25, 50, 75, 100, 300, 600, 1000]\n",
    "ncols = 4\n",
    "nrows = len(ns_range) // ncols + min(1, len(ns_range) % ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*ncols * 0.8, \n",
    "                    plt.rcParams[\"figure.figsize\"][1] * nrows * 0.8)\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    for i in range(len(ns_range)):\n",
    "        ns = ns_range[i]\n",
    "        lower = (all_jacs_stats.loc[(m, ns, new_concs), \"mean\"] \n",
    "                 - np.sqrt(all_jacs_stats.loc[(m, ns, new_concs), \"var\"])).clip(lower=0.0)\n",
    "        upper = (all_jacs_stats.loc[(m, ns, new_concs), \"mean\"] \n",
    "                 + np.sqrt(all_jacs_stats.loc[(m, ns, new_concs), \"var\"])).clip(upper=1.0)\n",
    "        axes[i].fill_between(new_concs, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    for i in range(len(ns_range)):\n",
    "        ns = ns_range[i]\n",
    "        axes[i].plot(new_concs, all_jacs_stats.loc[(m, ns, new_concs), \"mean\"], \n",
    "            label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "            ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "        )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "ns_animals = {v:k for k, v in animals_ns.items()}\n",
    "for i in range(len(ns_range)):\n",
    "    ns = ns_range[i]\n",
    "    ti = r\"$N_S = {:d}$\".format(ns)\n",
    "    if ns in ns_animals:\n",
    "        ti += \" (\" + ns_animals[ns] + \")\"\n",
    "    axes[i].set_title(ti, y=0.85)\n",
    "    if nrows*ncols - i <= ncols:\n",
    "        axes[i].set_xlabel(r\"New concentration $c$\")\n",
    "    axes[i].set_ylabel(\"Mean Jaccard similarity\")\n",
    "    ylim = axes[i].get_ylim()\n",
    "    axes[i].set_ylim([ylim[0], 1.05])\n",
    "for i in range(len(ns_range), ncols*nrows):\n",
    "    axes[i].set_axis_off()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "leg_title = \"Model\"\n",
    "axes[-1].legend(handles, labels, loc=\"center\", bbox_to_anchor=(0.5, 0.5), frameon=False, \n",
    "                title=leg_title, borderaxespad=0.0, handlelength=1.5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(panels_folder, \"supp_jaccard_vs_newconc_alldims.pdf\"),\n",
    "            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847728f-ef46-4632-b8a6-99736f496381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of distance to new odor for all odor concentrations, for supplementary figures. \n",
    "n_new_concs = 4\n",
    "keep_conc = np.sort(all_dists_stats.index.get_level_values(\"new_conc\").unique())[0:n_new_concs]\n",
    "ns_range = np.sort(all_dists_stats.index.get_level_values(\"N_S\").unique())\n",
    "fig, axes = plt.subplots(2, n_new_concs // 2, sharex=True, sharey=True)\n",
    "if n_new_concs == 1: axes = [axes]\n",
    "else: axes = axes.flatten()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.75, plt.rcParams[\"figure.figsize\"][1]*1.75)\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        lower = (all_dists_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 - np.sqrt(all_dists_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(lower=0.0)\n",
    "        upper = (all_dists_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 + np.sqrt(all_dists_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(upper=1.0)\n",
    "        axes[i].fill_between(ns_range, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        axes[i].plot(ns_range, all_dists_stats.loc[(m, ns_range, new_conc), \"mean\"], \n",
    "            label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "            ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "        )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "for i in range(n_new_concs):\n",
    "    axes[i].set_title(r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(keep_conc[i] / average_conc), y=1.0)\n",
    "    if i >= 2:\n",
    "        axes[i].set_xlabel(r\"OSN space dimensionality, $N_S$\")\n",
    "    axes[i].set_ylabel(r\"Mean dist. $\\langle\\|y_{\\mathrm{new}} - y_{\\mathrm{mix}}\\|\\rangle$\")\n",
    "    axes[i].set_xscale(\"log\")\n",
    "    axes[i].set_yscale(\"log\")\n",
    "leg_title = \"Model\"\n",
    "axes[-1].legend(loc=\"lower left\",  frameon=False, ncols=2, title=leg_title, \n",
    "                borderaxespad=0.0, handlelength=1.5, alignment=\"left\")\n",
    "for ani in animals_ns:\n",
    "    for i in range(n_new_concs):\n",
    "        axes[i].axvline(animals_ns[ani], ls=\":\", color=\"k\", lw=0.5, zorder=0)\n",
    "        axes[i].annotate(ani, (animals_ns[ani]*0.95, 1.05), ha=\"right\", va=\"bottom\", fontsize=6)\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"supp_distance_vs_dimension_allconcs.pdf\"),\n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213f2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance time series\n",
    "ex_s = np.load(os.path.join(data_folder, \"sser_norm_turbulent_model_comparison.npz\"))\n",
    "show_models = [\"none\", \"avgsub\", \"biopca\", \"ibcm\", \"ideal\"]\n",
    "# Variance averaged over a time window\n",
    "std_options = dict(kernelsize=1500, boundary=\"free\")\n",
    "std_series = {\n",
    "    a: np.sqrt(moving_var(ex_s[a], **std_options)) for a in show_models\n",
    "}\n",
    "# For reference, the averaging time window in minutes\n",
    "step_size = tser_example[1] - tser_example[0]\n",
    "avg_time_min = std_options[\"kernelsize\"] * dt_u / 1000 / 60 * step_size\n",
    "print(\"Sliding time window length:\", avg_time_min, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for mod in show_models:\n",
    "    ax.plot(tser_example*dt_u/1000/60, ex_s[mod], label=model_nice_names[mod], \n",
    "           color=model_colors[mod], lw=0.5)\n",
    "ax.set(xlabel=\"Time (min)\")\n",
    "ax.set_ylabel(r\"PN activity norm, $\\|\\mathbf{s}\\|$\", labelpad=4)\n",
    "ax.set_ylim([ax.get_ylim()[0], ax.get_ylim()[1]*1.2])\n",
    "ax.legend(frameon=False, title=\"Habituation model\", ncol=2)\n",
    "fig.savefig(os.path.join(panels_folder, \"sser_norm_turbulent_model_comparison.pdf\"), \n",
    "            transparent=True, bbox_inches=\"tight\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for mod in show_models:\n",
    "    ax.plot(tser_example*dt_u/1000/60, std_series[mod], label=model_nice_names[mod], \n",
    "           color=model_colors[mod])\n",
    "ax.set(xlabel=\"Time (min)\")\n",
    "ax.set_ylabel(r\"PN norm st. dev., $\\sigma_{\\|\\mathbf{s}\\|}$\", labelpad=4)\n",
    "ax.set_ylim([ax.get_ylim()[0], ax.get_ylim()[1]*1.6])\n",
    "ax.legend(frameon=False, title=\"Habituation model\", ncol=2)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(panels_folder, \"sser_norm_stdev_turbulent_model_comparison.pdf\"), \n",
    "            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afaf90",
   "metadata": {},
   "source": [
    "# Supplementary panel: IBCM eigenvalues\n",
    "This will go to supplementary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load eigenvalues for this example\n",
    "with open(os.path.join(data_folder, \"ibcm_eigenvalues_keys_turbulent_example.json\"), \"r\") as f:\n",
    "    ibcm_specif_keys = json.load(f)\n",
    "\n",
    "ibcm_eig_values=ex[\"ibcm_eig_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "reals, imags = np.real(ibcm_eig_values), np.imag(ibcm_eig_values)\n",
    "ibcm_eig_values_specif1 = np.asarray([len(s) == 1 for s in ibcm_specif_keys], dtype=bool)\n",
    "highlights = ibcm_eig_values_specif1\n",
    "ax.axvline(0.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "ax.axhline(0.0, ls=\"--\", color=\"k\", lw=1.0)\n",
    "scaleup = 1e3\n",
    "ax.plot(reals[highlights]*scaleup, imags[highlights]*scaleup, marker=\"*\", \n",
    "        mfc=model_colors[\"ibcm\"], mec=model_colors[\"ibcm\"], \n",
    "        ls=\"none\", label=\"One odor\", ms=5)\n",
    "ax.plot(reals[~highlights]*scaleup, imags[~highlights]*scaleup, marker=\"o\", mfc=\"k\", mec=\"k\", \n",
    "       ls=\"none\", label=\"0 or 2+ odors\", ms=3, alpha=0.7)\n",
    "for side in (\"top\", \"right\"):\n",
    "    ax.spines[side].set_visible(False)\n",
    "ax.legend(title=\"Specificity of\\nthe fixed point\", loc=\"center right\", title_fontsize=6)\n",
    "ax.set(xlabel=r\"$\\mathrm{Re}(\\lambda_{\\mathrm{max}})$    ($\\times 10^{-3}$)\", \n",
    "      ylabel=r\"$\\mathrm{Im}(\\lambda_{\\mathrm{max}})$     ($\\times 10^{-3}$)\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"ibcm_jacobian_max_eigenvalues_turbulent.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a38cae-0760-4f8f-98f3-b915d7821030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
