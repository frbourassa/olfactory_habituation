{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence of IBCM and BioPCA habituation to turbulent backgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import seaborn as sns\n",
    "import os, json\n",
    "pj = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_save_plots = True\n",
    "# Resources\n",
    "root_dir = pj(\"..\", \"..\", \"..\")\n",
    "data_folder = pj(root_dir, \"results\", \"for_plots\")\n",
    "data_folder_conv = pj(root_dir, \"results\", \"for_plots\", \"convergence\")\n",
    "panels_folder = \"panels/\"\n",
    "params_folder = pj(root_dir, \"results\", \"common_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams\n",
    "with open(pj(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(pj(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(pj(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(pj(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(pj(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full = np.asarray(json.load(f))\n",
    "\n",
    "with open(pj(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(pj(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)\n",
    "\n",
    "models = list(model_colors.keys())\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra aesthetic parameters for this figure\n",
    "# Figures slightly less high, to squeeze four rows of plots\n",
    "plt.rcParams[\"figure.figsize\"] = (plt.rcParams[\"figure.figsize\"][0], 1.6)\n",
    "\n",
    "# More legend rcParams: make everything smaller by 30 %\n",
    "plt.rcParams[\"patch.linewidth\"] = 0.75\n",
    "legend_rc = {\"labelspacing\":0.5, \"handlelength\":2.0, \"handleheight\":0.7, \n",
    "             \"handletextpad\":0.8, \"borderaxespad\":0.5, \"columnspacing\":2.0}\n",
    "for k in legend_rc:\n",
    "    plt.rcParams[\"legend.\"+k] = 0.75 * legend_rc[k]\n",
    "\n",
    "new_color = \"r\"\n",
    "linestyles = [\"-\", \"--\", \":\", (0, (5, 1, 2, 1)), \"-.\"]\n",
    "neuron_styles = linestyles + [(0, (1, 2, 1, 2))]\n",
    "\n",
    "markerstyles = [\"o\", \"s\", \"^\", \"v\", \"X\", \"*\", \"d\", \"h\", \"<\", \"p\", \"P\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBCM plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ibcm_hgammas_series(t_axis, i_highlights, hgammaser, squeeze=0.65, figax=[]):\n",
    "    # Show three neurons\n",
    "    if figax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    else:\n",
    "        fig, ax = figax\n",
    "    # By default, we squeeze to be able to put matrix of hgammas series besides\n",
    "    fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*squeeze, \n",
    "                        plt.rcParams[\"figure.figsize\"][1])\n",
    "\n",
    "    #ax.axhline(0.0, ls=\"-\", color=(0.8,)*3, lw=0.8)\n",
    "    legend_styles = [[0,]*6, [0,]*6, [0,]*6]\n",
    "    neuron_colors3 = neuron_colors_full[[8, 17, 23]]\n",
    "    clr_back = back_palette[-1]\n",
    "    plot_skp = 20\n",
    "    n_b = hgammaser.shape[2]\n",
    "\n",
    "    # plot all other neurons first, skip some points\n",
    "    for i in range(n_i_ibcm):\n",
    "        if i in i_highlights: \n",
    "            continue\n",
    "        elif i % 2 == 0:   # thinning\n",
    "            continue\n",
    "        else: \n",
    "            for j in range(n_b):\n",
    "                ax.plot(t_axis[::plot_skp], hgammaser[::plot_skp, i, j], color=clr_back, \n",
    "                    ls=\"-\", alpha=1.0-0.1*j, lw=plt.rcParams[\"lines.linewidth\"]-j*0.1)\n",
    "\n",
    "    # Now plot the highlighted neuron\n",
    "    for j in range(n_b):\n",
    "        for i in range(len(i_highlights)):\n",
    "            li, = ax.plot(t_axis[::plot_skp], hgammaser[::plot_skp, i_highlights[i], j], \n",
    "                          color=neuron_colors3[i], ls=\"-\", alpha=1.0-0.2*j, \n",
    "                          lw=plt.rcParams[\"lines.linewidth\"]-j*0.2)\n",
    "            legend_styles[i][j] = li\n",
    "    \n",
    "    # Annotations\n",
    "    ax.set(xlabel=\"Time (min)\", \n",
    "           ylabel=r\"Alignments $\\bar{h}_{i\\gamma} = \\mathbf{\\bar{m}}_i \\cdot \\mathbf{s}_{\\gamma}$\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def plot_ibcm_hgammas_matrix(hgammas_mat, i_high, squeeze=0.4):\n",
    "    n_i, n_comp = hgammas_mat.shape\n",
    "    neuron_colors3 = neuron_colors_full[[8, 17, 23]]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*squeeze, \n",
    "                        plt.rcParams[\"figure.figsize\"][1])\n",
    "    # Extent: left, right, bottom, top\n",
    "    # Greyscale version\n",
    "    #ax.imshow(hgammas_matrix, cmap=\"Greys\", aspect=0.6, extent=(0.5, n_comp+0.5, 0.5, n_i))\n",
    "    #ax.set_xticks(list(range(1, n_comp+1)))\n",
    "    # Colorful version: add patches manually with fill_between. \n",
    "    # Color highlighted neurons, leave others grayscale!\n",
    "    normed_matrix = (hgammas_mat - hgammas_mat.min()) / (hgammas_mat.max() - hgammas_mat.min())\n",
    "    for i in range(n_i):\n",
    "        # Full rainbow version\n",
    "        #cmap = sns.light_palette(neuron_colors_full[i], as_cmap=True)\n",
    "        # Version where only highlights are colored\n",
    "        if i in i_high:\n",
    "            cmap = sns.light_palette(neuron_colors3[i_high.index(i)], as_cmap=True)\n",
    "        else:\n",
    "            cmap = sns.color_palette(\"Greys\", as_cmap=True)\n",
    "        for j in range(n_comp):\n",
    "            ax.fill_between([-0.5+j, 0.5+j], -0.5+i, 0.5+i, color=cmap(normed_matrix[i, j]))\n",
    "\n",
    "    ax.set_xlim([-0.6, -0.6+n_comp])\n",
    "    ax.set_ylim([-0.6, -0.6+n_i])\n",
    "    ax.set_yticks(list(range(0, n_i, 2)))\n",
    "\n",
    "    for i, lbl in enumerate(ax.get_yticklabels()):\n",
    "        if int(lbl.get_text()) in i_high:\n",
    "            clr = neuron_colors3[i_high.index(int(lbl.get_text()))]\n",
    "            lbl.set_color(clr)\n",
    "            ax.yaxis.get_ticklines()[i].set_color(clr)\n",
    "\n",
    "    ax.set_xlabel(r\"Component $\\gamma$\", size=6)\n",
    "    ax.set_ylabel(r\"IBCM neuron index $i$\", size=6)\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(\n",
    "        norm=mpl.colors.Normalize(hgammas_mat.min(), hgammas_mat.max()), \n",
    "        cmap=\"Greys\"), ax=ax, aspect=30, pad=0.1)\n",
    "    cbar.set_ticks([])\n",
    "    cbar.set_label(label=r\"Alignments ${\\bar{h}}_{i\\gamma}$, 45 min\", fontsize=6)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax, cbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ibcm_hgammas_series_percomp(t_axis, comp_high, hgammaser, n_b, figax=None):\n",
    "    \"\"\" Assumes a separate hgammas matrix will be plotted as a legend \"\"\"\n",
    "    if figax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.75, \n",
    "                        plt.rcParams[\"figure.figsize\"][1])\n",
    "    else:\n",
    "        fig, ax = figax\n",
    "\n",
    "    odor_colors = sns.color_palette(\"colorblind\", n_colors=n_b)\n",
    "    clr_back = back_palette[-1]\n",
    "    plot_skp = 20\n",
    "\n",
    "    # plot all other components first, skip some points\n",
    "    for j in range(n_b):\n",
    "        if j in comp_high: \n",
    "            continue\n",
    "        else:\n",
    "            for i in range(0, n_i_ibcm, 2):\n",
    "                ax.plot(t_axis[::plot_skp], hgammaser[::plot_skp, i, j], color=clr_back, \n",
    "                    ls=\"-\", alpha=0.8, lw=plt.rcParams[\"lines.linewidth\"])\n",
    "\n",
    "    # Now plot the highlighted components\n",
    "    for j in range(len(comp_high)):\n",
    "        for i in range(0, n_i_ibcm):\n",
    "            lbl = r\"$\\gamma = {}$\".format(j) if i == 0 else \"\"\n",
    "            li, = ax.plot(t_axis[::plot_skp], hgammaser[::plot_skp, i, comp_high[j]], \n",
    "                          color=odor_colors[j], ls=\"-\", alpha=1.0-0.05*i, \n",
    "                          label=lbl, lw=plt.rcParams[\"lines.linewidth\"]-0.05*i)\n",
    "\n",
    "    ax.set(xlabel=\"Time (min)\", \n",
    "           ylabel=r\"Alignments $\\bar{h}_{i\\gamma} = \\mathbf{\\bar{m}}_i \\cdot \\mathbf{s}_{\\gamma}$\")\n",
    "    ax.legend(frameon=False, title=\"Component\", title_fontsize=6)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_ibcm_hgammas_matrix_percomp(hgammas_mat, comp_high, n_i, n_comp):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.6, \n",
    "                        plt.rcParams[\"figure.figsize\"][1])\n",
    "    \n",
    "    normed_matrix = (hgammas_mat - hgammas_mat.min()) / (hgammas_mat.max() - hgammas_mat.min())\n",
    "    odor_colors = sns.color_palette(\"colorblind\", n_colors=n_comp)\n",
    "    for j in range(n_comp):\n",
    "        if j in comp_high:\n",
    "            cmap = sns.light_palette(odor_colors[comp_high.index(j)], as_cmap=True)\n",
    "        else:\n",
    "            cmap = sns.color_palette(\"Greys\", as_cmap=True)\n",
    "        for i in range(n_i):\n",
    "            ax.fill_between([-0.5+j, 0.5+j], -0.5+i, 0.5+i, color=cmap(normed_matrix[i, j]))\n",
    "\n",
    "    ax.set_xlim([-0.6, -0.6+n_comp])\n",
    "    ax.set_ylim([-0.6, -0.6+n_i])\n",
    "    ax.set_xticks(list(range(0, n_comp)))\n",
    "    ax.set_yticks(list(range(0, n_i, 2)))\n",
    "\n",
    "    for j, lbl in enumerate(ax.get_xticklabels()):\n",
    "        if int(lbl.get_text()) in comp_high:\n",
    "            clr = odor_colors[comp_high.index(int(lbl.get_text()))]\n",
    "            lbl.set_color(clr)\n",
    "            ax.xaxis.get_ticklines()[j].set_color(clr)\n",
    "    ax.set(xlabel=r\"Component $\\gamma$\", ylabel=\"IBCM neuron index $i$\")\n",
    "    cbar = fig.colorbar(mpl.cm.ScalarMappable(\n",
    "        norm=mpl.colors.Normalize(hgammas_mat.min(), hgammas_mat.max()), \n",
    "        cmap=\"Greys\"), ax=ax, label=r\"Alignments ${\\bar{h}}_{i\\gamma}$, 45 min\", aspect=30, pad=0.1)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax, cbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load IBCM simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract saved simulation\n",
    "with np.load(pj(data_folder_conv, \"non-gaussian_ibcm_convergence_analysis.npz\")) as fp:\n",
    "    hgammas_ser = fp[\"hgammas_ser\"]\n",
    "    tser_scaled = fp[\"tser_scaled\"]\n",
    "    specifs = fp[\"hgammas_specifs\"]\n",
    "    th_predictions = fp[\"th_predictions\"]\n",
    "    tu_predictions = fp[\"tu_predictions\"]\n",
    "    horiz_lines = fp[\"horiz_lines\"]\n",
    "    backnorm_ser = fp[\"backnorm_ser\"]\n",
    "    ynorm_ser = fp[\"ynorm_ser\"]\n",
    "    moments_conc = fp[\"moments_conc\"]\n",
    "    fixed_point_preds = fp[\"fixed_point_preds\"]\n",
    "    saddle_hd_divmean, saddle_u2, target_u2 = horiz_lines\n",
    "    learnrate_mscale = fp[\"learnrate_mscale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel A: good IBCM example, annotation of convergence metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu_scale = 1.0 / 100.0 / 60.0  # 10 ms steps to min\n",
    "n_i_ibcm = hgammas_ser.shape[1]\n",
    "nsteps = hgammas_ser.shape[0]\n",
    "n_components = hgammas_ser.shape[2]\n",
    "tser_example = tser_scaled  # in min\n",
    "\n",
    "transient = int(3*tser_example.size/4)\n",
    "i_highlights = [0, 1, 4]  # Neurons to highlight\n",
    "\n",
    "hgammas_matrix = np.mean(hgammas_ser[transient:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True)\n",
    "ax = axes[0]\n",
    "#fig, ax = plot_ibcm_hgammas_series(tser_example, i_highlights, hgammas_ser, \n",
    "#                                   squeeze=1.0, figax=[fig, axes[0]])\n",
    "fig, ax = plot_ibcm_hgammas_series_percomp(tser_example, [0, 1, 2], hgammas_ser, \n",
    "                                           n_components, figax=[fig, ax])\n",
    "# Remove x label\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "# Annotate with learning rate and initial conditions\n",
    "ax.set_title((r\"Learning rate: $\\mu =\" +\" {:.1f}\".format(learnrate_mscale[0]/tu_scale) \n",
    "              + r\" \\,\\mathrm{s^{-1}}$\"), y=0.98)\n",
    "arrowprops = {\"arrowstyle\": \"<->\", \"lw\":0.75, \"color\":\"k\"}\n",
    "arrowprops.update({\"lw\": 0.5, \"arrowstyle\":\"->\", \"shrinkB\":0.01})\n",
    "xannot = 5.0\n",
    "hgampad = 0.1\n",
    "arrowlen = 0.6\n",
    "ax.annotate(\"\", xy=(xannot, hgampad), xytext=(xannot, hgampad+arrowlen), arrowprops=arrowprops)\n",
    "ax.annotate(\"\", xy=(xannot, -hgampad), xytext=(xannot, -hgampad-arrowlen), arrowprops=arrowprops)\n",
    "ax.annotate((r\"$m_{\\gamma, \\mathrm{init}} \\sim \" + \"{:d}\".format(int(learnrate_mscale[1]*1e4)) \n",
    "             + r\" \\times 10^{-4}$\"), xy=(xannot-5.0, -hgampad-arrowlen), \n",
    "            ha=\"left\", va=\"top\", fontsize=5)\n",
    "\n",
    "# Adjust size for second subplot\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0], plt.rcParams[\"figure.figsize\"][1]*1.75)\n",
    "\n",
    "# Combine plot with the y norm series, to see when it habituates\n",
    "n_odors = hgammas_ser.shape[1]\n",
    "ax2 = axes[1]\n",
    "tsl = slice(None, None, 20)\n",
    "ax2.plot(tser_example[tsl], backnorm_ser[tsl], color=\"grey\", alpha=0.8)\n",
    "ax2.plot(tser_example[tsl], ynorm_ser[tsl], color=\"k\", alpha=0.8)\n",
    "ax2.set(xlabel=\"Time (min)\", ylabel=\"PN activity norm\")\n",
    "\n",
    "th_pred_lastcomp = th_predictions[np.argmax(specifs == 1)]\n",
    "lastcomp_color = sns.color_palette(\"colorblind\")[1]\n",
    "for ax in axes:\n",
    "    ax.axvline(th_pred_lastcomp, ls=\"--\", color=lastcomp_color)\n",
    "\n",
    "txt = ax2.annotate(\"Predicted $t_h$ for\\nlast covered odor\", xy=(th_pred_lastcomp+1, ax.get_ylim()[1]*0.98), \n",
    "            ha=\"left\", va=\"top\", fontsize=6, color=lastcomp_color)\n",
    "txt.set_bbox(dict(facecolor='w', alpha=0.8, edgecolor='none', pad=0))\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_hgamma_example.pdf\"), \n",
    "                transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax, axi = plot_ibcm_hgammas_matrix_percomp(hgammas_matrix, [0, 1, 2], n_i_ibcm, n_components)\n",
    "# Extra annotations\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.4, plt.rcParams[\"figure.figsize\"][1]*0.9)\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_hgamma_matrix_example.pdf\"), \n",
    "                transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel B: other IBCM example, larger $\\mu$, analytics still work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract saved simulation\n",
    "with np.load(pj(data_folder_conv, \"non-gaussian_ibcm_convergence_analysis_highmu.npz\")) as fp:\n",
    "    hgammas_ser_himu = fp[\"hgammas_ser\"]\n",
    "    tser_scaled_himu = fp[\"tser_scaled\"]\n",
    "    tser_example_himu = tser_scaled_himu\n",
    "    specifs_himu = fp[\"hgammas_specifs\"]\n",
    "    th_predictions_himu = fp[\"th_predictions\"]\n",
    "    tu_predictions_himu = fp[\"tu_predictions\"]\n",
    "    horiz_lines_himu = fp[\"horiz_lines\"]\n",
    "    backnorm_ser_himu = fp[\"backnorm_ser\"]\n",
    "    ynorm_ser_himu = fp[\"ynorm_ser\"]\n",
    "    moments_conc_himu = fp[\"moments_conc\"]\n",
    "    fixed_point_preds_himu = fp[\"fixed_point_preds\"]\n",
    "    learnrate_mscale = fp[\"learnrate_mscale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True)\n",
    "ax = axes[0]\n",
    "#fig, ax = plot_ibcm_hgammas_series(tser_example, i_highlights, hgammas_ser, \n",
    "#                                   squeeze=1.0, figax=[fig, axes[0]])\n",
    "fig, ax = plot_ibcm_hgammas_series_percomp(tser_example_himu, [0, 1, 2], hgammas_ser_himu, \n",
    "                                           n_components, figax=[fig, ax])\n",
    "# Remove x label\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "# Annotate with learning rate and initial conditions. \n",
    "# Learning rate here is 0.002, m initial scale is 2e-3 (1 + fluctuating part of 1e-3)\n",
    "ax.set_title((r\"Learning rate: $\\mu =\" +\" {:.1f}\".format(learnrate_mscale[0]/tu_scale) \n",
    "                + r\" \\,\\mathrm{s^{-1}}$\"), y=0.98)\n",
    "arrowprops = {\"arrowstyle\": \"<->\", \"lw\":0.75, \"color\":\"k\"}\n",
    "arrowprops.update({\"lw\": 0.5, \"arrowstyle\":\"->\", \"shrinkB\":0.01})\n",
    "xannot = 1.0\n",
    "hgampad = 0.1\n",
    "arrowlen = 0.6\n",
    "ax.annotate(\"\", xy=(xannot, hgampad), xytext=(xannot, hgampad+arrowlen), arrowprops=arrowprops)\n",
    "ax.annotate(\"\", xy=(xannot, -hgampad), xytext=(xannot, -hgampad-arrowlen), arrowprops=arrowprops)\n",
    "txt = ax.annotate((r\"$m_{\\gamma, \\mathrm{init}} \\sim \" + \"{:d}\".format(int(learnrate_mscale[1]*1e3)) \n",
    "             + r\" \\times 10^{-3}$\"), xy=(xannot-1.0, -hgampad-arrowlen), \n",
    "            ha=\"left\", va=\"top\", fontsize=5, annotation_clip=False)\n",
    "txt.set_bbox(dict(facecolor='w', alpha=0.8, edgecolor='none', pad=0))\n",
    "# Re-do legend with title to save space\n",
    "ax.legend(frameon=False, loc=\"upper right\", bbox_to_anchor=(1.0, 0.75))\n",
    "\n",
    "# Adjust size for second subplot\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0], plt.rcParams[\"figure.figsize\"][1]*1.75)\n",
    "\n",
    "# Combine plot with the y norm series, to see when it habituates\n",
    "n_odors = hgammas_ser_himu.shape[1]\n",
    "ax2 = axes[1]\n",
    "tsl = slice(None, None, 20)\n",
    "ax2.plot(tser_example_himu[tsl], backnorm_ser_himu[tsl], color=\"grey\", alpha=0.8)\n",
    "ax2.plot(tser_example_himu[tsl], ynorm_ser_himu[tsl], color=\"k\", alpha=0.8)\n",
    "ax2.set(xlabel=\"Time (min)\", ylabel=\"PN activity norm\")\n",
    " \n",
    "last_specif = 0  # manually looked at which component is selected last\n",
    "th_pred_lastcomp = th_predictions_himu[np.argmax(specifs_himu == last_specif)]\n",
    "lastcomp_color = sns.color_palette(\"colorblind\")[last_specif]\n",
    "for ax in axes:\n",
    "    ax.axvline(th_pred_lastcomp, ls=\"--\", color=lastcomp_color)\n",
    "\n",
    "txt = ax2.annotate(\"Predicted $t_h$ for\\nlast covered odor\", \n",
    "                   xy=(th_pred_lastcomp+1, ax.get_ylim()[1]*0.98), \n",
    "            ha=\"left\", va=\"top\", fontsize=6, color=lastcomp_color)\n",
    "txt.set_bbox(dict(facecolor='w', alpha=0.8, edgecolor='none', pad=0))\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_hgamma_example_himu.pdf\"), \n",
    "                transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgammas_matrix_himu = np.mean(hgammas_ser_himu[transient:], axis=0)\n",
    "fig, ax, axi = plot_ibcm_hgammas_matrix_percomp(hgammas_matrix_himu, [0, 1, 2], n_i_ibcm, n_components)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.4, plt.rcParams[\"figure.figsize\"][1]*0.9)\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_hgamma_matrix_example_himu.pdf\"), \n",
    "                transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel C: individual neurons $h_\\mathrm{d}$, $u^2$ series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convergence, track sums of h_gammas within each neuron\n",
    "hdsums = np.sum(hgammas_ser, axis=2)\n",
    "u2sums = np.sum(hgammas_ser**2, axis=2)\n",
    "\n",
    "ncols = 5\n",
    "nrows = n_i_ibcm // ncols + min(1, n_i_ibcm % ncols)\n",
    "fig, axes = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*3.0, \n",
    "                    plt.rcParams[\"figure.figsize\"][1]*0.7*nrows)\n",
    "colors = sns.color_palette(\"tab20\", n_colors=n_i_ibcm*2)\n",
    "tsl = slice(0, len(tser_scaled), 4)\n",
    "for i in range(n_i_ibcm):\n",
    "    colors2 = colors[0], colors[1]  # Same two colors for each subplot\n",
    "    axes.flat[i].plot(tser_scaled[tsl], hdsums[tsl, i], \n",
    "                 alpha=1.0, color=colors2[0], ls=\"-\", \n",
    "                label=r\"$ h_d \\,/\\langle c \\rangle = \\sum_{\\gamma} h_{\\gamma}$\")\n",
    "    axes.flat[i].plot(tser_scaled[tsl], u2sums[tsl, i], \n",
    "                 alpha=1.0, color=colors2[1], ls=\"--\", label=r\"$u^2 = \\sum_{\\gamma} h_{\\gamma}^2$\")\n",
    "    axes.flat[i].set_title(\"Neuron {}, specif: {}\".format(i, specifs[i]), y=0.9)\n",
    "    #axes.flat[i].axhline(1.0 / avgnu, ls=\"-\", color=\"k\", lw=0.5)\n",
    "    axes.flat[i].axhline(saddle_hd_divmean, ls=\"-\", color=\"k\", lw=0.75)\n",
    "    # saddle and final h_d are pretty much the same\n",
    "    axes.flat[i].axhline(saddle_u2, ls=\":\", color=\"grey\", lw=0.75)\n",
    "\n",
    "    # u^2 at stable fixed point? Not worth showing\n",
    "    #axes.flat[i].axhline(fixed_u2, ls=\"-.\", color=\"grey\", lw=0.75)\n",
    "    \n",
    "    # Prediction of convergence time?\n",
    "    th_pred = th_predictions[i]\n",
    "    axes.flat[i].axvline(th_pred, ymax=0.9, \n",
    "        color=\"r\", lw=0.75, ls=\"-\", label=\"$t_d$ predict.\")\n",
    "    #axes.flat[i].axhline(0.0, ls=\"-\", color=\"k\", lw=0.5)\n",
    "    \n",
    "    # Phase 2: predict from actual t_d, using the exponential exit rate\n",
    "    # obtained from the Jacobian matrix at the saddle point\n",
    "    # Use for the initial value of u^2 the value at the actual t_h\n",
    "    tu_pred = tu_predictions[i]\n",
    "    clr_tu = colors[3*2+1]\n",
    "    axes.flat[i].axvline(tu_pred, ymax=0.9, \n",
    "        color=clr_tu, lw=0.75, ls=\"-\", label=r\"$t_u$ predict.\")  # after true t_d\n",
    "    axes.flat[i].axhline(target_u2, ls=\"--\", color=clr_tu, lw=0.75)\n",
    "    \n",
    "    # Annotations where there is space\n",
    "    if th_pred > 25.0:\n",
    "        xannot, yshiftd, yshiftu, halign = 0.0, 0.0, 0.15, \"left\"\n",
    "    else:\n",
    "        xannot, yshiftd, yshiftu, halign = 60.0, 0.5, 0.0, \"right\"\n",
    "    axes.flat[i].annotate(r\"Saddle $h_\\mathrm{d}/\\langle c \\rangle$\", \n",
    "                          xy=(xannot, saddle_hd_divmean + yshiftd), fontsize=5, ha=halign, va=\"bottom\")\n",
    "    axes.flat[i].annotate(r\"Saddle $u^2$\", xy=(xannot, saddle_u2 + yshiftu), fontsize=5, \n",
    "                          ha=halign, va=\"top\", color=\"grey\")\n",
    "    axes.flat[i].annotate(r\"Target $u^2$\", xy=(xannot, target_u2), fontsize=5, \n",
    "                          ha=halign, va=\"top\", color=clr_tu)\n",
    "for i in range(n_i_ibcm, axes.size):\n",
    "    if i == n_i_ibcm:\n",
    "        handles, labels = axes.flat[0].get_legend_handles_labels()\n",
    "        handles[1], handles[0] = handles[0], handles[1]\n",
    "        labels[1], labels[0] = labels[0], labels[1]\n",
    "        axes.flat[i].legend(handles, labels, frameon=False, loc=\"upper left\")\n",
    "    axes.flat[i].set_axis_off()\n",
    "for i in range(n_i_ibcm-ncols, n_i_ibcm):\n",
    "    axes.flat[i].set_xlabel(\"Time (min)\")\n",
    "for j in range(2):\n",
    "    axes[j, 0].set_ylabel(r\"Sums of $h_\\gamma$s\")\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_individual_neurons.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panel D, E, F: BioPCA $L$, $M$, and background inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_biopca_convergence(t_axis, true_pvs, learned_pvs, figax=None):\n",
    "    # Get existing figure and axis, if any\n",
    "    if figax is None: fig, ax = plt.subplots()\n",
    "    else: fig, ax = figax\n",
    "    # First plot: eigenvalues\n",
    "    n_comp = learned_pvs.shape[1]\n",
    "    pca_palette = sns.color_palette(\"colorblind\", n_colors=n_comp)\n",
    "    \n",
    "    tsl = slice(None, None, 4)\n",
    "    for i in range(n_comp):\n",
    "        li, = ax.plot(t_axis[tsl], learned_pvs[tsl, i], label=\"Value {}\".format(i),\n",
    "                      lw=plt.rcParams[\"lines.linewidth\"] - 0.5*i/n_comp, zorder=10-i, color=pca_palette[i])\n",
    "        if true_pvs[i] / true_pvs.max() > 1e-12:\n",
    "            ax.axhline(true_pvs[i], ls=\"--\", color=pca_palette[i], \n",
    "                       lw=plt.rcParams[\"lines.linewidth\"] - 0.5*i/n_comp, zorder=n_comp-i)\n",
    "    ax.set(ylabel=\"Principal values, diag$(L^{-1})$\", yscale=\"log\", xlabel=\"Time (min)\")\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract saved simulation\n",
    "with np.load(pj(data_folder_conv, \"non-gaussian_biopca_convergence_analysis.npz\")) as fp:\n",
    "    tser_scaled = fp[\"tser_scaled\"]\n",
    "    mnormser = fp[\"mnormser\"]\n",
    "    tser_example_himu = tser_scaled_himu\n",
    "    lser = fp[\"lser\"]\n",
    "    true_pvs = fp[\"true_pvs\"]\n",
    "    align_error = fp[\"align_error\"]\n",
    "    ynormser_pca = fp[\"ynormser\"]\n",
    "    bknormser_pca = fp[\"bknormser\"]\n",
    "    decay_times = fp[\"decay_times\"]\n",
    "    decay_rates = fp[\"decay_rates\"]\n",
    "    n_i_pca = len(decay_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convergence dynamics in terms of L, M norm, and PN activity norm\n",
    "# L plot first\n",
    "fig, ax = plot_biopca_convergence(tser_scaled, true_pvs[:3], lser)\n",
    "\n",
    "ax.set_ylim(ax.get_ylim()[0]*0.65, ax.get_ylim()[1])\n",
    "\n",
    "# Stop vertical lines at the level of horizontal ones\n",
    "axis_to_data = ax.transAxes + ax.transData.inverted()\n",
    "data_to_axis = axis_to_data.inverted()\n",
    "\n",
    "comp_colors = []\n",
    "for i in range(n_i_pca):\n",
    "    clr = ax.get_lines()[2*i].get_color()\n",
    "    comp_colors.append(clr)\n",
    "    ax.axvline(decay_times[i], ls=\":\", ymax=data_to_axis.transform((decay_times[i], true_pvs[i]))[1], \n",
    "                color=clr)\n",
    "    ax.annotate(\"Pred.\\n\" + r\"$t_{}$\".format(i+1), xy=(decay_times[i]+1.0, ax.get_ylim()[0]), \n",
    "               ha=\"left\", va=\"bottom\", fontsize=5, color=clr)\n",
    "\n",
    "# TODO: custom legend to indicate analytical vs learned?\n",
    "handles = [mpl.lines.Line2D([0], [0], color=\"grey\", ls=\"-\", label=r\"BioPCA\", \n",
    "                            lw=plt.rcParams[\"lines.linewidth\"]), \n",
    "          mpl.lines.Line2D([0], [0], color=\"grey\", ls=\":\", label=\"Predicted $t_i$\", \n",
    "                          lw=plt.rcParams[\"lines.linewidth\"]),\n",
    "          mpl.lines.Line2D([0], [0], color=\"grey\", ls=\"--\", label=\"True PCA\", \n",
    "                          lw=plt.rcParams[\"lines.linewidth\"])]\n",
    "leg = ax.legend(handles=handles, frameon=False, fontsize=5.0, ncol=2)\n",
    "leg.set_zorder(30)\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_biopca_principal_principal_values.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then M plot \n",
    "fig, ax = plt.subplots()\n",
    "tsl = slice(None, None, 4)\n",
    "ypositions = [2.0, 0.5, 0.15]\n",
    "for i in range(n_i_pca):\n",
    "    li, = ax.plot(tser_scaled[tsl], mnormser[tsl, i], color=comp_colors[i])\n",
    "    ax.axvline(decay_times[i], ls=\":\", color=li.get_color())\n",
    "    ax.annotate(\"Pred.\\n\" + r\"$t_{}$\".format(i+1), xy=(decay_times[i]+1.0, ypositions[i]), \n",
    "               ha=\"left\", va=\"bottom\", fontsize=5, color=li.get_color())\n",
    "ax.set(yscale=\"log\", xlabel=\"Time (min)\", ylabel=r\"Norm of $M$ rows, $\\|\\mathbf{m}\\|$\")\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_biopca_mnorms.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, finally, background inhibition\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(tser_example_himu[tsl], bknormser_pca[tsl], color=\"grey\", alpha=0.8)\n",
    "ax.plot(tser_example_himu[tsl], ynormser_pca[tsl], color=\"k\", alpha=0.8)\n",
    "ax.set(xlabel=\"Time (min)\", ylabel=\"PN activity norm\")\n",
    " \n",
    "for i in range(n_i_pca):\n",
    "    ax.axvline(decay_times[i], ls=\":\", color=comp_colors[i])\n",
    "    ax.annotate(\"Pred.\\n\" + r\"$t_{}$\".format(i+1), xy=(decay_times[i]+1.0, bknormser_pca[tsl].max()*1.1), \n",
    "               ha=\"left\", va=\"top\", fontsize=5, color=comp_colors[i], annotation_clip=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_convergence_time_biopca_ynorm_inhibition.pdf\"), \n",
    "               transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
