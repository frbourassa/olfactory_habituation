{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea92fd9f",
   "metadata": {},
   "source": [
    "# Figure 4: analysis of IBCM in turbulent backgrounds\n",
    "This version is with a six-odor, turbulent background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json\n",
    "pj = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072da4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "root_dir = pj(\"..\", \"..\", \"..\")\n",
    "data_folder = pj(root_dir, \"results\", \"for_plots\")\n",
    "panels_folder = \"panels/\"\n",
    "params_folder = pj(root_dir, \"results\", \"common_params\")\n",
    "\n",
    "do_save_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcd12d",
   "metadata": {},
   "source": [
    "# Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ee39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams\n",
    "with open(pj(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(pj(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(pj(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(pj(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(pj(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full = np.asarray(json.load(f))\n",
    "\n",
    "with open(pj(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(pj(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)\n",
    "model_colors[\"random\"] = \"k\"\n",
    "model_nice_names[\"random\"] = \"Rand. odors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neu = np.load(pj(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"cbars_gamma\"].shape[1]\n",
    "n_components, n_orn = np.load(pj(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"back_vecs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33912f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra aesthetic parameters for this figure\n",
    "\n",
    "# More legend rcParams: make everything smaller by 30 %\n",
    "plt.rcParams[\"patch.linewidth\"] = 0.75\n",
    "legend_rc = {\"labelspacing\":0.5, \"handlelength\":2.0, \"handleheight\":0.7, \n",
    "             \"handletextpad\":0.8, \"borderaxespad\":0.5, \"columnspacing\":2.0}\n",
    "for k in legend_rc:\n",
    "    plt.rcParams[\"legend.\"+k] = 0.75 * legend_rc[k]\n",
    "\n",
    "new_color = \"r\"\n",
    "linestyles = [\"-\", \"--\", \":\", (0, (5, 1, 2, 1)), \"-.\"]\n",
    "neuron_styles = linestyles + [(0, (1, 2, 1, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e99599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_var(points, kernelsize, ddof=1, boundary=\"free\"):\n",
    "    \"\"\" Computing the variance of time series points in a sliding window.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): the data points\n",
    "        kernelsize (int): odd integer giving the window size. \n",
    "        boundary (str): how to deal with points within kernelsize//2 of edges\n",
    "            \"shrink\": the window for a point within distance d < w\n",
    "                is shrunk symmetrically to a kernel of size d\n",
    "            \"free\": the window is asymmetric, full on the inside and clipped\n",
    "                on the side near the edge.\n",
    "            \"noflux\": these points are set to the value of the closest point\n",
    "                with full window (i.e. distance kernelsize//2 of the edge)\n",
    "\n",
    "    Returns:\n",
    "        var_points (np.ndarray): standard deviation at every point\n",
    "    \"\"\"\n",
    "    var_points = np.zeros(points.shape)\n",
    "    # To compute std, we need to compute the average too\n",
    "    avg_points = np.zeros(points.shape)\n",
    "    if kernelsize < 3: raise ValueError(\"Need larger kernel for variance\")\n",
    "    if kernelsize % 2 == 0:  # if an even number was given\n",
    "        kernelsize -= 1\n",
    "    w = kernelsize // 2  # width\n",
    "    end = avg_points.shape[0]  # index of the last element\n",
    "\n",
    "    if boundary not in [\"shrink\", \"free\", \"noflux\"]:\n",
    "        raise ValueError(\"Unknown boundary {}\".format(boundary))\n",
    "\n",
    "    # Smooth the middle points using slicing.\n",
    "    # First store second moment in var_points\n",
    "    var_points[w:end - w] = points[w:end - w]**2\n",
    "    avg_points[w:end - w] = points[w: end - w]\n",
    "    for j in range(w):  # Add points around the middle one\n",
    "        avg_points[w:-w] += points[w - j - 1:end - w - j - 1]\n",
    "        avg_points[w:-w] += points[w + j + 1:end - w + j + 1]\n",
    "        var_points[w:-w] += points[w - j - 1:end - w - j - 1]**2\n",
    "        var_points[w:-w] += points[w + j + 1:end - w + j + 1]**2\n",
    "\n",
    "        # Use the loop to treat the two points at a distance j from boundaries\n",
    "        if j < w and j > 0 and boundary == \"shrink\":\n",
    "            avg_points[j] = np.sum(points[0:2*j + 1], axis=0) / (2*j + 1)\n",
    "            var_points[j] = (np.sum(points[0:2*j + 1]**2, axis=0)\n",
    "                    - avg_points[j]**2 * (2*j + 1)) / (2*j + 1 - ddof)\n",
    "            avg_points[-j - 1] = np.sum(points[-2*j - 1:], axis=0) / (2*j + 1)\n",
    "            var_points[-j - 1] = (np.sum(points[-2*j - 1:]**2, axis=0)\n",
    "                    - avg_points[-j - 1]**2 * (2*j + 1)) / (2*j + 1 - ddof)\n",
    "        elif j < w and boundary == \"free\":\n",
    "            avg_points[j] = np.sum(points[0:j + w + 1], axis=0) / (j + w + 1)\n",
    "            var_points[j] = (np.sum(points[0:j + w + 1]**2, axis=0)\n",
    "                    - avg_points[j]**2 * (j + w + 1)) / (j + w + 1 - ddof)\n",
    "            avg_points[-j - 1] = np.sum(points[-j - w - 1:], axis=0) / (j + w + 1)\n",
    "            var_points[-j - 1] = (np.sum(points[-j - w - 1:]**2, axis=0)\n",
    "                    - avg_points[-j - 1]**2 * (j + w + 1)) / (j + w + 1 - ddof)\n",
    "\n",
    "    # Normalize the middle points by kernelsize - ddof\n",
    "    avg_points[w:end - w] /= kernelsize\n",
    "    var_points[w:end - w] /= (kernelsize - ddof)\n",
    "\n",
    "    # Set the edge points to the nearest full point if boundary is no flux\n",
    "    if boundary == \"noflux\":\n",
    "        var_points[:w] = var_points[w]\n",
    "        var_points[-w:] = var_points[-w]\n",
    "\n",
    "    # Then subtract the average squared, taking ddof into account once\n",
    "    var_points[w:end - w] -= (avg_points[w:end - w]**2\n",
    "                                * kernelsize / (kernelsize - ddof))\n",
    "\n",
    "    return var_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b32a61-30a7-41fb-8fb8-a2124ee4e2a9",
   "metadata": {},
   "source": [
    "# Supplementary panels for several new concentrations or dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044fada5-8b6f-41cd-a835-86ea65743a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved statistics\n",
    "all_jacs_stats = pd.read_hdf(pj(data_folder, \"jaccard_similarities_stats_dimensionality_identity.hdf\"), key=\"df\")\n",
    "all_dists_stats = pd.read_hdf(pj(data_folder, \"new_mix_distances_stats_dimensionality_identity.hdf\"), key=\"df\")\n",
    "animals_ns = {\"Fly\": 50.0, \"Human\": 300.0, \"Mouse\": 1000.0}\n",
    "average_conc = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bf5f4-7444-4102-baf9-341040c7f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplementary version with multiple panels for several OSN space sizes\n",
    "new_concs = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())\n",
    "ns_range = [25, 50, 75, 100, 300, 600, 1000]\n",
    "ncols = 4\n",
    "nrows = len(ns_range) // ncols + min(1, len(ns_range) % ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*ncols * 0.8, \n",
    "                    plt.rcParams[\"figure.figsize\"][1] * nrows * 0.8)\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    for i in range(len(ns_range)):\n",
    "        ns = ns_range[i]\n",
    "        lower = (all_jacs_stats.loc[(m, ns, new_concs), \"mean\"] \n",
    "                 - np.sqrt(all_jacs_stats.loc[(m, ns, new_concs), \"var\"])).clip(lower=0.0)\n",
    "        upper = (all_jacs_stats.loc[(m, ns, new_concs), \"mean\"] \n",
    "                 + np.sqrt(all_jacs_stats.loc[(m, ns, new_concs), \"var\"])).clip(upper=1.0)\n",
    "        axes[i].fill_between(new_concs, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    for i in range(len(ns_range)):\n",
    "        ns = ns_range[i]\n",
    "        axes[i].plot(new_concs, all_jacs_stats.loc[(m, ns, new_concs), \"mean\"], \n",
    "            label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "            ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "        )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "ns_animals = {v:k for k, v in animals_ns.items()}\n",
    "for i in range(len(ns_range)):\n",
    "    ns = ns_range[i]\n",
    "    ti = r\"$N_{\\mathrm{S}} = \" + \"{:d}$\".format(ns)\n",
    "    if ns in ns_animals:\n",
    "        ti += \" (\" + ns_animals[ns] + \")\"\n",
    "    axes[i].set_title(ti, y=0.85)\n",
    "    if nrows*ncols - i <= ncols:\n",
    "        axes[i].set_xlabel(r\"New concentration $c$\")\n",
    "    if i % ncols == 0:\n",
    "        axes[i].set_ylabel(\"Mean Jaccard similarity\")\n",
    "    ylim = axes[i].get_ylim()\n",
    "    axes[i].set_ylim([ylim[0], 1.05])\n",
    "for i in range(len(ns_range), ncols*nrows):\n",
    "    axes[i].set_axis_off()\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "leg_title = \"Model\"\n",
    "axes[-1].legend(handles, labels, loc=\"center\", bbox_to_anchor=(0.5, 0.5), frameon=False, \n",
    "                title=leg_title, borderaxespad=0.0, handlelength=1.5)\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_jaccard_vs_newconc_alldims.pdf\"),\n",
    "            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c268ec7-11d3-4ef5-b6c1-24e6f9799f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of jaccard similarities as a function of dimension for each new concentration, for supplementary figures. \n",
    "n_new_concs = 4\n",
    "keep_conc = np.sort(all_jacs_stats.index.get_level_values(\"new_conc\").unique())[0:n_new_concs]\n",
    "ns_range = np.sort(all_jacs_stats.index.get_level_values(\"N_S\").unique())\n",
    "fig = plt.figure()\n",
    "ncols = 4\n",
    "add_leg = False\n",
    "nrows = n_new_concs // ncols + min(n_new_concs % ncols, 1)\n",
    "gs = fig.add_gridspec(ncols=2*ncols+int(add_leg), nrows=nrows)\n",
    "axes = np.empty([n_new_concs // ncols, ncols], dtype=\"object\")\n",
    "axes[0, 0] = fig.add_subplot(gs[0, 0:2])\n",
    "for i in range(axes.shape[0]):\n",
    "    for j in range(ncols):\n",
    "        if i == 0 and j == 0: \n",
    "            continue\n",
    "        else: \n",
    "            axes[i, j] = fig.add_subplot(gs[i, 2*j:2*j+2], sharex=axes[0, 0], sharey=axes[0, 0])\n",
    "axes = axes.flatten()\n",
    "#fig, axes = plt.subplots(2, n_new_concs // 2, sharex=True, sharey=True)\n",
    "#if n_new_concs == 1: axes = [axes]\n",
    "#else: axes = axes.flatten()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*(2*ncols+int(add_leg))*0.8/2, \n",
    "                    plt.rcParams[\"figure.figsize\"][1]*nrows * 0.9)\n",
    "if add_leg: axleg = fig.add_subplot(gs[:, -1])\n",
    "else: axleg = None\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        lower = (all_jacs_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 - np.sqrt(all_jacs_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(lower=0.0)\n",
    "        upper = (all_jacs_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 + np.sqrt(all_jacs_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(upper=1.0)\n",
    "        axes[i].fill_between(ns_range, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        axes[i].plot(ns_range, all_jacs_stats.loc[(m, ns_range, new_conc), \"mean\"], \n",
    "            label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "            ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "        )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "for i in range(n_new_concs):\n",
    "    axes[i].set_title(r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(keep_conc[i] / average_conc), y=0.9)\n",
    "    if i - (n_new_concs - ncols) >= 0:\n",
    "        axes[i].set_xlabel(r\"OSN space dimensionality, $N_\\mathrm{S}$\")\n",
    "    if i % ncols == 0:\n",
    "        axes[i].set_ylabel(\"Mean Jaccard similarity\")\n",
    "    else:\n",
    "        axes[i].yaxis.set_tick_params(labelleft=False)\n",
    "    axes[i].set_xscale(\"log\")\n",
    "if add_leg:\n",
    "    leg_title = \"Model\"\n",
    "    leg_handles_labels = axes[-1].get_legend_handles_labels()\n",
    "    leg = axleg.legend(*leg_handles_labels, loc=\"upper left\",  frameon=False, ncols=1, title=leg_title, \n",
    "                    borderaxespad=-2.0, handlelength=1.5, alignment=\"left\")\n",
    "    axleg.set_axis_off()\n",
    "    extra_artists = (axleg,)\n",
    "else:\n",
    "    extra_artists = ()\n",
    "for ani in animals_ns:\n",
    "    for i in range(n_new_concs):\n",
    "        axes[i].axvline(animals_ns[ani], ls=\":\", color=\"k\", lw=0.5, zorder=0, ymax=0.95)\n",
    "        axes[i].annotate(ani, (animals_ns[ani]*0.95, 1.05), ha=\"right\", va=\"bottom\", fontsize=6)\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_jaccards_vs_dimension_allconcs.pdf\"),\n",
    "                transparent=True, bbox_inches=\"tight\", bbox_extra_artists=extra_artists)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bb379-5704-4fbe-96d3-355d10b915be",
   "metadata": {},
   "source": [
    "## Optional figure: $\\|\\mathbf{y}_{\\mathrm{new}} - \\mathbf{y}_{\\mathrm{mix}}\\|$ distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847728f-ef46-4632-b8a6-99736f496381",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plots of distance to new odor for all odor concentrations, for supplementary figures. \n",
    "n_new_concs = 4\n",
    "keep_conc = np.sort(all_dists_stats.index.get_level_values(\"new_conc\").unique())[0:n_new_concs]\n",
    "ns_range = np.sort(all_dists_stats.index.get_level_values(\"N_S\").unique())\n",
    "fig, axes = plt.subplots(2, n_new_concs // 2, sharex=True, sharey=True)\n",
    "if n_new_concs == 1: axes = [axes]\n",
    "else: axes = axes.flatten()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.75, plt.rcParams[\"figure.figsize\"][1]*1.75)\n",
    "\n",
    "# Order models according to the line order (best first)\n",
    "show_models = [\"optimal\", \"orthogonal\", \"ibcm\", \"biopca\", \"avgsub\", \"none\", \"random\"]\n",
    "model_zorder = [\"none\", \"avgsub\", \"random\", \"optimal\", \"orthogonal\",  \"biopca\", \"ibcm\"]\n",
    "model_linestyles = {show_models[i]:neuron_styles[i % 6] for i in range(len(show_models))}\n",
    "model_linestyles[\"ibcm\"], model_linestyles[\"optimal\"] = \"-\", model_linestyles[\"ibcm\"]\n",
    "for m in show_models[::-1]:  # Plot IBCM last\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        lower = (all_dists_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 - np.sqrt(all_dists_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(lower=0.0)\n",
    "        upper = (all_dists_stats.loc[(m, ns_range, new_conc), \"mean\"] \n",
    "                 + np.sqrt(all_dists_stats.loc[(m, ns_range, new_conc), \"var\"])).clip(upper=1.0)\n",
    "        axes[i].fill_between(ns_range, lower, upper, color=model_colors.get(m), alpha=0.25)\n",
    "for m in show_models:\n",
    "    for i in range(n_new_concs):\n",
    "        new_conc = keep_conc[i]\n",
    "        axes[i].plot(ns_range, all_dists_stats.loc[(m, ns_range, new_conc), \"mean\"], \n",
    "            label=model_nice_names.get(m, m), color=model_colors.get(m), alpha=1.0, \n",
    "            ls=model_linestyles[m], zorder=model_zorder.index(m) + 20\n",
    "        )\n",
    "# Labeling the graphs, adding similarity between random odors, etc.\n",
    "for i in range(n_new_concs):\n",
    "    axes[i].set_title(r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(keep_conc[i] / average_conc), y=1.0)\n",
    "    if i >= 2:\n",
    "        axes[i].set_xlabel(r\"OSN space dimensionality, $N_\\mathrm{S}$\")\n",
    "    if i % 2 == 0:\n",
    "        axes[i].set_ylabel(r\"Mean dist. $\\langle\\|y_{\\mathrm{new}} - y_{\\mathrm{mix}}\\|\\rangle$\")\n",
    "    axes[i].set_xscale(\"log\")\n",
    "    axes[i].set_yscale(\"log\")\n",
    "leg_title = \"Model\"\n",
    "axes[-1].legend(loc=\"lower left\",  frameon=False, ncols=2, title=leg_title, \n",
    "                borderaxespad=0.0, handlelength=1.5, alignment=\"left\")\n",
    "for ani in animals_ns:\n",
    "    for i in range(n_new_concs):\n",
    "        axes[i].axvline(animals_ns[ani], ls=\":\", color=\"k\", lw=0.5, zorder=0)\n",
    "        axes[i].annotate(ani, (animals_ns[ani]*0.95, 1.05), ha=\"right\", va=\"bottom\", fontsize=6)\n",
    "\n",
    "fig.tight_layout()\n",
    "if do_save_plots:\n",
    "    fig.savefig(pj(panels_folder, \"supfig_distance_vs_dimension_allconcs.pdf\"),\n",
    "                transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099373d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
