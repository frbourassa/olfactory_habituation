{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea92fd9f",
   "metadata": {},
   "source": [
    "# Figure 2: new odor recognition performance tests\n",
    "This version is with a six-odor, turbulent background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe280c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import os, colorsys, json\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072da4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "data_folder = os.path.join(\"..\", \"results\", \"for_plots\")\n",
    "panels_folder = \"panels/\"\n",
    "params_folder = os.path.join(\"..\", \"results\", \"common_params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fcd12d",
   "metadata": {},
   "source": [
    "# Aesthetic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ee39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rcParams\n",
    "with open(os.path.join(params_folder, \"olfaction_rcparams.json\"), \"r\") as f:\n",
    "    new_rcParams = json.load(f)\n",
    "plt.rcParams.update(new_rcParams)\n",
    "\n",
    "# color maps\n",
    "with open(os.path.join(params_folder, \"back_colors.json\"), \"r\") as f:\n",
    "    all_back_colors = json.load(f)\n",
    "back_color = all_back_colors[\"back_color\"]\n",
    "back_color_samples = all_back_colors[\"back_color_samples\"]\n",
    "back_palette = all_back_colors[\"back_palette\"]\n",
    "\n",
    "with open(os.path.join(params_folder, \"orn_colors.json\"), \"r\") as f:\n",
    "    orn_colors = json.load(f)\n",
    "    \n",
    "with open(os.path.join(params_folder, \"inhibitory_neuron_two_colors.json\"), \"r\") as f:\n",
    "    neuron_colors = np.asarray(json.load(f))\n",
    "with open(os.path.join(params_folder, \"inhibitory_neuron_full_colors.json\"), \"r\") as f:\n",
    "    neuron_colors_full = np.asarray(json.load(f))\n",
    "\n",
    "with open(os.path.join(params_folder, \"model_colors.json\"), \"r\") as f:\n",
    "    model_colors = json.load(f)\n",
    "with open(os.path.join(params_folder, \"model_nice_names.json\"), \"r\") as f:\n",
    "    model_nice_names = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neu = np.load(os.path.join(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"cbars_gamma\"].shape[1]\n",
    "n_components, n_orn = np.load(os.path.join(data_folder, \n",
    "                    \"sample_turbulent_ibcm_simulation.npz\"))[\"back_vecs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33912f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra aesthetic parameters for this figure\n",
    "\n",
    "# More legend rcParams: make everything smaller by 30 %\n",
    "plt.rcParams[\"patch.linewidth\"] = 0.75\n",
    "legend_rc = {\"labelspacing\":0.5, \"handlelength\":2.0, \"handleheight\":0.7, \n",
    "             \"handletextpad\":0.8, \"borderaxespad\":0.5, \"columnspacing\":2.0}\n",
    "for k in legend_rc:\n",
    "    plt.rcParams[\"legend.\"+k] = 0.75 * legend_rc[k]\n",
    "\n",
    "new_color = \"r\"\n",
    "linestyles = [\"-\", \"--\", \":\", (0, (5, 1, 2, 1)), \"-.\"]\n",
    "neuron_styles = linestyles + [(0, (1, 2, 1, 2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcc6e5",
   "metadata": {},
   "source": [
    "# Panel A: habituation narrow long trace\n",
    "Part of the diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute norm of PN activity\n",
    "ex = np.load(os.path.join(data_folder, \"sample_turbulent_ibcm_simulation.npz\"))\n",
    "tser_example = np.arange(*ex[\"tser_range\"])\n",
    "sser_example = ex[\"sser\"]\n",
    "dt_u = 10.0  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7bc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(100.0 / 25.4, 18.0 / 25.4)\n",
    "snorm_ser = np.sqrt(np.sum(sser_example**2, axis=1))\n",
    "ax.plot(tser_example * dt_u / 1000 / 60, snorm_ser, color=back_color, lw=0.5)\n",
    "last_times = np.linspace(tser_example[-1] - 2000*10, tser_example[-1], 10)\n",
    "for t in last_times:\n",
    "    ax.plot(np.asarray([t-20, t, t+20])*dt_u/1000/60, \n",
    "            np.asarray([0.0, snorm_ser.max()/3+0.2*np.random.uniform(), 0.0]), \n",
    "            color=\"r\", lw=0.85, alpha=0.8)\n",
    "ymax = snorm_ser.max()\n",
    "ax.annotate(\"Habituation period\", xy=(28.0, ymax), ha=\"center\", va=\"center\", fontsize=6)\n",
    "ax.annotate(\"Tests\", xy=(last_times[4]*dt_u/60/1000, ymax), \n",
    "            color=\"r\", ha=\"center\", va=\"center\", fontsize=6)\n",
    "ax.annotate(\"\", xy=(1.0, ymax), xytext=(17.0, ymax), \n",
    "            arrowprops={\"color\":\"k\", \"width\":0.1, \"headwidth\":2.0, \"headlength\":2.0})\n",
    "ax.annotate(\"\", xy=(last_times[0]*dt_u/60/1000 - 2, ymax), xytext=(40.0, ymax), \n",
    "            arrowprops={\"color\":\"k\", \"width\":0.1, \"headwidth\":2.0, \"headlength\":2.0})\n",
    "ax.fill_between([0, last_times[0]*dt_u/60/1000 - 1.5], [0, 0], [ymax-0.4, ymax-0.4], \n",
    "               color=back_color_samples, alpha=0.3)\n",
    "ax.set_ylabel(\"PN\\nactivity\\nnorm\", fontsize=6)\n",
    "#lbl = ax.set_xlabel(\"Time (min)\", fontsize=6, labelpad=-6, ha=\"left\", x=1.0)\n",
    "lbl = ax.set_xlabel(\"Time (min)\", fontsize=6)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"habituation_time_axis.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\", bbox_extra_artists=(lbl,))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db250c",
   "metadata": {},
   "source": [
    "# Former panel B, now in figure 1: background process\n",
    "Histograms of concentrations, whiff duration and blank duration, overlaid with analytical distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = np.load(os.path.join(data_folder, \"sample_turbulent_background.npz\"))\n",
    "# Time units per simulation step, for plotting, in ms\n",
    "dt_u = 10.0  # ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2495c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_outline(ax, bins, height, **plot_kwargs):\n",
    "    plot_hist = np.stack([height, height], axis=1).flatten()\n",
    "    plot_edges = np.stack([bins[:-1], bins[1:]], axis=1).flatten()\n",
    "    ax.plot(plot_edges, plot_hist, **plot_kwargs)\n",
    "    ax.fill_between(plot_edges, min(0.0, height.min()), plot_hist,\n",
    "                    color=plot_kwargs.get(\"color\"), alpha=0.3)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9044bebc-293d-4cd3-98a5-71a69d503198",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Plot the statistics to make sure it's convenient and correct.\n",
    "fig = plt.figure()\n",
    "gs = fig.add_gridspec(1, 4)\n",
    "axes = [fig.add_subplot(gs[:, :2]), fig.add_subplot(gs[:, 2:])]\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1])\n",
    "# TODO: try superposing whiffs and blanks?\n",
    "\n",
    "# Concentrations\n",
    "ax = axes[0]\n",
    "# Histogram\n",
    "hist_outline(ax, bins=ex2[\"conc_bins\"], height=ex2[\"conc_pdf\"], color=back_color_samples, label=\"Samples\")\n",
    "# Analytical\n",
    "conc_axis = np.linspace(ex2[\"conc_bins\"][0], ex2[\"conc_bins\"][-1], 201)\n",
    "ax.plot(conc_axis,  ex2[\"conc_analytical_pdf\"], color=\"k\", lw=1.0,\n",
    "        label=r\"$p_c(c) \\sim \\frac{e^{-c/c_0}}{Ac}$\")\n",
    "# Probability of zero concentration\n",
    "ax.plot(0.0, ex2[\"conc_prob_zero\"], mfc=back_palette[2],  #, label=\"Blank (c=0)\",\n",
    "        marker=\"o\", ls=\"none\", mec=back_palette[1], ms=4)\n",
    "ax.plot(0.0, ex2[\"conc_analytical_prob_zero\"], marker=\"*\", color=\"k\", ls=\"none\",\n",
    "        mec=\"k\", ms=2)  #, label=r\"$p_c(c=0) = 1 - \\chi$\")\n",
    "# Annotate with arrow since does not fit in legend\n",
    "ax.annotate(\"\", xy=(0.1, ex2[\"conc_prob_zero\"]*0.5), xytext=(1.0, 2e-3), \n",
    "            arrowprops=dict(color=back_color_samples, width=0.3, headwidth=3.0, headlength=3.0), \n",
    "            ha=\"center\", va=\"top\")\n",
    "ax.annotate(\"Blanks\", xy=(1.0, 1e-3), ha=\"center\", va=\"top\")\n",
    "ax.legend(frameon=False)\n",
    "ax.set(xlabel=r\"$c$\", ylabel=r\"$p_c(c)$\", yscale=\"log\")\n",
    "ax.set_title(\"Concentration\", va=\"top\", pad=-20)\n",
    "\n",
    "# Whiffs: just say the distribution is similar but stops at shorter times\n",
    "pdf_fact = 1.0 / (dt_u/1000)  # to have s^{-1} units\n",
    "if len(axes) > 2:\n",
    "    ax = axes[1]\n",
    "    hist_outline(ax, ex2[\"t_w_bins\"]*dt_u/1000, ex2[\"t_w_pdf\"]*pdf_fact, \n",
    "                 color=back_color_samples, label=\"Samples\")\n",
    "    ax.plot(ex2[\"t_w_axis\"]*dt_u/1000, ex2[\"t_w_analytical_pdf\"]*pdf_fact, color=\"k\", lw=1.0,\n",
    "            label=r\"$p(t_w) \\sim t_w^{-3/2}$\")\n",
    "    ax.set(xlabel=r\"$t_w$ (s)\", ylabel=r\"$p_t(t_w)$ (s$^{-1}$)\", yscale=\"log\", xscale=\"log\")\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_title(\"Whiffs\", va=\"top\", pad=-20)\n",
    "    \n",
    "# Blanks\n",
    "ax = axes[1]\n",
    "hist_outline(ax, ex2[\"t_b_bins\"]*dt_u/1000, ex2[\"t_b_pdf\"]*pdf_fact, \n",
    "             color=back_color_samples, label=\"Samples\")\n",
    "# Analytical\n",
    "ax.plot(ex2[\"t_b_axis\"]*dt_u/1000, ex2[\"t_b_analytical_pdf\"]*pdf_fact, color=\"k\", lw=1.0,\n",
    "        label=r\"$p(t_d) \\sim t_d^{-3/2}$\")\n",
    "ax.set(xlabel=r\"$t_b$ (s)\", ylabel=r\"$p_t(t_b)$ (s$^{-1}$)\", yscale=\"log\", xscale=\"log\")\n",
    "ax.legend(frameon=False)\n",
    "ax.set_title(\"Blank duration\", va=\"top\", pad=-20)\n",
    "   \n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"turbulent_background_statistics.pdf\"), \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44560a-30d5-4e41-9479-2bdf89374498",
   "metadata": {},
   "source": [
    "# Panel C: habituation, response to background goes down\n",
    "Just show how different models fare in this respect: it does habituate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52e96f-d2cb-4cbc-8683-a7645b436ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ysers = {}\n",
    "for mod in [\"ibcm\", \"pca\", \"avgsub\"]:\n",
    "    k = \"biopca\" if mod == \"pca\" else mod\n",
    "    all_ysers[k] = np.load(os.path.join(data_folder, \n",
    "        \"{}_full_habituation_run_example.npz\".format(mod)))[\"s_snaps\"]\n",
    "all_ysers[\"none\"] = np.load(os.path.join(data_folder, \n",
    "        \"ibcm_full_habituation_run_example.npz\"))[\"back_vec_snaps\"]\n",
    "\n",
    "# Should show the optimum too. \n",
    "all_ysers[\"optimal\"] = all_ysers[\"none\"] - all_ysers[\"none\"].dot(\n",
    "    np.load(os.path.join(data_folder, \"optimal_habituation_example.npz\"))[\"optimal_ws\"][0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24261d81-fbf0-4ca8-a3d9-5d958b1fb995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot habituation time series. Think about using some smoothing?\n",
    "# No, we want this to look rough, hard problem, etc. \n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.9, fig.get_size_inches()[1]*1.1)\n",
    "# We know the time series of these simulations: \n",
    "# 360000 steps, skipping 20, 10 ms each step\n",
    "extra_skp = 10\n",
    "tser = np.arange(0.0, 360000.0, 20.0*extra_skp) * 0.01 / 60.0  # 0.01 s/step\n",
    "# Choose plotting order wisely: no habituation first, smallest last\n",
    "yser_norm = np.sqrt(np.sum(all_ysers[\"none\"]**2, axis=1))[::extra_skp]\n",
    "ax.plot(tser, yser_norm, label=\"None\", color=model_colors[\"none\"], lw=0.5, alpha=0.8)\n",
    "for m in [ \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]:\n",
    "    lbl = model_nice_names.get(m)\n",
    "    yser_norm = np.sqrt(np.sum(all_ysers[m]**2, axis=1))[::extra_skp]\n",
    "    ax.plot(tser, yser_norm, label=lbl, color=model_colors[m], lw=0.5, alpha=0.7)\n",
    "\n",
    "leg_props = dict(borderaxespad=0.3, handlelength=1.2, facecolor=(1,1,1,0.8), edgecolor=(1,1,1,0.8))\n",
    "ax.legend(loc=\"upper center\", title=\"Model\", **leg_props, ncol=2)\n",
    "\n",
    "ax.set(ylabel=r\"PN activity norm $\\|\\mathbf{y}(t)\\|$\", xlabel=\"Time (min)\")\n",
    "ax.set_title(\"Habituation\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", pad=15)\n",
    "ylims_orig = ax.get_ylim()\n",
    "ax.set_ylim([ylims_orig[0], ylims_orig[1]*0.9])\n",
    "#ax.set_xlim([0.0, 5.0])\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"habituation_examples_turbulent_back.pdf\"), \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f68406-fd0b-4c31-bf16-a4566dfa0e7d",
   "metadata": {},
   "source": [
    "# Panel D: odor recognition performance, distance to new odor vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49185be-af07-407d-955f-74278f386d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = np.load(os.path.join(data_folder, \"new_mix_distances_identity.npz\"))\n",
    "all_models = list(all_dists.keys())\n",
    "all_models.remove(\"new_concs\")\n",
    "print(all_dists[\"ibcm\"].shape)\n",
    "print(all_models)\n",
    "new_concs = all_dists[\"new_concs\"]\n",
    "# I know these are 0.5x and 1x the average concentration, so use these relative measures instead\n",
    "rel_new_concs = [a/new_concs[1] for a in new_concs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25748c8-b0f4-43a4-be0a-53b124ed381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interesting statistics\n",
    "show_models = [\"none\", \"avgsub\", \"orthogonal\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "dist_histograms = {}\n",
    "dist_cdfs = {}\n",
    "dist_stats = {}\n",
    "min_dist_to_show = np.log10((all_dists[\"optimal\"] / np.asarray(new_concs).reshape(1, 1, 1, 2, 1)).min())\n",
    "for m in show_models:\n",
    "    dist_histograms[m] = []\n",
    "    dist_cdfs[m] = []\n",
    "    dist_stats[m] = []\n",
    "    dists = []\n",
    "    for i in range(len(new_concs)):\n",
    "        # Normalize by new odor magnitude = 1.0 * conc\n",
    "        # Combine all concentrations this way. \n",
    "        conc = new_concs[i]\n",
    "        # Distances in log scale\n",
    "        dists_i = all_dists[m][:, :, :, i].flatten() / conc\n",
    "        dists_i = np.log10(dists_i[dists_i > 0.0])  # Drop exact zeros\n",
    "        dists.append(dists_i)\n",
    "    dists = np.concatenate(dists)\n",
    "    dist_stats[m] = [\n",
    "        np.mean(dists), \n",
    "        np.median(dists), \n",
    "        np.var(dists),\n",
    "    ]\n",
    "    # Remove extremely small distances for plotting purposes\n",
    "    dists_clipped = dists[dists > min_dist_to_show]\n",
    "    dist_histograms[m] = np.histogram(dists_clipped, bins=\"doane\", density=True)\n",
    "    # Cumulative distribution function of distances\n",
    "    n_bins_dists = 300\n",
    "    dists_axis = np.linspace(dists_clipped.min(), dists_clipped.max(), n_bins_dists)\n",
    "    dists_counts = np.histogram(dists_clipped, bins=dists_axis)[0] / dists_clipped.size\n",
    "    dists_cdf = np.concatenate([[0.0], np.cumsum(dists_counts)])\n",
    "    dist_cdfs[m] = dists_cdf, dists_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66635ac-d120-455f-a632-d7b0a614bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.9, fig.get_size_inches()[1]*1.1)\n",
    "for m in show_models:\n",
    "    lbl = model_nice_names.get(m)\n",
    "    hist_outline(ax, 10.0**dist_histograms[m][1], dist_histograms[m][0], \n",
    "                color=model_colors[m], lw=1.0, label=lbl)\n",
    "handles1, labels1 = ax.get_legend_handles_labels()\n",
    "for m in show_models:\n",
    "    lbl = \"Medians\" if m == \"none\" else None\n",
    "    li = ax.axvline(10.0**dist_stats[m][1], ls=\"--\", color=model_colors[m], \n",
    "               lw=0.75)\n",
    "    if lbl is not None:\n",
    "        handles2, labels2 = [li], [lbl]\n",
    "ax.set(xlabel=r\"Distance $\\|\\mathbf{y}_{\\mathrm{n}} - \\mathbf{y}_{\\mathrm{mix}}\\| / \\|\\mathbf{y}_{\\mathrm{n}}\\|$\", \n",
    "       ylabel=\"Probability density\", xscale=\"log\")\n",
    "ax.set_title(\"Distance to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", pad=15)\n",
    "\n",
    "# Create a legend for the first line.\n",
    "leg_props = dict(frameon=False, borderaxespad=0.3, handlelength=1.2)\n",
    "first_legend = ax.legend(handles=handles1, labels=labels1, loc=\"upper left\", title=\"Model\", **leg_props)\n",
    "# Add the legend manually to the Axes.\n",
    "ax.add_artist(first_legend)\n",
    "# Create another legend for the second line.\n",
    "ax.legend(handles=handles2, labels=labels2, loc='upper right', handletextpad=0.1, **leg_props)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"distance_to_new_odor_histograms_turbulent_back.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfa1e9-63db-4e87-89fb-591203e21ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDF. I don't want to show the \"Orthogonal\" model in this figure\n",
    "# but the histograms above show that IBCM and PCA peak at the norm of y_n, perp, \n",
    "# so they implement very well the strategy for which W was optimized. \n",
    "show_models = [\"none\", \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*0.85, fig.get_size_inches()[1]*1.1)\n",
    "ax.set_title(\"Distance to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", pad=15)\n",
    "for m in show_models:\n",
    "    ax.plot(10.0**dist_cdfs[m][1], dist_cdfs[m][0], \n",
    "                color=model_colors[m], lw=1.0, label=model_nice_names.get(m))\n",
    "ax.set(xlabel=r\"Distance $\\|\\mathbf{y}_{\\mathrm{n}} - \\mathbf{y}_{\\mathrm{mix}}\\| / \\|\\mathbf{y}_{\\mathrm{n}}\\|$\", \n",
    "       ylabel=\"Cumulative distribution\", xscale=\"log\")\n",
    "ax.legend(title=\"Model\", frameon=False)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"distance_to_new_odor_cdf_turbulent_back.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19355d8f-931b-4cbd-9bea-7e8d6b642224",
   "metadata": {},
   "source": [
    "### Versions with two plots, one per concentration"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ace9be1e-f31e-4b76-b464-3bb4250a5305",
   "metadata": {},
   "source": [
    "# Compute interesting statistics\n",
    "show_models = [\"none\", \"avgsub\", \"biopca\",\"ibcm\",  \"optimal\"]\n",
    "dist_histograms = {}\n",
    "dist_cdfs = {}\n",
    "dist_stats = {}\n",
    "min_dist_to_show = np.log10(all_dists[\"optimal\"].min())\n",
    "for m in show_models:\n",
    "    dist_histograms[m] = {}\n",
    "    dist_cdfs[m] = {}\n",
    "    dist_stats[m] = {}\n",
    "    for i in range(len(new_concs)):\n",
    "        conc = new_concs[i]\n",
    "        # Distances in log scale\n",
    "        dists = all_dists[m][:, :, :, i].flatten()\n",
    "        dists = np.log10(dists[dists > 0.0])  # Drop exact zeros\n",
    "        dist_stats[m][conc] = [\n",
    "            np.mean(dists), \n",
    "            np.median(dists), \n",
    "            np.var(dists),\n",
    "        ]\n",
    "        # Remove extremely small distances for plotting purposes\n",
    "        dists_clipped = dists[dists > min_dist_to_show]\n",
    "        dist_histograms[m][conc] = np.histogram(dists_clipped, bins=\"doane\", density=True)\n",
    "        # Cumulative distribution function of distances\n",
    "        n_bins_dists = 300\n",
    "        dists_axis = np.linspace(dists.min(), dists.max(), n_bins_dists)\n",
    "        dists_counts = np.histogram(dists, bins=dists_axis)[0] / dists.size\n",
    "        dists_cdf = np.concatenate([[0.0], np.cumsum(dists_counts)])\n",
    "        dist_cdfs[m][conc] = dists_cdf, dists_axis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfbba991-2528-462d-ae9d-c3a53a0ccbdf",
   "metadata": {},
   "source": [
    "# Plot histograms\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1]*1.1)\n",
    "fig.suptitle(\"Distance to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", y=0.92)\n",
    "for i in range(len(new_concs)):\n",
    "    conc = new_concs[i]\n",
    "    conc_rel = rel_new_concs[i]\n",
    "    ax = axes[i]\n",
    "    for m in show_models:\n",
    "        lbl = model_nice_names.get(m) if i ==0 else \"\"\n",
    "        hist_outline(ax, 10.0**dist_histograms[m][conc][1], dist_histograms[m][conc][0], \n",
    "                    color=model_colors[m], lw=1.0, label=lbl)\n",
    "        lbl = \"Median\" if i == 1 and m == \"none\" else \"\"\n",
    "        ax.axvline(10.0**dist_stats[m][conc][1], ls=\"--\", color=model_colors[m], \n",
    "                   lw=0.75, label=lbl)\n",
    "    ax.set(xlabel=r\"Distance $\\|\\mathbf{y}_{\\mathrm{n}} - \\mathbf{y}_{\\mathrm{mix}}\\|$\", \n",
    "           ylabel=\"Probability density\", title=r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(conc_rel)), \n",
    "          xscale=\"log\")\n",
    "    leg_title = \"Model\" if i == 0 else \"\"\n",
    "    ax.legend(frameon=False, title=leg_title, borderaxespad=0.0, handlelength=1.2)\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"distance_to_new_odor_histograms_turbulent_back.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cfaf409-0997-4897-916d-c716511d2e7f",
   "metadata": {},
   "source": [
    "# Plot CDFs\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1])\n",
    "for i in range(len(new_concs)):\n",
    "    conc = new_concs[i]\n",
    "    conc_rel = rel_new_concs[i]\n",
    "    ax = axes[i]\n",
    "    for m in show_models:\n",
    "        ax.plot(10.0**dist_cdfs[m][conc][1], dist_cdfs[m][conc][0], \n",
    "                    color=model_colors[m], lw=1.0, label=model_nice_names.get(m))\n",
    "    ax.set(xlabel=r\"Distance $\\|\\mathbf{y}_{\\mathrm{n}} - \\mathbf{y}_{\\mathrm{mix}}\\| / \\|\\mathbf{y}_{\\mathrm{n}}\\|$\", \n",
    "           ylabel=\"Cumulative distribution\", title=r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(conc_rel)),\n",
    "          xscale=\"log\")\n",
    "    ax.legend(title=\"Model\", frameon=False)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"distance_to_new_odor_cdf_turbulent_back.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fccbb1",
   "metadata": {},
   "source": [
    "# Panel E: odor recognition performance, Jaccard\n",
    "Should highlight somewhere that larger is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jacs = np.load(os.path.join(data_folder, \"jaccard_similarities_identity.npz\"))\n",
    "all_models = list(all_jacs.keys())\n",
    "all_models.remove(\"new_concs\")\n",
    "print(all_jacs[\"ibcm\"].shape)\n",
    "print(all_models)\n",
    "new_concs = all_jacs[\"new_concs\"]\n",
    "# I know these are 0.5x and 1x the average concentration, so use these relative measures instead\n",
    "rel_new_concs = [a/new_concs[1] for a in new_concs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interesting statistics\n",
    "show_models = [\"none\", \"avgsub\", \"biopca\", \"ibcm\", \"optimal\"]\n",
    "jac_histograms = {}\n",
    "jac_cdfs = {}\n",
    "jac_stats = {}\n",
    "for m in show_models:\n",
    "    jac_histograms[m] = {}\n",
    "    jac_cdfs[m] = {}\n",
    "    jac_stats[m] = {}\n",
    "    for i in range(len(new_concs)):\n",
    "        conc = new_concs[i]\n",
    "        jacs_sim = all_jacs[m][:, :, :, i].flatten()\n",
    "        jac_histograms[m][conc] = np.histogram(jacs_sim, bins=\"doane\", density=True)\n",
    "        jacs_dists = 1.0 - jacs_sim\n",
    "        # There is only a discrete number of possible J, increments of card(z_n \\cap z_mix)\n",
    "        # So count each value\n",
    "        dists_axis, dists_counts = np.unique(jacs_dists, return_counts=True)\n",
    "        reorder = np.argsort(dists_axis)\n",
    "        dists_axis = dists_axis[reorder]\n",
    "        dists_counts = dists_counts[reorder] / jacs_dists.size\n",
    "        dists_cdf = np.cumsum(dists_counts) \n",
    "        jac_cdfs[m][conc] = dists_cdf, dists_axis\n",
    "        jac_stats[m][conc] = [\n",
    "            np.mean(jacs_sim), \n",
    "            np.median(jacs_sim), \n",
    "            np.var(jacs_sim),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1]*1.1)\n",
    "fig.suptitle(\"Jaccard similarity to new odor\", fontsize=plt.rcParams[\"font.size\"], weight=\"bold\", y=0.92)\n",
    "for i in range(len(new_concs)):\n",
    "    conc = new_concs[i]\n",
    "    conc_rel = rel_new_concs[i]\n",
    "    ax = axes[i]\n",
    "    for m in show_models:\n",
    "        lbl = model_nice_names.get(m) if i ==0 else \"\"\n",
    "        hist_outline(ax, jac_histograms[m][conc][1], jac_histograms[m][conc][0], \n",
    "                    color=model_colors[m], lw=1.0, label=lbl)\n",
    "        lbl = \"Median\" if i == 1 and m == \"none\" else \"\"\n",
    "        ax.axvline(jac_stats[m][conc][1], ls=\"--\", color=model_colors[m], \n",
    "                   lw=0.75, label=lbl)\n",
    "    ax.set(xlabel=r\"Jaccard similarity $(z_{\\mathrm{n}}, z_{\\mathrm{mix}})$\", \n",
    "           ylabel=\"Probability density\", title=r\"New conc.$= {:.1f} \\langle c \\rangle$\".format(conc_rel))\n",
    "    leg_title = \"Model\" if i == 0 else \"\"\n",
    "    ax.legend(frameon=False, title=leg_title, borderaxespad=0.0, handlelength=1.2)\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"jaccard_histograms_turbulent_back.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e590705-865f-4d05-929d-e094d87efb09",
   "metadata": {},
   "source": [
    "# Jensen-Shannon distance: average KL divergence with each distribution taken as p or q\n",
    "# Estimate true value from binned data by using more and more bins\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def regress_jensen_shannon(psamp, qsamp, xrange):\n",
    "    # bin with increasingly more bins, compute entropy for each\n",
    "    # linear regression as a function of bin number to remove bias from binning\n",
    "    max_n = max(psamp.size, qsamp.size) // 30\n",
    "    n_bins_range = [10, 30]\n",
    "    max_n_current = 30\n",
    "    while max_n_current < max_n:\n",
    "        n_bins_range += [n_bins_range[-2]*10, n_bins_range[-1]*10]\n",
    "        max_n_current = n_bins_range[-1]\n",
    "    entropies = []\n",
    "    for n in n_bins_range:\n",
    "        binlims = np.linspace(*xrange, n+1)\n",
    "        pdist, _ = np.histogram(psamp, bins=binlims)\n",
    "        qdist, _ = np.histogram(qsamp, bins=binlims)\n",
    "        entropies.append(jensenshannon(pdist, qdist, base=2.0))\n",
    "    fig, ax = plt.subplots()\n",
    "    ninv_range = [1.0 / n for n in n_bins_range]\n",
    "    ax.plot(n_bins_range, entropies)\n",
    "    ax.set(xscale=\"log\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return entropies"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75400da9-4c6b-42a3-aef0-8414a7c9e230",
   "metadata": {},
   "source": [
    "regress_jensen_shannon(all_jacs[\"ibcm\"][:, :, :, 0].flatten(), all_jacs[\"none\"][:, :, :, 0].flatten(), [0, 1])\n",
    "regress_jensen_shannon(all_jacs[\"ibcm\"][:, :, :, 0].flatten(), all_jacs[\"biopca\"][:, :, :, 0].flatten(), [0, 1])\n",
    "regress_jensen_shannon(all_jacs[\"ibcm\"][:, :, :, 0].flatten(), all_jacs[\"optimal\"][:, :, :, 0].flatten(), [0, 1])\n",
    "regress_jensen_shannon(all_jacs[\"ibcm\"][:, :, :, 0].flatten(), all_jacs[\"orthogonal\"][:, :, :, 0].flatten(), [0, 1])\n",
    "regress_jensen_shannon(all_jacs[\"optimal\"][:, :, :, 0].flatten(), all_jacs[\"orthogonal\"][:, :, :, 0].flatten(), [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b7d00-9650-4445-a09f-cb47b25952e8",
   "metadata": {},
   "source": [
    "# Supplementary panel: odor recognition performance cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb46431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CDFs\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0]*1.5, fig.get_size_inches()[1])\n",
    "for i in range(len(new_concs)):\n",
    "    conc = new_concs[i]\n",
    "    conc_rel = rel_new_concs[i]\n",
    "    ax = axes[i]\n",
    "    for m in show_models:\n",
    "        ax.plot(jac_cdfs[m][conc][1], jac_cdfs[m][conc][0], \n",
    "                    color=model_colors[m], lw=1.0, label=model_nice_names.get(m))\n",
    "    ax.set(xlabel=r\"Jaccard distance $(z_{\\mathrm{n}}, z_{\\mathrm{mix}})$\", \n",
    "           ylabel=\"Cumulative distribution\", title=r\"New conc. $= {:.1f} \\langle c \\rangle$\".format(conc_rel))\n",
    "    ax.legend(title=\"Model\", frameon=False)\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"jaccard_distances_cdf_turbulent_back.pdf\"), \n",
    "#           transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14332d0d",
   "metadata": {},
   "source": [
    "# Supplementary panel: score vs background - new odor distance\n",
    "Not using this version yet. Make this plot with PCA scaled up\n",
    "Move to supplementary. Or maybe in the last figure, to say all models are limited? Need to re-run with PCA scaled up first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad542fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_back_dists = np.load(os.path.join(data_folder, \"new_back_distances_identity.npz\"))[\"new_back_distances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9266adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenated Jaccard scores shaped [n_background, n_new_odors, n_times, n_new_concs, n_back_samples]\n",
    "# new_back_dists shaped background, new_odor\n",
    "# Just need median along axes 2, 3, 4 to get one per [back, new] pair\n",
    "jaccards_per_pair = {}\n",
    "for m in show_models:\n",
    "    jaccards_per_pair[m] = np.median(all_jacs[m], axis=(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: kdeplot is slow, this figure takes around 1 min to generate\n",
    "fig, ax = plt.subplots()\n",
    "plot_type = \"scatter\"  # or \"kde\"\n",
    "if plot_type == \"kde\":\n",
    "    data = pd.concat({m:pd.DataFrame(np.stack([jaccards_per_pair[m].flatten(), new_back_dists.flatten()], axis=1), \n",
    "                                columns=pd.Index([\"jaccard\", \"new-back\"]))\n",
    "                    for m in show_models}, names=[\"Model\"])\n",
    "    data = data.rename(model_nice_names, level=\"Model\")\n",
    "    model_nice_colors = {model_nice_names[m]:model_colors[m] for m in show_models}\n",
    "    g = sns.kdeplot(data=data.reset_index(), x=\"new-back\", y=\"jaccard\", hue=\"Model\", \n",
    "            palette=model_nice_colors, ax=ax, fill=True, alpha=0.5)\n",
    "    sns.move_legend(g, frameon=False, loc=\"upper left\")\n",
    "elif plot_type == \"scatter\":\n",
    "    for m in show_models:\n",
    "        xy = np.stack([new_back_dists.flatten(), jaccards_per_pair[m].flatten()], axis=0)\n",
    "        xy = np.unique(xy, axis=1)  # Find unique (x, y) pairs\n",
    "        ax.scatter(xy[0], xy[1], color=model_colors[m], label=model_nice_names[m], s=0.9, alpha=0.1)\n",
    "\n",
    "ax.set(xlabel=\"Background-new odor distance\", ylabel=r\"Jaccard similarity $(z_{\\mathrm{n}}, z_{\\mathrm{mix}})$\")\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join(panels_folder, \"back-new_distance_jaccard_correlation.pdf\"), \n",
    "#            transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937e2ab-ab60-407d-b80d-3a02d0ede09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, in particular, the improvement afforded by IBCM compared to no habituation\n",
    "improvements = jaccards_per_pair[\"ibcm\"] - jaccards_per_pair[\"none\"]\n",
    "fraction_positive = (improvements >= 0).sum() / improvements.size\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axhline(0.0, ls=\"--\", color=\"grey\", zorder=0)\n",
    "ax.scatter(new_back_dists.flatten(), improvements.flatten(), s=1.0, alpha=0.7, color=\"k\")\n",
    "ax.set(xlabel=\"Background-new odor distance\", ylabel=\"IBCM vs None improvement\")\n",
    "ax.annotate(f\"{fraction_positive*100:.1f} %\", xy=(0.8, 0.02), va=\"bottom\")\n",
    "ax.annotate(f\"{(1.0-fraction_positive)*100:.1f} %\", xy=(0.8, -0.04), va=\"top\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab031bbb",
   "metadata": {},
   "source": [
    "#### Remark\n",
    "Extrapolating, we see how the IBCM model is driving new odors close to the background into the floor too quickly. In case this becomes a problem, e.g. if we run simulations with real odor vectors, just dial up the regularization $\\beta$, to reduce the amount of inhibition exterted by the IBCM model, closer to a level that would preserve more of the parallel component. \n",
    "\n",
    "So, let reviewers ask, and do this fix if necessary. But don't show this figure except in supplementary maybe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb28b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
