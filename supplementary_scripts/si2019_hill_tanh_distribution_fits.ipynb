{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233c2218",
   "metadata": {},
   "source": [
    "# Fitting OSN-odorant EC50 distribution\n",
    "\n",
    "Data of OSN dose-response curves for a panel of $30$ odorants or so, in the paper: Si et al., *Neuron*, 2019: https://doi.org/10.1016/j.neuron.2018.12.030\n",
    "\n",
    "Also analyzed by Kadakia and Emonet, *eLife*, 2019. \n",
    "\n",
    "## Description of the data and distribution\n",
    "\n",
    "\n",
    "EC50s are in units of relative concentration (dilution), so have amplitudes typically between $10^{-7}$ and $10^{-3}$. This means EC50s are similarly small. They look at the distribution of \n",
    "\n",
    "$$ x = 1/\\mathrm{EC50} $$\n",
    "\n",
    "which are, roughly speaking, the affinities $K^*$ in the model by Kadakia and Emonet, 2019. So the affinities themselves follow a power-law, it was not necessary (as Kadakia and Emonet do) to sample the dissociation constants $K_D = $ EC50, they could have\n",
    "\n",
    "Si et al., 2019, Figure 3D plots the complementary CDF (CCDF)  of $x$, $1 - \\mathrm{CDF} = 1 - F_X(x) \\equiv G_X(x) $. Si et al. claim this is a power-law with exponent $-0.42$, but this is based on the tail, which contains few points. The full distribution, plotted in log-log, looks much closer to a repressive Hill function, that is\n",
    "\n",
    "$$ G_X(x) = 1 - F_X(x) = \\frac{1}{1 + A x^{\\alpha}} $$\n",
    "\n",
    "with exponent $\\alpha = 0.42$ explaining the tail. Note that this is already properly  normalized, as this is the CDF (integral of the PDF) and it remains between $0$ and $1$. Note also that the log-log plot in Fig. 3D doesn't cause bin width normalization ambiguities, since the quantity plotted is a probability (CCDF is an integral of the density), so the y scale is unambiguous, not a function that transforms with a Jacobian (like the density) when the x axis is scaled. \n",
    "\n",
    "Note that the CDF would be a Hill function, \n",
    "\n",
    "$$ F_X(x) = \\frac{A x^{\\alpha}}{1 + A x^{\\alpha}}  \\,\\, .$$\n",
    "\n",
    "\n",
    "\n",
    "To show this Hill CDF is a better fit than a pure power law, I downloaded the table of EC50s from Si et al., 2019, and reanalyze it. Below, I recompute the empirical CDF of $x = 1/\\mathrm{EC50}$, and fit it with such a Hill function. The data (table of log10 EC50s) available on Github at https://github.com/samuellab/Larval-ORN/blob/master/Figure3/results/log_10_EC50.csv\n",
    "\n",
    "## Useful\n",
    "\n",
    "This type of CDF is easy to sample via the inverse CDF, although it may not be a well-known probability distribution function. \n",
    "\n",
    "specifically \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note that the CDF is valid for $x$ between $10^1$ and $10^9$; beyond that range, there is no data, but we do have $G_X(x) \\approx 1$ for smaller $x$, $G_X(x) < 10^{-3}$ for larger $x$, so we can assume this distribution spans the full range of $x$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from os.path import join as pj\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385330f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fold = pj(\"..\", \"data\")\n",
    "fig_fold = pj(\"..\", \"figures\", \"\")\n",
    "do_save_outputs = False   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94574964",
   "metadata": {},
   "source": [
    "## Load and preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2278b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(pj(data_fold, \"si2019_log10ec50s.csv\"))\n",
    "df[\"Odorant\"] = df[\"Unnamed: 0\"]\n",
    "df = df.drop(\"Unnamed: 0\", axis=1).set_index(\"Odorant\")\n",
    "df.columns.name = \"OR\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d97d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract non-NaN EC50s and compute complementary CDF of x = 1/EC50\n",
    "ec50s_sorted = np.sort(10.0**(df.stack(\"OR\").dropna().values))  # df contains log10ec50\n",
    "x_sorted = 1.0 / ec50s_sorted[::-1]\n",
    "print(\"number values: {:d}, min: {:.2e}, max: {:.2e}\".format(\n",
    "    x_sorted.size, x_sorted.min(), x_sorted.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each data point contributes a frequency 1 / npoints\n",
    "# remove this quantity at each encountered data point.\n",
    "# ccdf is the y values associated to the x values in x_sorted\n",
    "prob_per_pt = 1.0 / x_sorted.size\n",
    "ccdf_exp = np.arange(1.0, 0.0, -prob_per_pt)\n",
    "assert ccdf_exp.size == x_sorted.size\n",
    "assert abs(ccdf_exp[-1] - prob_per_pt) < 0.01 * prob_per_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eeba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ccdf in log-log scale, as in Fig. 3D from Si et al., 2019\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_sorted, ccdf_exp, marker=\"o\", mec=\"k\", mfc=\"none\", ms=6.0, ls=\"none\", mew=0.5)\n",
    "ax.set(xscale=\"log\", yscale=\"log\", xlabel=\"x = 1/EC50 (inv. dilution)\", \n",
    "       ylabel=r\"Complementary CDF $G_X(x)$\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0824360",
   "metadata": {},
   "source": [
    "## Fit Hill function on the complementary CDF\n",
    "\n",
    "$$ G_X(x) = \\frac{1}{1 + b x^\\alpha} $$\n",
    "\n",
    "Fit the log of $b$, since $b$ is likely very small but positive. Also, fit the log of G_X, so the tail is not too penalized by its lower amplitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_ccdf(x, b, alpha):\n",
    "    return 1.0 / (1.0 + b * x**alpha)\n",
    "\n",
    "def hill_ccdf_logb(x, logb, alpha):\n",
    "    return 1.0 / (1.0 + (10.0**logb) * (x**alpha))\n",
    "\n",
    "def loghill_ccdf_logb(x, logb, alpha):\n",
    "    return -np.log10(1.0 + (10.0**logb) * (x**alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c325f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerbounds = (-3.0, 0.1)  # scale log10(b), power alpha\n",
    "upperbounds = (0.0, 1.5)\n",
    "p_estim = (-2.0, 0.42)\n",
    "\n",
    "# Fit in linear scale\n",
    "popt_lin, pcov_lin = curve_fit(hill_ccdf_logb, x_sorted, ccdf_exp,\n",
    "                       p0=p_estim, bounds=(lowerbounds, upperbounds))\n",
    "\n",
    "# Fit in log scale\n",
    "popt_log, pcov_log = curve_fit(loghill_ccdf_logb, x_sorted, np.log10(ccdf_exp),\n",
    "                       p0=p_estim, bounds=(lowerbounds, upperbounds))\n",
    "                       \n",
    "print(\"Best fit in log-scale:\", popt_log)\n",
    "print(\"With standard dev. on parameters:\", np.sqrt(pcov_log[[0, 1], [0, 1]]))\n",
    "\n",
    "print(\"Best fit in linear-scale:\", popt_lin)\n",
    "print(\"With standard dev. on parameters:\", np.sqrt(pcov_lin[[0, 1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78cc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.geomspace(x_sorted.min(), x_sorted.max(), 200)\n",
    "ccdf_fit_log = 10.0**(loghill_ccdf_logb(xrange, *popt_log))\n",
    "ccdf_fit_linear = hill_ccdf_logb(xrange, *popt_lin)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0], \n",
    "                   plt.rcParams[\"figure.figsize\"][1]*1.5)\n",
    "for ax in axes:\n",
    "    ax.plot(x_sorted, ccdf_exp, marker=\"o\", mec=\"k\", mfc=\"none\", ms=6.0, ls=\"none\", mew=0.5, label='Data')\n",
    "    ax.plot(xrange, ccdf_fit_linear, ls=\"-\", label=\"Linear-scale fit\", color=\"tab:blue\")\n",
    "    ax.plot(xrange, ccdf_fit_log, ls=\"-\", label=\"Log-scale fit\", color=\"tab:orange\")\n",
    "    ax.set_ylabel(r\"Complementary CDF $G_X(x)$\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.legend(frameon=False)\n",
    "axes[1].set_xlabel(\"x = 1/EC50 (inverse dilution units)\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[1].set_yscale(\"linear\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c801b",
   "metadata": {},
   "source": [
    "## Sample from this Hill distribution\n",
    "See what kind of odor vectors we get, if they are similar to each other or not, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f2488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_hillcdf(r, logb, alpha):\n",
    "    return ((1.0/r - 1.0)/10.0**logb)**(1.0 / alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58af08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgen = np.random.default_rng(0xb183e7d8079f5bde91fdff60a4b31df2)\n",
    "n_dims = 50\n",
    "unif = rgen.random(size=(100, n_dims))\n",
    "odor_vecs_hill = inverse_transform_hillcdf(unif, *popt_log)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(np.log10(odor_vecs_hill))\n",
    "#img = ax.imshow(odor_vecs_hill)\n",
    "ax.set(xlabel=\"OSN\", ylabel=\"Odor\")\n",
    "fig.colorbar(img, label=\"log10 OSN affinity (1/EC50)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d512196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity now\n",
    "n_samples = int(1e4)\n",
    "unif = rgen.random(size=(n_samples, n_dims))\n",
    "odor_vecs_hill_samp = inverse_transform_hillcdf(unif, *popt_log)\n",
    "odor_norms = np.sqrt(np.sum(odor_vecs_hill_samp**2, axis=1))\n",
    "unit_vecs = odor_vecs_hill_samp / odor_norms[:, None]\n",
    "\n",
    "cosine_sims = unit_vecs.dot(unit_vecs.T)\n",
    "cosine_sims[np.diag_indices(n_samples)] = np.nan\n",
    "\n",
    "mean_cosine = np.nanmean(cosine_sims)\n",
    "std_cosine = np.nanstd(cosine_sims, ddof=1)\n",
    "\n",
    "print(\"Average cosine similarity:\", mean_cosine)\n",
    "print(\"Standard deviation:\", std_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65533672",
   "metadata": {},
   "source": [
    "## Alternate distribution with a tanh function\n",
    "\n",
    "$$ G_X(x) = \\mathrm{tanh}\\left( x^{-\\alpha} / b \\right) $$ \n",
    "\n",
    "has a power-law behavior for large $x$, with a better cutoff for small $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_ccdf(x, b, alpha):\n",
    "    return np.tanh(1.0 / (b * x**alpha))\n",
    "\n",
    "def tanh_ccdf_logb(x, logb, alpha):\n",
    "    return np.tanh(1.0 / ((10.0**logb) * (x**alpha)))\n",
    "\n",
    "def logtanh_ccdf_logb(x, logb, alpha):\n",
    "    return np.log10(np.tanh(1.0 / ((10.0**logb) * (x**alpha))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ba256",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerbounds = (-3.0, 0.1)  # scale log10(b), power alpha\n",
    "upperbounds = (0.0, 1.5)\n",
    "p_estim = (-2.0, 0.42)\n",
    "\n",
    "# Fit in linear scale\n",
    "popt_lintanh, pcov_lintanh = curve_fit(tanh_ccdf_logb, x_sorted, ccdf_exp,\n",
    "                       p0=p_estim, bounds=(lowerbounds, upperbounds))\n",
    "\n",
    "# Fit in log scale\n",
    "popt_logtanh, pcov_logtanh = curve_fit(logtanh_ccdf_logb, x_sorted, np.log10(ccdf_exp),\n",
    "                       p0=p_estim, bounds=(lowerbounds, upperbounds))\n",
    "                       \n",
    "print(\"Best fit in log-scale:\", popt_logtanh)\n",
    "print(\"With standard dev. on parameters:\", np.sqrt(pcov_logtanh[[0, 1], [0, 1]]))\n",
    "\n",
    "print(\"Best fit in linear scale:\", popt_lintanh)\n",
    "print(\"With standard dev. on parameters:\", np.sqrt(pcov_lintanh[[0, 1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.geomspace(x_sorted.min(), x_sorted.max(), 200)\n",
    "ccdf_fit_log = 10.0**(logtanh_ccdf_logb(xrange, *popt_logtanh))\n",
    "ccdf_fit_linear = tanh_ccdf_logb(xrange, *popt_lintanh)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0], \n",
    "                   plt.rcParams[\"figure.figsize\"][1]*1.5)\n",
    "for ax in axes:\n",
    "    ax.plot(x_sorted, ccdf_exp, marker=\"o\", mec=\"k\", mfc=\"none\", ms=6.0, ls=\"none\", mew=0.5, label='Data')\n",
    "    ax.plot(xrange, ccdf_fit_linear, ls=\"-\", label=\"Linear-scale fit\", color=\"tab:blue\")\n",
    "    ax.plot(xrange, ccdf_fit_log, ls=\"-\", label=\"Log-scale fit\", color=\"tab:orange\")\n",
    "    ax.set_ylabel(r\"Complementary CDF $G_X(x)$\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.legend(frameon=False)\n",
    "axes[1].set_xlabel(\"x = 1/EC50 (inverse dilution units)\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[1].set_yscale(\"linear\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95fc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_tanhcdf(r, logb, alpha):\n",
    "    return (10.0**logb * np.arctanh(r))**(-1.0 / alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4c2ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unif = rgen.random(size=(100, n_dims))\n",
    "odor_vecs_tanh = inverse_transform_tanhcdf(unif, *popt_logtanh)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(np.log10(odor_vecs_tanh))\n",
    "#img = ax.imshow(odor_vecs_tanh)\n",
    "ax.set(xlabel=\"OSN\", ylabel=\"Odor\")\n",
    "fig.colorbar(img, label=\"log10 OSN affinity (1/EC50)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7510a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity now\n",
    "n_samples = int(1e4)\n",
    "unif = rgen.random(size=(n_samples, n_dims))\n",
    "odor_vecs_tanh_samp = inverse_transform_tanhcdf(unif, *popt_logtanh)\n",
    "odor_norms = np.sqrt(np.sum(odor_vecs_tanh_samp**2, axis=1))\n",
    "unit_vecs = odor_vecs_tanh_samp / odor_norms[:, None]\n",
    "\n",
    "cosine_sims = unit_vecs.dot(unit_vecs.T)\n",
    "cosine_sims[np.diag_indices(n_samples)] = np.nan\n",
    "\n",
    "mean_cosine = np.nanmean(cosine_sims)\n",
    "std_cosine = np.nanstd(cosine_sims, ddof=1)\n",
    "\n",
    "print(\"Average cosine similarity:\", mean_cosine)\n",
    "print(\"Standard deviation:\", std_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe35664e",
   "metadata": {},
   "source": [
    "## Cosine similarity in vectors from the original data\n",
    "Set inverse EC50s that are NaNs to zero: if $K_{i \\mu} = 0$, this OR type $i$  is unresponsive to that odor $\\mu$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a19fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_inverseec_50 = 1.0 / 10.0**df.values  # each row is an odorant\n",
    "empirical_vectors = np.nan_to_num(empirical_inverseec_50, copy=True, nan=0.0001*np.nanmin(empirical_inverseec_50))\n",
    "n_dim_emp = empirical_vectors.shape[1]\n",
    "empirical_vec_norms = np.sqrt(np.sum(empirical_vectors**2, axis=1))\n",
    "emp_unit_vecs = empirical_vectors / empirical_vec_norms[:, None]\n",
    "\n",
    "# Plot of unnormalized vectors\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(np.log10(empirical_vectors))\n",
    "#img = ax.imshow(empirical_vectors)\n",
    "ax.set(xlabel=\"OSN\", ylabel=\"Odor\")\n",
    "fig.colorbar(img, label=\"OSN affinity log10(1/EC50)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02678d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "cosine_sims = emp_unit_vecs.dot(emp_unit_vecs.T)\n",
    "cosine_sims[np.diag_indices(emp_unit_vecs.shape[0])] = np.nan\n",
    "\n",
    "mean_cosine = np.nanmean(cosine_sims)\n",
    "std_cosine = np.nanstd(cosine_sims, ddof=1)\n",
    "\n",
    "print(\"Average cosine similarity:\", mean_cosine)\n",
    "print(\"Standard deviation:\", std_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27cfa5",
   "metadata": {},
   "source": [
    "## Compare also to the raw power-law fitted in Si et al., 2019\n",
    "Show that it would not be very good to capture the full range of values... The pdf they use is\n",
    "\n",
    "$$ f_X(x) = (a -1 )x_{\\mathrm{min}}^{a-1} x^{-a} $$\n",
    "\n",
    "with setting a lower cutoff at $x_{\\mathrm{min}}$. Note that their $a$ in that definition is $\\alpha + 1$; they have $a = 1.42$ so a power-law with $\\alpha=0.42$ for the tail of the complementary CDF. This corresponds to a CDF of\n",
    "\n",
    "$$ F_X(x) = \\int_{x_\\mathrm{min}}^x \\mathrm{d}x' (a -1 )x_{\\mathrm{min}}^{a-1} x'^{-a} = 1 - \\left(\\frac{x_\\mathrm{min}}{x} \\right)^{a-1}$$\n",
    "\n",
    "or a CCDF of \n",
    "\n",
    "$$ G_X(x) = \\left(\\frac{x_\\mathrm{min}}{x} \\right)^{a-1} = \\left(\\frac{x}{x_\\mathrm{min}} \\right)^{-\\alpha}$$\n",
    "\n",
    "which we can easily invert to sample from it. If we sample $r \\sim U(0, 1)$, then we set\n",
    "\n",
    "$$ r = G_X(x) \\Rightarrow x = G_X^{-1}(r) = x_\\mathrm{min} r^{-1/\\alpha} $$\n",
    "\n",
    "\n",
    "Let's try to 1) plot their fitted pure power-law $G_X(x)$ against their empirical CCDF, and 2) sample odor vectors from their fitted power-law\n",
    "\n",
    "They have $a = 1.42$, so $\\alpha = 0.42$, and $x_\\mathrm{min} = 4.2 \\times 10^4$. Let's give a chance and re-do this fit? We work with $\\log_{10}(x_\\mathrm{min})$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_ccdf(x, xmin, alpha):\n",
    "    return (x / xmin)**(-alpha)\n",
    "\n",
    "def power_ccdf_logxmin(x, logxmin, alpha):\n",
    "    return (x / 10.0**logxmin)**(-alpha)\n",
    "\n",
    "def logpower_ccdf_logxmin(x, logxmin, alpha):\n",
    "    return -alpha * np.log10(x / 10.0**logxmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99daec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_powerlaw(r, logxmin, alpha):\n",
    "    return 10.0**logxmin * (1.0 - r)**(-1.0/alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ffd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerbounds = (-3.0, 0.1)  # scale log10(xmin), power alpha\n",
    "upperbounds = (6.0, 1.5)\n",
    "p_estim_si2019 = (np.log10(4.2e4), 0.42)\n",
    "\n",
    "# Fit in linear scale\n",
    "popt_linpow, pcov_linpow = curve_fit(power_ccdf_logxmin, x_sorted, ccdf_exp,\n",
    "                       p0=p_estim_si2019, bounds=(lowerbounds, upperbounds))\n",
    "\n",
    "# Fit in log scale\n",
    "popt_logpow, pcov_logpow = curve_fit(logpower_ccdf_logxmin, x_sorted, np.log10(ccdf_exp),\n",
    "                       p0=p_estim_si2019, bounds=(lowerbounds, upperbounds))\n",
    "                       \n",
    "print(\"Best fit in log-scale:\", popt_logpow)\n",
    "print(\"With standard dev. on parameters:\", np.sqrt(pcov_logpow[[0, 1], [0, 1]]))\n",
    "\n",
    "print(\"Best fit in linear scale:\", popt_linpow)\n",
    "print(\"With standard dev. on parameters:\", np.sqrt(pcov_linpow[[0, 1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrange = np.geomspace(x_sorted.min(), x_sorted.max(), 200)\n",
    "ccdf_fit_log = 10.0**(logpower_ccdf_logxmin(xrange, *popt_logpow))\n",
    "ccdf_fit_linear = power_ccdf_logxmin(xrange, *popt_linpow)\n",
    "\n",
    "# Also plot their reported fit\n",
    "ccdf_fit_si2019 = power_ccdf_logxmin(xrange, *p_estim_si2019)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, sharex=True)\n",
    "fig.set_size_inches(plt.rcParams[\"figure.figsize\"][0], \n",
    "                   plt.rcParams[\"figure.figsize\"][1]*1.5)\n",
    "for ax in axes:\n",
    "    ax.plot(x_sorted, ccdf_exp, marker=\"o\", mec=\"k\", mfc=\"none\", ms=6.0, ls=\"none\", mew=0.5, label='Data')\n",
    "    ax.plot(xrange, ccdf_fit_linear, ls=\"-\", label=\"Linear-scale fit\", color=\"tab:blue\")\n",
    "    ax.plot(xrange, ccdf_fit_log, ls=\"-\", label=\"Log-scale fit\", color=\"tab:orange\")\n",
    "    ax.plot(xrange, ccdf_fit_si2019, ls=\"-\", \n",
    "            label=\"Si 2019 reported fit\\n\" + r\"($x_{min}=4.2 \\times 10^4, \\alpha=0.42$)\", color=\"tab:green\")\n",
    "    ax.set_ylabel(r\"Complementary CDF $G_X(x)$\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.legend(frameon=False)\n",
    "axes[1].set_xlabel(\"x = 1/EC50 (inverse dilution units)\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "axes[1].set_yscale(\"linear\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293552ca",
   "metadata": {},
   "source": [
    "### Conclusion on the reported fit\n",
    "\n",
    "Clearly, they have only fitted the very tail of their distribution, which is based on a few EC50 values, and the pure power-law pdf is a terrible fit of the full OSN distribution, which we need in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06409cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample odor vectors from this power-law anyways\n",
    "n_samples = int(1e4)\n",
    "unif = rgen.random(size=(n_samples, n_dims))\n",
    "odor_vecs_si2019_samp = inverse_transform_powerlaw(unif, *p_estim_si2019)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(np.log10(odor_vecs_si2019_samp[:100]))\n",
    "#img = ax.imshow(odor_vecs_tanh)\n",
    "ax.set(xlabel=\"OSN\", ylabel=\"Odor\")\n",
    "fig.colorbar(img, label=\"log10 OSN affinity (1/EC50)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee8fd0",
   "metadata": {},
   "source": [
    "## Histogram of vector elements in data vs fit\n",
    "\n",
    "Just to be sure the fitted distribution is roughly OK and better than a pure power-law (which we also compare). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac770065",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1, bins1 = np.histogram(np.log10(x_sorted), bins=\"doane\", density=True)\n",
    "hist2, bins2 = np.histogram(np.log10(odor_vecs_hill_samp), bins=\"doane\", density=True)\n",
    "hist3, bins3 = np.histogram(np.log10(odor_vecs_tanh_samp), bins=\"doane\", density=True)\n",
    "hist4, bins4 = np.histogram(np.log10(odor_vecs_si2019_samp), bins=\"doane\", density=True)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(bins2[:-1], hist2, width=np.diff(bins2), align=\"edge\", label=\"Generated Hill\", alpha=0.5)\n",
    "ax.bar(bins3[:-1], hist3, width=np.diff(bins3), align=\"edge\", label=\"Generated tanh\", alpha=0.5)\n",
    "ax.bar(bins4[:-1], hist4, width=np.diff(bins4), align=\"edge\", label=\"Si et al., 2019\", alpha=0.5)\n",
    "ax.bar(bins1[:-1], hist1, width=np.diff(bins1), align=\"edge\", label=\"Empirical\", alpha=0.5, color=\"grey\")\n",
    "ax.legend()\n",
    "ax.set(xlabel=\"log10 OSN sensitivity\", ylabel=\"Frequency\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b039dac",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The clear winner is the tanh distribution fitted in log scale. The Hill has a tail for small $x$ which is not in the data distribution.\n",
    "\n",
    "\n",
    "However, the full dataset had a bunch of NaN EC50s, which means many sensitivities are in fact non-detectable, so there should be a tail for small $x$; perhaps the Hill distribution is the best one to also capture some of this non-detectable responsiveness of each OR to some odors?\n",
    "\n",
    "I will use the tanh, since for the available (non-NaN) data, it is the best fit, and I do not know the actual value of the other EC50s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b113800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export fit parameters and ccdf data for final plotting\n",
    "results_folder = pj(\"..\", \"results\", \"for_plots\", \"nonlin_adapt\")\n",
    "results_dicts = {\n",
    "    \"x_sorted\": list(x_sorted), \n",
    "    \"ccdf_exp\": list(ccdf_exp),\n",
    "    \"best_fit\": {\"logb\": float(popt_logtanh[0]), \"alpha\": float(popt_logtanh[1]), \n",
    "                 \"logb_cov\": float(pcov_logtanh[0, 0]), \"alpha_cov\": float(pcov_logtanh[1, 1])}\n",
    "}\n",
    "if do_save_outputs:\n",
    "    with open(pj(results_folder, \"si2019_cdf_and_fits.json\"), \"w\") as h:\n",
    "        json.dump(results_dicts, h, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e7846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
